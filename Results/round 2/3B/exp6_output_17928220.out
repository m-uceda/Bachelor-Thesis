Mon Jun 16 16:20:56 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.05              Driver Version: 560.35.05      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-PCIE-40GB          On  |   00000000:E3:00.0 Off |                    0 |
| N/A   32C    P0             36W /  250W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.
ü¶• Unsloth Zoo will now patch everything to make training faster!
INFO 06-16 16:24:50 __init__.py:207] Automatically detected platform cuda.
[W616 16:25:04.760770359 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
==((====))==  Unsloth 2025.6.2: Fast Llama patching. Transformers: 4.52.4. vLLM: 0.7.3.
   \\   /|    NVIDIA A100-PCIE-40GB. Num GPUs = 1. Max memory: 39.496 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.5.1+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.1.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: vLLM loading unsloth/Llama-3.2-3B-Instruct with actual GPU utilization = 59.31%
Unsloth: Your GPU has CUDA compute capability 8.0 with VRAM = 39.5 GB.
Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 4024. Num Sequences = 288.
Unsloth: vLLM's KV Cache can use up to 17.26 GB. Also swap space = 6 GB.
INFO 06-16 16:25:32 config.py:549] This model supports multiple tasks: {'generate', 'embed', 'classify', 'reward', 'score'}. Defaulting to 'generate'.
WARNING 06-16 16:25:32 cuda.py:95] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 06-16 16:25:32 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='unsloth/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='unsloth/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=4024, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/Llama-3.2-3B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":0,"backend":"inductor","splitting_ops":[],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"debug":false,"dce":true,"coordinate_descent_tuning":true,"trace.enabled":false,"trace.graph_diagram":false,"triton.cudagraphs":true,"compile_threads":48,"max_autotune":false,"disable_progress":false,"verbose_progress":true},"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[],"max_capture_size":0}, use_cached_outputs=False, 
INFO 06-16 16:25:35 cuda.py:229] Using Flash Attention backend.
INFO 06-16 16:25:36 model_runner.py:1110] Starting to load model unsloth/Llama-3.2-3B-Instruct...
INFO 06-16 16:25:38 weight_utils.py:254] Using model weights format ['*.safetensors']
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:06<00:06,  6.96s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:09<00:00,  4.09s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:09<00:00,  4.52s/it]

INFO 06-16 16:25:47 model_runner.py:1115] Loading model weights took 6.0316 GB
INFO 06-16 16:25:48 punica_selector.py:18] Using PunicaWrapperGPU.
INFO 06-16 16:25:57 worker.py:267] Memory profiling takes 8.50 seconds
INFO 06-16 16:25:57 worker.py:267] the current vLLM instance can use total_gpu_memory (39.50GiB) x gpu_memory_utilization (0.59) = 23.43GiB
INFO 06-16 16:25:57 worker.py:267] model weights take 6.03GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 1.35GiB; the rest of the memory reserved for KV Cache is 15.95GiB.
INFO 06-16 16:25:57 executor_base.py:111] # cuda blocks: 9333, # CPU blocks: 3510
INFO 06-16 16:25:57 executor_base.py:116] Maximum concurrency for 4024 tokens per request: 37.11x
INFO 06-16 16:25:59 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 11.27 seconds
Unsloth: Just some info: will skip parsing ['pre_feedforward_layernorm', 'k_norm', 'q_norm', 'post_feedforward_layernorm']
Unsloth: Just some info: will skip parsing ['pre_feedforward_layernorm', 'k_norm', 'q_norm', 'post_feedforward_layernorm']
Unsloth 2025.6.2 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.
Dataset distribution:
----------------------------------------
Problem Type   Train     Test      Total     Train %   
----------------------------------------
3-option       240       60        300       80.0%
5-option       400       100       500       80.0%
7-option       560       140       700       80.0%
----------------------------------------
Overall        1200      300       1500      80.0%
Processing method: cot
Fine-tuning model for method: cot
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.


--------------------------- Training args: UnslothGRPOConfig(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
beta=0.04,
bf16=True,
bf16_full_eval=True,
data_seed=3407,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=False,
do_predict=False,
do_train=False,
ds3_gather_for_generation=True,
eval_accumulation_steps=2,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.NO,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-06,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_completions=False,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=outputs/runs/Jun16_16-26-13_a100gpu4,
logging_first_step=False,
logging_nan_inf_filter=False,
logging_steps=1,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.COSINE,
max_completion_length=3000,
max_grad_norm=1.0,
max_prompt_length=1024,
max_steps=500,
metric_for_best_model=None,
model_init_kwargs=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_generations=4,
num_train_epochs=3.0,
optim=OptimizerNames.ADAMW_8BIT,
optim_args=None,
optim_target_modules=None,
output_dir=outputs,
overwrite_output_dir=None,
past_index=-1,
per_device_eval_batch_size=4,
per_device_train_batch_size=4,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
ref_model_mixup_alpha=0.9,
ref_model_sync_steps=64,
remove_unused_columns=False,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
reward_weights=None,
run_name=outputs,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=250,
save_strategy=SaveStrategy.STEPS,
save_total_limit=None,
seed=3407,
skip_memory_metrics=True,
sync_ref_model=False,
temperature=0.9,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=250,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
unsloth_num_chunks=-1,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
use_vllm=True,
vllm_device=auto,
vllm_dtype=auto,
vllm_gpu_memory_utilization=0.9,
vllm_max_model_len=None,
vllm_sampling_params=None,
warmup_ratio=0.1,
warmup_steps=0,
weight_decay=0.1,
)


==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 1,200 | Num Epochs = 7 | Total steps = 500
O^O/ \_/ \    Batch size per device = 4 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16
 "-____-"     Trainable parameters = 97,255,424/3,310,005,248 (2.94% trained)
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
wandb: Currently logged in as: m-uceda (m-uceda-rug). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.20.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /scratch/s5112583/thesis/RL/small/wandb/run-20250616_162617-8f5295ug
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run outputs
wandb: ‚≠êÔ∏è View project at https://wandb.ai/m-uceda-rug/huggingface
wandb: üöÄ View run at https://wandb.ai/m-uceda-rug/huggingface/runs/8f5295ug
  0%|          | 0/500 [00:00<?, ?it/s]Unsloth: Will smartly offload gradients to save VRAM!
  0%|          | 1/500 [02:02<16:58:45, 122.50s/it]                                                   {'loss': 0.0, 'grad_norm': 0.65018630027771, 'learning_rate': 0.0, 'rewards/cot_correctness_reward_func': 0.25, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.203125, 'reward_std': 0.59375, 'completion_length': 261.625, 'kl': 0.0, 'epoch': 0.01}
  0%|          | 1/500 [02:02<16:58:45, 122.50s/it]  0%|          | 2/500 [03:09<12:23:50, 89.62s/it]                                                   {'loss': -0.0, 'grad_norm': 0.8307822942733765, 'learning_rate': 1.0000000000000001e-07, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.4375, 'rewards/cot_format_reward_func': 0.40625, 'reward': 1.59375, 'reward_std': 1.1433208882808685, 'completion_length': 267.0625, 'kl': 0.0, 'epoch': 0.03}
  0%|          | 2/500 [03:09<12:23:50, 89.62s/it]  1%|          | 3/500 [04:19<11:08:10, 80.67s/it]                                                  {'loss': 0.0, 'grad_norm': 0.6889748573303223, 'learning_rate': 2.0000000000000002e-07, 'rewards/cot_correctness_reward_func': 0.375, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.40625, 'reward': 1.25, 'reward_std': 0.855913907289505, 'completion_length': 281.5, 'kl': 0.0004230321355862543, 'epoch': 0.04}
  1%|          | 3/500 [04:19<11:08:10, 80.67s/it]  1%|          | 4/500 [05:32<10:44:09, 77.92s/it]                                                  {'loss': 0.0, 'grad_norm': 0.8986427783966064, 'learning_rate': 3.0000000000000004e-07, 'rewards/cot_correctness_reward_func': 0.375, 'rewards/cot_letter_reward_func': 0.40625, 'rewards/cot_format_reward_func': 0.3125, 'reward': 1.09375, 'reward_std': 0.9691184014081955, 'completion_length': 278.1875, 'kl': 0.0003782738494919613, 'epoch': 0.05}
  1%|          | 4/500 [05:32<10:44:09, 77.92s/it]  1%|          | 5/500 [06:38<10:06:08, 73.47s/it]                                                  {'loss': 0.0, 'grad_norm': 0.914985716342926, 'learning_rate': 4.0000000000000003e-07, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.390625, 'reward': 1.734375, 'reward_std': 1.1799846291542053, 'completion_length': 258.5, 'kl': 0.00039220252074301243, 'epoch': 0.07}
  1%|          | 5/500 [06:38<10:06:08, 73.47s/it]  1%|          | 6/500 [07:55<10:16:26, 74.87s/it]                                                  {'loss': 0.0, 'grad_norm': 0.9118844270706177, 'learning_rate': 5.000000000000001e-07, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.375, 'reward': 1.625, 'reward_std': 1.0122289657592773, 'completion_length': 316.3125, 'kl': 0.0004003516150987707, 'epoch': 0.08}
  1%|          | 6/500 [07:55<10:16:26, 74.87s/it]  1%|‚ñè         | 7/500 [09:30<11:07:26, 81.23s/it]                                                  {'loss': 0.0, 'grad_norm': 0.7359720468521118, 'learning_rate': 6.000000000000001e-07, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.359375, 'reward': 1.703125, 'reward_std': 0.6523861587047577, 'completion_length': 305.3125, 'kl': 0.00038594719080720097, 'epoch': 0.09}
  1%|‚ñè         | 7/500 [09:30<11:07:26, 81.23s/it]  2%|‚ñè         | 8/500 [10:45<10:49:08, 79.16s/it]                                                  {'loss': 0.0, 'grad_norm': 0.7759977579116821, 'learning_rate': 7.000000000000001e-07, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.359375, 'reward': 1.453125, 'reward_std': 1.1077045947313309, 'completion_length': 268.875, 'kl': 0.0003651520164567046, 'epoch': 0.11}
  2%|‚ñè         | 8/500 [10:45<10:49:08, 79.16s/it]  2%|‚ñè         | 9/500 [11:41<9:48:54, 71.97s/it]                                                  {'loss': 0.0, 'grad_norm': 0.844200074672699, 'learning_rate': 8.000000000000001e-07, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.453125, 'reward': 1.578125, 'reward_std': 1.09375, 'completion_length': 248.0, 'kl': 0.00038927017158130184, 'epoch': 0.12}
  2%|‚ñè         | 9/500 [11:41<9:48:54, 71.97s/it]  2%|‚ñè         | 10/500 [12:52<9:46:55, 71.87s/it]                                                  {'loss': 0.0, 'grad_norm': 0.808281421661377, 'learning_rate': 9.000000000000001e-07, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.734375, 'reward_std': 0.8199251294136047, 'completion_length': 276.25, 'kl': 0.00034945614606840536, 'epoch': 0.13}
  2%|‚ñè         | 10/500 [12:52<9:46:55, 71.87s/it]  2%|‚ñè         | 11/500 [14:13<10:06:29, 74.42s/it]                                                   {'loss': 0.0, 'grad_norm': 0.7205879092216492, 'learning_rate': 1.0000000000000002e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.53125, 'reward_std': 0.8609456717967987, 'completion_length': 309.625, 'kl': 0.00039563408063258976, 'epoch': 0.15}
  2%|‚ñè         | 11/500 [14:13<10:06:29, 74.42s/it]  2%|‚ñè         | 12/500 [15:36<10:28:39, 77.29s/it]                                                   {'loss': 0.0, 'grad_norm': 0.7489127516746521, 'learning_rate': 1.1e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.453125, 'reward': 1.828125, 'reward_std': 1.0474944412708282, 'completion_length': 290.9375, 'kl': 0.00038836968451505527, 'epoch': 0.16}
  2%|‚ñè         | 12/500 [15:36<10:28:39, 77.29s/it]  3%|‚ñé         | 13/500 [16:45<10:05:23, 74.59s/it]                                                   {'loss': 0.0, 'grad_norm': 0.8920502662658691, 'learning_rate': 1.2000000000000002e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.390625, 'reward': 1.734375, 'reward_std': 1.1636907160282135, 'completion_length': 273.1875, 'kl': 0.0004472505170269869, 'epoch': 0.17}
  3%|‚ñé         | 13/500 [16:45<10:05:23, 74.59s/it]  3%|‚ñé         | 14/500 [18:03<10:13:09, 75.70s/it]                                                   {'loss': 0.0, 'grad_norm': 0.813386857509613, 'learning_rate': 1.3e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.390625, 'reward': 1.640625, 'reward_std': 1.1413123458623886, 'completion_length': 272.4375, 'kl': 0.0003947603399865329, 'epoch': 0.19}
  3%|‚ñé         | 14/500 [18:03<10:13:09, 75.70s/it]  3%|‚ñé         | 15/500 [19:39<11:01:40, 81.86s/it]                                                   {'loss': 0.0, 'grad_norm': 0.7845509648323059, 'learning_rate': 1.4000000000000001e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.84375, 'reward_std': 1.0787444412708282, 'completion_length': 318.3125, 'kl': 0.0003563157151802443, 'epoch': 0.2}
  3%|‚ñé         | 15/500 [19:39<11:01:40, 81.86s/it]  3%|‚ñé         | 16/500 [20:34<9:55:35, 73.83s/it]                                                   {'loss': 0.0, 'grad_norm': 1.0030901432037354, 'learning_rate': 1.5e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.90625, 'reward_std': 0.915751576423645, 'completion_length': 237.5625, 'kl': 0.0003307928636786528, 'epoch': 0.21}
  3%|‚ñé         | 16/500 [20:34<9:55:35, 73.83s/it]  3%|‚ñé         | 17/500 [21:38<9:28:42, 70.65s/it]                                                  {'loss': 0.0, 'grad_norm': 0.7153223752975464, 'learning_rate': 1.6000000000000001e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.53125, 'reward_std': 0.8807254433631897, 'completion_length': 263.5, 'kl': 0.00047078563511604443, 'epoch': 0.23}
  3%|‚ñé         | 17/500 [21:38<9:28:42, 70.65s/it]  4%|‚ñé         | 18/500 [22:44<9:18:27, 69.52s/it]                                                  {'loss': 0.0, 'grad_norm': 0.9906181693077087, 'learning_rate': 1.7000000000000002e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.4375, 'rewards/cot_format_reward_func': 0.40625, 'reward': 1.59375, 'reward_std': 0.95472851395607, 'completion_length': 259.8125, 'kl': 0.00038883679371792823, 'epoch': 0.24}
  4%|‚ñé         | 18/500 [22:44<9:18:27, 69.52s/it]  4%|‚ñç         | 19/500 [23:51<9:08:56, 68.47s/it]                                                  {'loss': 0.0, 'grad_norm': 0.9238780736923218, 'learning_rate': 1.8000000000000001e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.90625, 'reward_std': 1.2037444412708282, 'completion_length': 242.1875, 'kl': 0.0004205201257718727, 'epoch': 0.25}
  4%|‚ñç         | 19/500 [23:51<9:08:56, 68.47s/it]  4%|‚ñç         | 20/500 [24:57<9:04:02, 68.00s/it]                                                  {'loss': 0.0, 'grad_norm': 0.7204322814941406, 'learning_rate': 1.9000000000000002e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.46875, 'reward_std': 0.8287444412708282, 'completion_length': 244.1875, 'kl': 0.0003257103599025868, 'epoch': 0.27}
  4%|‚ñç         | 20/500 [24:57<9:04:02, 68.00s/it]  4%|‚ñç         | 21/500 [25:52<8:30:23, 63.93s/it]                                                  {'loss': 0.0, 'grad_norm': 0.9508869647979736, 'learning_rate': 2.0000000000000003e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.4375, 'rewards/cot_format_reward_func': 0.40625, 'reward': 1.34375, 'reward_std': 1.130722850561142, 'completion_length': 240.75, 'kl': 0.00037439689185703173, 'epoch': 0.28}
  4%|‚ñç         | 21/500 [25:52<8:30:23, 63.93s/it]  4%|‚ñç         | 22/500 [27:19<9:24:22, 70.84s/it]                                                  {'loss': 0.0, 'grad_norm': 1.2216708660125732, 'learning_rate': 2.1000000000000002e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.40625, 'rewards/cot_format_reward_func': 0.28125, 'reward': 1.4375, 'reward_std': 1.103939712047577, 'completion_length': 289.875, 'kl': 0.00043559676851145923, 'epoch': 0.29}
  4%|‚ñç         | 22/500 [27:19<9:24:22, 70.84s/it]  5%|‚ñç         | 23/500 [29:07<10:51:40, 81.97s/it]                                                   {'loss': 0.0, 'grad_norm': 0.9041067361831665, 'learning_rate': 2.2e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.4375, 'rewards/cot_format_reward_func': 0.375, 'reward': 1.5625, 'reward_std': 1.2695890367031097, 'completion_length': 323.3125, 'kl': 0.00047888688277453184, 'epoch': 0.31}
  5%|‚ñç         | 23/500 [29:07<10:51:40, 81.97s/it]  5%|‚ñç         | 24/500 [30:05<9:53:33, 74.82s/it]                                                   {'loss': 0.0, 'grad_norm': 0.8407300710678101, 'learning_rate': 2.3000000000000004e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.734375, 'reward_std': 1.0894283056259155, 'completion_length': 254.5, 'kl': 0.00039260019548237324, 'epoch': 0.32}
  5%|‚ñç         | 24/500 [30:05<9:53:33, 74.82s/it]  5%|‚ñå         | 25/500 [31:22<9:57:57, 75.53s/it]                                                  {'loss': 0.0, 'grad_norm': 0.7744876742362976, 'learning_rate': 2.4000000000000003e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.8125, 'reward_std': 1.1108438968658447, 'completion_length': 280.6875, 'kl': 0.00032708345679566264, 'epoch': 0.33}
  5%|‚ñå         | 25/500 [31:22<9:57:57, 75.53s/it]  5%|‚ñå         | 26/500 [33:32<12:06:37, 91.98s/it]                                                   {'loss': 0.0, 'grad_norm': 0.9187041521072388, 'learning_rate': 2.5e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.84375, 'reward_std': 1.0658445954322815, 'completion_length': 410.625, 'kl': 0.0004512648083618842, 'epoch': 0.35}
  5%|‚ñå         | 26/500 [33:32<12:06:37, 91.98s/it]  5%|‚ñå         | 27/500 [35:15<12:30:51, 95.25s/it]                                                   {'loss': 0.0, 'grad_norm': 0.8240317702293396, 'learning_rate': 2.6e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.65625, 'reward_std': 1.1908445954322815, 'completion_length': 365.125, 'kl': 0.000414409652876202, 'epoch': 0.36}
  5%|‚ñå         | 27/500 [35:15<12:30:51, 95.25s/it]  6%|‚ñå         | 28/500 [36:58<12:47:22, 97.55s/it]                                                   {'loss': 0.0, 'grad_norm': 0.7893427610397339, 'learning_rate': 2.7000000000000004e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.421875, 'reward': 1.546875, 'reward_std': 0.8370086625218391, 'completion_length': 396.1875, 'kl': 0.00041890706052072346, 'epoch': 0.37}
  6%|‚ñå         | 28/500 [36:58<12:47:22, 97.55s/it]  6%|‚ñå         | 29/500 [38:25<12:20:53, 94.38s/it]                                                   {'loss': 0.0, 'grad_norm': 0.74893718957901, 'learning_rate': 2.8000000000000003e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.375, 'reward': 1.46875, 'reward_std': 1.1908803880214691, 'completion_length': 366.75, 'kl': 0.0004116477430216037, 'epoch': 0.39}
  6%|‚ñå         | 29/500 [38:25<12:20:53, 94.38s/it]  6%|‚ñå         | 30/500 [41:30<15:50:53, 121.39s/it]                                                    {'loss': 0.0, 'grad_norm': 0.664715588092804, 'learning_rate': 2.9e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.40625, 'reward': 1.53125, 'reward_std': 0.8989385366439819, 'completion_length': 510.3125, 'kl': 0.00038517717621289194, 'epoch': 0.4}
  6%|‚ñå         | 30/500 [41:30<15:50:53, 121.39s/it]  6%|‚ñå         | 31/500 [42:51<14:16:03, 109.52s/it]                                                    {'loss': 0.0, 'grad_norm': 0.6585142016410828, 'learning_rate': 3e-06, 'rewards/cot_correctness_reward_func': 0.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.34375, 'reward_std': 0.7771694660186768, 'completion_length': 353.0, 'kl': 0.00034451127430656925, 'epoch': 0.41}
  6%|‚ñå         | 31/500 [42:51<14:16:03, 109.52s/it]  6%|‚ñã         | 32/500 [44:10<13:01:24, 100.18s/it]                                                    {'loss': 0.0, 'grad_norm': 0.6173218488693237, 'learning_rate': 3.1000000000000004e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.453125, 'reward': 1.546875, 'reward_std': 0.9110283851623535, 'completion_length': 366.0625, 'kl': 0.00038755406421842054, 'epoch': 0.43}
  6%|‚ñã         | 32/500 [44:10<13:01:24, 100.18s/it]  7%|‚ñã         | 33/500 [45:35<12:24:30, 95.65s/it]                                                    {'loss': 0.0, 'grad_norm': 0.7529407739639282, 'learning_rate': 3.2000000000000003e-06, 'rewards/cot_correctness_reward_func': 0.375, 'rewards/cot_letter_reward_func': 0.4375, 'rewards/cot_format_reward_func': 0.34375, 'reward': 1.15625, 'reward_std': 0.9091904163360596, 'completion_length': 376.0625, 'kl': 0.0004229304104228504, 'epoch': 0.44}
  7%|‚ñã         | 33/500 [45:35<12:24:30, 95.65s/it]  7%|‚ñã         | 34/500 [46:40<11:12:43, 86.62s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6960551142692566, 'learning_rate': 3.3000000000000006e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.96875, 'reward_std': 1.1045197248458862, 'completion_length': 307.6875, 'kl': 0.00032675289548933506, 'epoch': 0.45}
  7%|‚ñã         | 34/500 [46:40<11:12:43, 86.62s/it]  7%|‚ñã         | 35/500 [48:32<12:10:11, 94.22s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6366772055625916, 'learning_rate': 3.4000000000000005e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.6875, 'reward_std': 0.8783445954322815, 'completion_length': 385.6875, 'kl': 0.00040576594619778916, 'epoch': 0.47}
  7%|‚ñã         | 35/500 [48:32<12:10:11, 94.22s/it]  7%|‚ñã         | 36/500 [49:50<11:29:49, 89.20s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6830769777297974, 'learning_rate': 3.5e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.9375, 'reward_std': 1.0911408960819244, 'completion_length': 353.0, 'kl': 0.0003660952716018073, 'epoch': 0.48}
  7%|‚ñã         | 36/500 [49:50<11:29:49, 89.20s/it]  7%|‚ñã         | 37/500 [51:21<11:32:12, 89.70s/it]                                                   {'loss': 0.0, 'grad_norm': 0.784756600856781, 'learning_rate': 3.6000000000000003e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.375, 'reward': 1.625, 'reward_std': 0.9634132236242294, 'completion_length': 383.6875, 'kl': 0.00048501604032935575, 'epoch': 0.49}
  7%|‚ñã         | 37/500 [51:21<11:32:12, 89.70s/it]  8%|‚ñä         | 38/500 [52:53<11:36:57, 90.51s/it]                                                   {'loss': 0.0, 'grad_norm': 0.8934058547019958, 'learning_rate': 3.7e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.375, 'reward': 1.5, 'reward_std': 1.1602528393268585, 'completion_length': 372.25, 'kl': 0.00045070176565786824, 'epoch': 0.51}
  8%|‚ñä         | 38/500 [52:53<11:36:57, 90.51s/it]  8%|‚ñä         | 39/500 [54:30<11:49:18, 92.32s/it]                                                   {'loss': 0.0, 'grad_norm': 0.8460521101951599, 'learning_rate': 3.8000000000000005e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.65625, 'reward_std': 0.9408445954322815, 'completion_length': 375.875, 'kl': 0.00044597534724744037, 'epoch': 0.52}
  8%|‚ñä         | 39/500 [54:30<11:49:18, 92.32s/it]  8%|‚ñä         | 40/500 [55:41<10:59:31, 86.03s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6867201328277588, 'learning_rate': 3.900000000000001e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.4375, 'reward_std': 0.5719172433018684, 'completion_length': 335.9375, 'kl': 0.000380959827452898, 'epoch': 0.53}
  8%|‚ñä         | 40/500 [55:41<10:59:31, 86.03s/it]  8%|‚ñä         | 41/500 [57:01<10:45:01, 84.32s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6144216060638428, 'learning_rate': 4.000000000000001e-06, 'rewards/cot_correctness_reward_func': 0.375, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.40625, 'reward': 1.25, 'reward_std': 0.6971687823534012, 'completion_length': 352.3125, 'kl': 0.0003694391853059642, 'epoch': 0.55}
  8%|‚ñä         | 41/500 [57:01<10:45:01, 84.32s/it]  8%|‚ñä         | 42/500 [59:00<12:01:05, 94.47s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5625879168510437, 'learning_rate': 4.1e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.421875, 'reward': 1.421875, 'reward_std': 0.8679919540882111, 'completion_length': 457.625, 'kl': 0.00043933109554927796, 'epoch': 0.56}
  8%|‚ñä         | 42/500 [59:00<12:01:05, 94.47s/it]  9%|‚ñä         | 43/500 [1:01:55<15:04:17, 118.72s/it]                                                      {'loss': 0.0, 'grad_norm': 0.6654633283615112, 'learning_rate': 4.2000000000000004e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.453125, 'reward': 1.453125, 'reward_std': 0.8470945954322815, 'completion_length': 500.4375, 'kl': 0.00034509956458350644, 'epoch': 0.57}
  9%|‚ñä         | 43/500 [1:01:55<15:04:17, 118.72s/it]  9%|‚ñâ         | 44/500 [1:03:23<13:52:04, 109.48s/it]                                                      {'loss': 0.0, 'grad_norm': 0.6386255025863647, 'learning_rate': 4.3e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 0.8273502588272095, 'completion_length': 345.125, 'kl': 0.0003930690072593279, 'epoch': 0.59}
  9%|‚ñâ         | 44/500 [1:03:23<13:52:04, 109.48s/it]  9%|‚ñâ         | 45/500 [1:04:38<12:32:33, 99.24s/it]                                                      {'loss': 0.0, 'grad_norm': 0.7734380960464478, 'learning_rate': 4.4e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 1.0386751294136047, 'completion_length': 336.5625, 'kl': 0.00043581089266808704, 'epoch': 0.6}
  9%|‚ñâ         | 45/500 [1:04:38<12:32:33, 99.24s/it]  9%|‚ñâ         | 46/500 [1:06:20<12:37:30, 100.11s/it]                                                      {'loss': 0.0, 'grad_norm': 0.8720278739929199, 'learning_rate': 4.5e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.375, 'reward': 1.625, 'reward_std': 0.9540545418858528, 'completion_length': 405.3125, 'kl': 0.0005382321396609768, 'epoch': 0.61}
  9%|‚ñâ         | 46/500 [1:06:20<12:37:30, 100.11s/it]  9%|‚ñâ         | 47/500 [1:08:16<13:11:07, 104.78s/it]                                                      {'loss': 0.0, 'grad_norm': 0.6634202003479004, 'learning_rate': 4.600000000000001e-06, 'rewards/cot_correctness_reward_func': 0.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.3125, 'reward_std': 0.6412444412708282, 'completion_length': 408.625, 'kl': 0.0004046634421683848, 'epoch': 0.63}
  9%|‚ñâ         | 47/500 [1:08:16<13:11:07, 104.78s/it] 10%|‚ñâ         | 48/500 [1:10:28<14:11:19, 113.01s/it]                                                      {'loss': 0.0, 'grad_norm': 0.64056396484375, 'learning_rate': 4.7e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.390625, 'reward': 1.515625, 'reward_std': 0.6165667623281479, 'completion_length': 454.3125, 'kl': 0.0004154784182901494, 'epoch': 0.64}
 10%|‚ñâ         | 48/500 [1:10:28<14:11:19, 113.01s/it] 10%|‚ñâ         | 49/500 [1:11:44<12:45:33, 101.85s/it]                                                      {'loss': 0.0, 'grad_norm': 0.5975114703178406, 'learning_rate': 4.800000000000001e-06, 'rewards/cot_correctness_reward_func': 0.25, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.1875, 'reward_std': 0.625, 'completion_length': 336.1875, 'kl': 0.0003890248408424668, 'epoch': 0.65}
 10%|‚ñâ         | 49/500 [1:11:44<12:45:33, 101.85s/it] 10%|‚ñà         | 50/500 [1:12:58<11:40:29, 93.40s/it]                                                      {'loss': 0.0, 'grad_norm': 0.8322202563285828, 'learning_rate': 4.9000000000000005e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.421875, 'reward': 1.421875, 'reward_std': 0.872921958565712, 'completion_length': 333.1875, 'kl': 0.0004148942025494762, 'epoch': 0.67}
 10%|‚ñà         | 50/500 [1:12:58<11:40:29, 93.40s/it] 10%|‚ñà         | 51/500 [1:14:32<11:41:32, 93.75s/it]                                                     {'loss': 0.0, 'grad_norm': 0.8753995895385742, 'learning_rate': 5e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.40625, 'rewards/cot_format_reward_func': 0.359375, 'reward': 1.265625, 'reward_std': 1.1286316215991974, 'completion_length': 357.625, 'kl': 0.0004988363652955741, 'epoch': 0.68}
 10%|‚ñà         | 51/500 [1:14:32<11:41:32, 93.75s/it] 10%|‚ñà         | 52/500 [1:16:05<11:36:58, 93.34s/it]                                                     {'loss': 0.0, 'grad_norm': 0.7534237504005432, 'learning_rate': 4.999939076763487e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.40625, 'reward': 1.625, 'reward_std': 1.2180140614509583, 'completion_length': 351.1875, 'kl': 0.0003702409958350472, 'epoch': 0.69}
 10%|‚ñà         | 52/500 [1:16:05<11:36:58, 93.34s/it] 11%|‚ñà         | 53/500 [1:17:44<11:48:36, 95.11s/it]                                                     {'loss': 0.0, 'grad_norm': 0.7152733206748962, 'learning_rate': 4.999756310023261e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.71875, 'reward_std': 1.0271694660186768, 'completion_length': 377.9375, 'kl': 0.00045768222480546683, 'epoch': 0.71}
 11%|‚ñà         | 53/500 [1:17:44<11:48:36, 95.11s/it] 11%|‚ñà         | 54/500 [1:20:56<15:24:19, 124.35s/it]                                                      {'loss': 0.0, 'grad_norm': 0.6854797005653381, 'learning_rate': 4.999451708687114e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.375, 'reward': 1.71875, 'reward_std': 1.109827235341072, 'completion_length': 517.5625, 'kl': 0.00037838847492821515, 'epoch': 0.72}
 11%|‚ñà         | 54/500 [1:20:56<15:24:19, 124.35s/it] 11%|‚ñà         | 55/500 [1:22:40<14:37:07, 118.26s/it]                                                      {'loss': 0.0, 'grad_norm': 0.813164234161377, 'learning_rate': 4.999025287600886e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.40625, 'reward': 1.78125, 'reward_std': 0.8634346574544907, 'completion_length': 407.0, 'kl': 0.0004523869283730164, 'epoch': 0.73}
 11%|‚ñà         | 55/500 [1:22:40<14:37:07, 118.26s/it] 11%|‚ñà         | 56/500 [1:23:57<13:02:40, 105.77s/it]                                                      {'loss': 0.0, 'grad_norm': 0.7807551026344299, 'learning_rate': 4.99847706754774e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.40625, 'reward': 1.625, 'reward_std': 1.1263704001903534, 'completion_length': 322.1875, 'kl': 0.000492758110340219, 'epoch': 0.75}
 11%|‚ñà         | 56/500 [1:23:57<13:02:40, 105.77s/it] 11%|‚ñà‚ñè        | 57/500 [1:25:32<12:36:03, 102.40s/it]                                                      {'loss': 0.0, 'grad_norm': 0.8441243171691895, 'learning_rate': 4.997807075247147e-06, 'rewards/cot_correctness_reward_func': 0.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.375, 'reward': 1.25, 'reward_std': 0.8940083980560303, 'completion_length': 395.0625, 'kl': 0.0004039656341774389, 'epoch': 0.76}
 11%|‚ñà‚ñè        | 57/500 [1:25:32<12:36:03, 102.40s/it] 12%|‚ñà‚ñè        | 58/500 [1:27:14<12:33:17, 102.26s/it]                                                      {'loss': 0.0, 'grad_norm': 0.7291355729103088, 'learning_rate': 4.9970153433535855e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.59375, 'reward_std': 1.0658445954322815, 'completion_length': 398.375, 'kl': 0.00044627918396145105, 'epoch': 0.77}
 12%|‚ñà‚ñè        | 58/500 [1:27:14<12:33:17, 102.26s/it] 12%|‚ñà‚ñè        | 59/500 [1:28:32<11:39:22, 95.15s/it]                                                      {'loss': 0.0, 'grad_norm': 0.7261171936988831, 'learning_rate': 4.996101910454953e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.421875, 'reward': 1.515625, 'reward_std': 0.832192063331604, 'completion_length': 331.0625, 'kl': 0.0005193099423195235, 'epoch': 0.79}
 12%|‚ñà‚ñè        | 59/500 [1:28:32<11:39:22, 95.15s/it] 12%|‚ñà‚ñè        | 60/500 [1:29:52<11:05:03, 90.69s/it]                                                     {'loss': 0.0, 'grad_norm': 0.7037464380264282, 'learning_rate': 4.9950668210706795e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.421875, 'reward': 1.671875, 'reward_std': 0.864586591720581, 'completion_length': 345.6875, 'kl': 0.0004991430032532662, 'epoch': 0.8}
 12%|‚ñà‚ñè        | 60/500 [1:29:52<11:05:03, 90.69s/it] 12%|‚ñà‚ñè        | 61/500 [1:30:32<9:11:59, 75.44s/it]                                                     {'loss': 0.0, 'grad_norm': 1.3696411848068237, 'learning_rate': 4.993910125649561e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.8125, 'reward_std': 1.1961640119552612, 'completion_length': 150.6875, 'kl': 0.0005667232107953168, 'epoch': 0.81}
 12%|‚ñà‚ñè        | 61/500 [1:30:32<9:11:59, 75.44s/it] 12%|‚ñà‚ñè        | 62/500 [1:31:12<7:51:35, 64.60s/it]                                                    {'loss': 0.0, 'grad_norm': 0.8664859533309937, 'learning_rate': 4.992631880567301e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.4375, 'reward': 2.15625, 'reward_std': 0.875, 'completion_length': 151.875, 'kl': 0.00042187782673863694, 'epoch': 0.83}
 12%|‚ñà‚ñè        | 62/500 [1:31:12<7:51:35, 64.60s/it] 13%|‚ñà‚ñé        | 63/500 [1:31:46<6:44:43, 55.57s/it]                                                    {'loss': 0.0, 'grad_norm': 1.1303592920303345, 'learning_rate': 4.9912321481237616e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.421875, 'reward': 1.890625, 'reward_std': 1.138298660516739, 'completion_length': 146.3125, 'kl': 0.0005736470120609738, 'epoch': 0.84}
 13%|‚ñà‚ñé        | 63/500 [1:31:46<6:44:43, 55.57s/it] 13%|‚ñà‚ñé        | 64/500 [1:32:36<6:31:30, 53.88s/it]                                                    {'loss': 0.0, 'grad_norm': 1.052783489227295, 'learning_rate': 4.989710996539926e-06, 'rewards/cot_correctness_reward_func': 1.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.421875, 'reward': 2.421875, 'reward_std': 1.0405092984437943, 'completion_length': 167.0, 'kl': 0.00046168545668479055, 'epoch': 0.85}
 13%|‚ñà‚ñé        | 64/500 [1:32:36<6:31:30, 53.88s/it] 13%|‚ñà‚ñé        | 65/500 [1:33:12<5:52:17, 48.59s/it]                                                    {'loss': 0.0, 'grad_norm': 1.2740329504013062, 'learning_rate': 4.988068499954578e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.390625, 'reward': 1.890625, 'reward_std': 0.9299846291542053, 'completion_length': 143.0625, 'kl': 0.000661302576190792, 'epoch': 0.87}
 13%|‚ñà‚ñé        | 65/500 [1:33:12<5:52:17, 48.59s/it] 13%|‚ñà‚ñé        | 66/500 [1:33:50<5:28:55, 45.47s/it]                                                    {'loss': 0.0, 'grad_norm': 1.1030982732772827, 'learning_rate': 4.986304738420684e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.359375, 'reward': 2.078125, 'reward_std': 0.909479945898056, 'completion_length': 149.9375, 'kl': 0.0007176637955126353, 'epoch': 0.88}
 13%|‚ñà‚ñé        | 66/500 [1:33:50<5:28:55, 45.47s/it] 13%|‚ñà‚ñé        | 67/500 [1:34:21<4:56:39, 41.11s/it]                                                    {'loss': 0.0, 'grad_norm': 1.554518222808838, 'learning_rate': 4.984419797901491e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.453125, 'reward': 2.078125, 'reward_std': 0.7961002588272095, 'completion_length': 124.375, 'kl': 0.0005250209651421756, 'epoch': 0.89}
 13%|‚ñà‚ñé        | 67/500 [1:34:21<4:56:39, 41.11s/it] 14%|‚ñà‚ñé        | 68/500 [1:34:57<4:43:26, 39.37s/it]                                                    {'loss': 0.0, 'grad_norm': 1.2439345121383667, 'learning_rate': 4.9824137702663424e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.359375, 'reward': 2.203125, 'reward_std': 0.9573773145675659, 'completion_length': 138.6875, 'kl': 0.0007132189348340034, 'epoch': 0.91}
 14%|‚ñà‚ñé        | 68/500 [1:34:57<4:43:26, 39.37s/it] 14%|‚ñà‚ñç        | 69/500 [1:35:35<4:40:04, 38.99s/it]                                                    {'loss': 0.0, 'grad_norm': 0.9530770182609558, 'learning_rate': 4.980286753286196e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.390625, 'reward': 2.265625, 'reward_std': 1.0754607766866684, 'completion_length': 152.5, 'kl': 0.0007034844747977331, 'epoch': 0.92}
 14%|‚ñà‚ñç        | 69/500 [1:35:35<4:40:04, 38.99s/it] 14%|‚ñà‚ñç        | 70/500 [1:36:16<4:45:05, 39.78s/it]                                                    {'loss': 0.0, 'grad_norm': 1.0238145589828491, 'learning_rate': 4.978038850628855e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.9375, 'reward_std': 0.5498075932264328, 'completion_length': 157.125, 'kl': 0.0005964096344541758, 'epoch': 0.93}
 14%|‚ñà‚ñç        | 70/500 [1:36:16<4:45:05, 39.78s/it] 14%|‚ñà‚ñç        | 71/500 [1:36:58<4:48:00, 40.28s/it]                                                    {'loss': 0.0, 'grad_norm': 1.189540982246399, 'learning_rate': 4.975670171853926e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.390625, 'reward': 2.140625, 'reward_std': 0.9192633628845215, 'completion_length': 147.375, 'kl': 0.0007461405912181363, 'epoch': 0.95}
 14%|‚ñà‚ñç        | 71/500 [1:36:58<4:48:00, 40.28s/it] 14%|‚ñà‚ñç        | 72/500 [1:37:33<4:36:34, 38.77s/it]                                                    {'loss': 0.0, 'grad_norm': 1.29328453540802, 'learning_rate': 4.973180832407471e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.40625, 'reward': 1.75, 'reward_std': 0.8816685974597931, 'completion_length': 139.5625, 'kl': 0.0007661109993932769, 'epoch': 0.96}
 14%|‚ñà‚ñç        | 72/500 [1:37:33<4:36:34, 38.77s/it] 15%|‚ñà‚ñç        | 73/500 [1:38:10<4:32:29, 38.29s/it]                                                    {'loss': 0.0, 'grad_norm': 1.2256131172180176, 'learning_rate': 4.970570953616383e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.453125, 'reward': 1.796875, 'reward_std': 1.1997035145759583, 'completion_length': 140.875, 'kl': 0.0007448549731634557, 'epoch': 0.97}
 15%|‚ñà‚ñç        | 73/500 [1:38:10<4:32:29, 38.29s/it] 15%|‚ñà‚ñç        | 74/500 [1:38:57<4:49:41, 40.80s/it]                                                    {'loss': 0.0, 'grad_norm': 1.1509703397750854, 'learning_rate': 4.96784066268247e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.40625, 'reward': 1.78125, 'reward_std': 1.113404095172882, 'completion_length': 151.1875, 'kl': 0.0007304336249944754, 'epoch': 0.99}
 15%|‚ñà‚ñç        | 74/500 [1:38:57<4:49:41, 40.80s/it] 15%|‚ñà‚ñå        | 75/500 [1:39:32<4:37:12, 39.13s/it]                                                    {'loss': 0.0, 'grad_norm': 1.2812458276748657, 'learning_rate': 4.964990092676263e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.4375, 'rewards/cot_format_reward_func': 0.375, 'reward': 1.5625, 'reward_std': 1.2244400084018707, 'completion_length': 144.6875, 'kl': 0.000990586617263034, 'epoch': 1.0}
 15%|‚ñà‚ñå        | 75/500 [1:39:32<4:37:12, 39.13s/it] 15%|‚ñà‚ñå        | 76/500 [1:40:47<5:52:47, 49.92s/it]                                                    {'loss': 0.0, 'grad_norm': 0.9263181090354919, 'learning_rate': 4.962019382530521e-06, 'rewards/cot_correctness_reward_func': 0.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.34375, 'reward_std': 0.7771694660186768, 'completion_length': 290.125, 'kl': 0.0006859400309622288, 'epoch': 1.01}
 15%|‚ñà‚ñå        | 76/500 [1:40:47<5:52:47, 49.92s/it] 15%|‚ñà‚ñå        | 77/500 [1:43:05<8:57:57, 76.31s/it]                                                    {'loss': 0.0, 'grad_norm': 0.8526313900947571, 'learning_rate': 4.958928677033465e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.4375, 'reward_std': 0.8783445954322815, 'completion_length': 368.6875, 'kl': 0.0006045901100151241, 'epoch': 1.03}
 15%|‚ñà‚ñå        | 77/500 [1:43:05<8:57:57, 76.31s/it] 16%|‚ñà‚ñå        | 78/500 [1:43:59<8:08:27, 69.45s/it]                                                    {'loss': 0.0, 'grad_norm': 0.921528160572052, 'learning_rate': 4.9557181268217225e-06, 'rewards/cot_correctness_reward_func': 0.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.453125, 'reward': 1.328125, 'reward_std': 0.8084194660186768, 'completion_length': 252.0, 'kl': 0.0007744736794847995, 'epoch': 1.04}
 16%|‚ñà‚ñå        | 78/500 [1:43:59<8:08:27, 69.45s/it] 16%|‚ñà‚ñå        | 79/500 [1:45:00<7:50:31, 67.06s/it]                                                    {'loss': 0.0, 'grad_norm': 0.991278886795044, 'learning_rate': 4.9523878883729794e-06, 'rewards/cot_correctness_reward_func': 0.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.3125, 'reward_std': 0.6636751294136047, 'completion_length': 243.5, 'kl': 0.0009245731198461726, 'epoch': 1.05}
 16%|‚ñà‚ñå        | 79/500 [1:45:00<7:50:31, 67.06s/it] 16%|‚ñà‚ñå        | 80/500 [1:45:58<7:30:32, 64.36s/it]                                                    {'loss': 0.0, 'grad_norm': 1.0157793760299683, 'learning_rate': 4.94893812399836e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.84375, 'reward_std': 1.0076940953731537, 'completion_length': 233.0625, 'kl': 0.0011171925434609875, 'epoch': 1.07}
 16%|‚ñà‚ñå        | 80/500 [1:45:58<7:30:32, 64.36s/it] 16%|‚ñà‚ñå        | 81/500 [1:47:00<7:23:30, 63.51s/it]                                                    {'loss': 0.0, 'grad_norm': 0.9012627005577087, 'learning_rate': 4.9453690018345144e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.4375, 'rewards/cot_format_reward_func': 0.40625, 'reward': 1.46875, 'reward_std': 0.9091878235340118, 'completion_length': 270.75, 'kl': 0.0010748027852969244, 'epoch': 1.08}
 16%|‚ñà‚ñå        | 81/500 [1:47:00<7:23:30, 63.51s/it] 16%|‚ñà‚ñã        | 82/500 [1:47:55<7:05:56, 61.14s/it]                                                    {'loss': 0.0001, 'grad_norm': 0.9911438822746277, 'learning_rate': 4.9416806958354206e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.4375, 'rewards/cot_format_reward_func': 0.390625, 'reward': 1.453125, 'reward_std': 1.203670173883438, 'completion_length': 239.375, 'kl': 0.0016035213047871366, 'epoch': 1.09}
 16%|‚ñà‚ñã        | 82/500 [1:47:55<7:05:56, 61.14s/it] 17%|‚ñà‚ñã        | 83/500 [1:48:57<7:05:55, 61.28s/it]                                                    {'loss': 0.0, 'grad_norm': 0.867488443851471, 'learning_rate': 4.937873385763909e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.453125, 'reward': 1.546875, 'reward_std': 1.072001576423645, 'completion_length': 257.3125, 'kl': 0.0009787821036297828, 'epoch': 1.11}
 17%|‚ñà‚ñã        | 83/500 [1:48:57<7:05:55, 61.28s/it] 17%|‚ñà‚ñã        | 84/500 [1:49:57<7:01:26, 60.78s/it]                                                    {'loss': 0.0, 'grad_norm': 0.8369776606559753, 'learning_rate': 4.933947257182901e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.4375, 'rewards/cot_format_reward_func': 0.40625, 'reward': 1.34375, 'reward_std': 1.1563223600387573, 'completion_length': 233.25, 'kl': 0.001016613852698356, 'epoch': 1.12}
 17%|‚ñà‚ñã        | 84/500 [1:49:57<7:01:26, 60.78s/it] 17%|‚ñà‚ñã        | 85/500 [1:50:54<6:53:23, 59.77s/it]                                                    {'loss': 0.0, 'grad_norm': 0.9536725282669067, 'learning_rate': 4.9299025014463665e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.078125, 'reward_std': 1.1324251294136047, 'completion_length': 229.625, 'kl': 0.0010746206971816719, 'epoch': 1.13}
 17%|‚ñà‚ñã        | 85/500 [1:50:54<6:53:23, 59.77s/it] 17%|‚ñà‚ñã        | 86/500 [1:52:21<7:48:01, 67.83s/it]                                                    {'loss': 0.0, 'grad_norm': 0.5923147797584534, 'learning_rate': 4.925739315689991e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.59375, 'reward_std': 0.3125, 'completion_length': 297.125, 'kl': 0.00100838924117852, 'epoch': 1.15}
 17%|‚ñà‚ñã        | 86/500 [1:52:21<7:48:01, 67.83s/it] 17%|‚ñà‚ñã        | 87/500 [1:53:27<7:43:54, 67.40s/it]                                                    {'loss': 0.0, 'grad_norm': 0.9558581113815308, 'learning_rate': 4.921457902821578e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.71875, 'reward_std': 0.8511751294136047, 'completion_length': 257.8125, 'kl': 0.0012340570974629372, 'epoch': 1.16}
 17%|‚ñà‚ñã        | 87/500 [1:53:27<7:43:54, 67.40s/it] 18%|‚ñà‚ñä        | 88/500 [1:54:26<7:25:18, 64.85s/it]                                                    {'loss': 0.0, 'grad_norm': 0.9331994652748108, 'learning_rate': 4.917058471511149e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.96875, 'reward_std': 1.117419570684433, 'completion_length': 229.75, 'kl': 0.0011174280371051282, 'epoch': 1.17}
 18%|‚ñà‚ñä        | 88/500 [1:54:26<7:25:18, 64.85s/it] 18%|‚ñà‚ñä        | 89/500 [1:55:32<7:26:05, 65.12s/it]                                                    {'loss': 0.0001, 'grad_norm': 0.8837544918060303, 'learning_rate': 4.912541236180779e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.0625, 'reward_std': 0.8919267058372498, 'completion_length': 245.5625, 'kl': 0.0018117821600753814, 'epoch': 1.19}
 18%|‚ñà‚ñä        | 89/500 [1:55:32<7:26:05, 65.12s/it] 18%|‚ñà‚ñä        | 90/500 [1:56:45<7:42:39, 67.71s/it]                                                    {'loss': 0.0001, 'grad_norm': 0.9293813705444336, 'learning_rate': 4.907906416994146e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.484375, 'reward_std': 1.012078046798706, 'completion_length': 263.75, 'kl': 0.001301952259382233, 'epoch': 1.2}
 18%|‚ñà‚ñä        | 90/500 [1:56:45<7:42:39, 67.71s/it] 18%|‚ñà‚ñä        | 91/500 [1:57:44<7:23:21, 65.04s/it]                                                    {'loss': 0.0001, 'grad_norm': 0.8135733008384705, 'learning_rate': 4.903154239845798e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.40625, 'reward': 2.25, 'reward_std': 0.8636976182460785, 'completion_length': 254.8125, 'kl': 0.002009803065448068, 'epoch': 1.21}
 18%|‚ñà‚ñä        | 91/500 [1:57:44<7:23:21, 65.04s/it] 18%|‚ñà‚ñä        | 92/500 [1:58:31<6:45:51, 59.69s/it]                                                    {'loss': 0.0001, 'grad_norm': 0.7806301116943359, 'learning_rate': 4.898284936350144e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.859375, 'reward_std': 0.762078046798706, 'completion_length': 211.25, 'kl': 0.001696344232186675, 'epoch': 1.23}
 18%|‚ñà‚ñä        | 92/500 [1:58:31<6:45:51, 59.69s/it] 19%|‚ñà‚ñä        | 93/500 [1:59:29<6:40:28, 59.04s/it]                                                    {'loss': 0.0001, 'grad_norm': 1.0638370513916016, 'learning_rate': 4.893298743830168e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.40625, 'rewards/cot_format_reward_func': 0.34375, 'reward': 1.625, 'reward_std': 1.288926601409912, 'completion_length': 237.5, 'kl': 0.0025182039535138756, 'epoch': 1.24}
 19%|‚ñà‚ñä        | 93/500 [1:59:29<6:40:28, 59.04s/it] 19%|‚ñà‚ñâ        | 94/500 [2:00:24<6:31:06, 57.80s/it]                                                    {'loss': 0.0001, 'grad_norm': 1.0712343454360962, 'learning_rate': 4.888195905305859e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.8125, 'reward_std': 1.2023502588272095, 'completion_length': 237.0, 'kl': 0.002611414558487013, 'epoch': 1.25}
 19%|‚ñà‚ñâ        | 94/500 [2:00:24<6:31:06, 57.80s/it] 19%|‚ñà‚ñâ        | 95/500 [2:01:26<6:39:14, 59.15s/it]                                                    {'loss': 0.0001, 'grad_norm': 1.0128992795944214, 'learning_rate': 4.882976669482368e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.8125, 'reward_std': 1.1832641661167145, 'completion_length': 233.3125, 'kl': 0.0017825645918492228, 'epoch': 1.27}
 19%|‚ñà‚ñâ        | 95/500 [2:01:26<6:39:14, 59.15s/it] 19%|‚ñà‚ñâ        | 96/500 [2:02:28<6:43:59, 60.00s/it]                                                    {'loss': 0.0001, 'grad_norm': 0.7948888540267944, 'learning_rate': 4.8776412907378845e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.8125, 'reward_std': 1.125, 'completion_length': 255.5625, 'kl': 0.0014558172260876745, 'epoch': 1.28}
 19%|‚ñà‚ñâ        | 96/500 [2:02:28<6:43:59, 60.00s/it] 19%|‚ñà‚ñâ        | 97/500 [2:03:27<6:41:27, 59.77s/it]                                                    {'loss': 0.0001, 'grad_norm': 1.0158783197402954, 'learning_rate': 4.8721900291112415e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.5625, 'reward_std': 0.9523502588272095, 'completion_length': 238.3125, 'kl': 0.002006902708671987, 'epoch': 1.29}
 19%|‚ñà‚ñâ        | 97/500 [2:03:27<6:41:27, 59.77s/it] 20%|‚ñà‚ñâ        | 98/500 [2:04:15<6:16:42, 56.23s/it]                                                    {'loss': 0.0001, 'grad_norm': 0.9989728927612305, 'learning_rate': 4.866623150289241e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0773502588272095, 'completion_length': 210.9375, 'kl': 0.002133885456714779, 'epoch': 1.31}
 20%|‚ñà‚ñâ        | 98/500 [2:04:15<6:16:42, 56.23s/it] 20%|‚ñà‚ñâ        | 99/500 [2:05:07<6:05:53, 54.75s/it]                                                    {'loss': 0.0001, 'grad_norm': 0.9407914280891418, 'learning_rate': 4.860940925593703e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.84375, 'reward_std': 1.025296300649643, 'completion_length': 221.5, 'kl': 0.0025032619887497276, 'epoch': 1.32}
 20%|‚ñà‚ñâ        | 99/500 [2:05:07<6:05:53, 54.75s/it] 20%|‚ñà‚ñà        | 100/500 [2:06:09<6:20:50, 57.13s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.8261769413948059, 'learning_rate': 4.855143631968242e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.59375, 'reward_std': 1.0658445954322815, 'completion_length': 263.25, 'kl': 0.0021218821639195085, 'epoch': 1.33}
 20%|‚ñà‚ñà        | 100/500 [2:06:09<6:20:50, 57.13s/it] 20%|‚ñà‚ñà        | 101/500 [2:07:35<7:17:35, 65.80s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.8433735966682434, 'learning_rate': 4.849231551964771e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.78125, 'reward_std': 0.9761751294136047, 'completion_length': 341.75, 'kl': 0.0023296523140743375, 'epoch': 1.35}
 20%|‚ñà‚ñà        | 101/500 [2:07:35<7:17:35, 65.80s/it] 20%|‚ñà‚ñà        | 102/500 [2:08:41<7:17:09, 65.90s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.906691312789917, 'learning_rate': 4.84320497372973e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.84375, 'reward_std': 1.1560947000980377, 'completion_length': 300.875, 'kl': 0.003109487472102046, 'epoch': 1.36}
 20%|‚ñà‚ñà        | 102/500 [2:08:41<7:17:09, 65.90s/it] 21%|‚ñà‚ñà        | 103/500 [2:09:47<7:16:18, 65.94s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.9652667045593262, 'learning_rate': 4.837064190990036e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0, 'completion_length': 297.375, 'kl': 0.0022469321556854993, 'epoch': 1.37}
 21%|‚ñà‚ñà        | 103/500 [2:09:47<7:16:18, 65.94s/it] 21%|‚ñà‚ñà        | 104/500 [2:11:47<9:01:03, 81.98s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.7645816802978516, 'learning_rate': 4.830809503038781e-06, 'rewards/cot_correctness_reward_func': 0.125, 'rewards/cot_letter_reward_func': 0.4375, 'rewards/cot_format_reward_func': 0.390625, 'reward': 0.953125, 'reward_std': 0.48499444127082825, 'completion_length': 442.375, 'kl': 0.0028014204290229827, 'epoch': 1.39}
 21%|‚ñà‚ñà        | 104/500 [2:11:47<9:01:03, 81.98s/it] 21%|‚ñà‚ñà        | 105/500 [2:15:06<12:50:26, 117.03s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.7996048927307129, 'learning_rate': 4.824441214720629e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.375, 'reward': 1.375, 'reward_std': 1.108677864074707, 'completion_length': 529.375, 'kl': 0.0034115127637051046, 'epoch': 1.4}
 21%|‚ñà‚ñà        | 105/500 [2:15:06<12:50:26, 117.03s/it] 21%|‚ñà‚ñà        | 106/500 [2:16:31<11:45:55, 107.50s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.7695640921592712, 'learning_rate': 4.817959636416969e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 0.75, 'completion_length': 343.875, 'kl': 0.002643050567712635, 'epoch': 1.41}
 21%|‚ñà‚ñà        | 106/500 [2:16:31<11:45:55, 107.50s/it] 21%|‚ñà‚ñà‚ñè       | 107/500 [2:17:43<10:35:00, 96.95s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.8365020751953125, 'learning_rate': 4.811365084030784e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.59375, 'reward_std': 1.0076940953731537, 'completion_length': 317.4375, 'kl': 0.004277185071259737, 'epoch': 1.43}
 21%|‚ñà‚ñà‚ñè       | 107/500 [2:17:43<10:35:00, 96.95s/it] 22%|‚ñà‚ñà‚ñè       | 108/500 [2:19:09<10:10:28, 93.44s/it]                                                      {'loss': 0.0001, 'grad_norm': 0.7715508937835693, 'learning_rate': 4.804657878971252e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.71875, 'reward_std': 0.7576940953731537, 'completion_length': 344.125, 'kl': 0.003592646389734, 'epoch': 1.44}
 22%|‚ñà‚ñà‚ñè       | 108/500 [2:19:09<10:10:28, 93.44s/it] 22%|‚ñà‚ñà‚ñè       | 109/500 [2:20:33<9:51:30, 90.77s/it]                                                      {'loss': 0.0001, 'grad_norm': 0.668839693069458, 'learning_rate': 4.7978383481380865e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.7886751294136047, 'completion_length': 339.625, 'kl': 0.0024287595879286528, 'epoch': 1.45}
 22%|‚ñà‚ñà‚ñè       | 109/500 [2:20:33<9:51:30, 90.77s/it] 22%|‚ñà‚ñà‚ñè       | 110/500 [2:21:44<9:10:22, 84.67s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.9933278560638428, 'learning_rate': 4.790906823905599e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 293.5, 'kl': 0.003047457488719374, 'epoch': 1.47}
 22%|‚ñà‚ñà‚ñè       | 110/500 [2:21:44<9:10:22, 84.67s/it] 22%|‚ñà‚ñà‚ñè       | 111/500 [2:22:48<8:29:33, 78.60s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.0649359226226807, 'learning_rate': 4.783863644106502e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.984375, 'reward_std': 0.8199251294136047, 'completion_length': 296.875, 'kl': 0.004078669298905879, 'epoch': 1.48}
 22%|‚ñà‚ñà‚ñè       | 111/500 [2:22:48<8:29:33, 78.60s/it] 22%|‚ñà‚ñà‚ñè       | 112/500 [2:25:07<10:26:31, 96.89s/it]                                                      {'loss': 0.0001, 'grad_norm': 0.7874118685722351, 'learning_rate': 4.776709152015443e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.71875, 'reward_std': 0.9285253882408142, 'completion_length': 414.3125, 'kl': 0.002428043371764943, 'epoch': 1.49}
 22%|‚ñà‚ñà‚ñè       | 112/500 [2:25:07<10:26:31, 96.89s/it] 23%|‚ñà‚ñà‚ñé       | 113/500 [2:26:23<9:44:14, 90.58s/it]                                                      {'loss': 0.0001, 'grad_norm': 0.7095845341682434, 'learning_rate': 4.769443696332272e-06, 'rewards/cot_correctness_reward_func': 0.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.359375, 'reward_std': 0.28125, 'completion_length': 308.625, 'kl': 0.003651409293524921, 'epoch': 1.51}
 23%|‚ñà‚ñà‚ñé       | 113/500 [2:26:23<9:44:14, 90.58s/it] 23%|‚ñà‚ñà‚ñé       | 114/500 [2:27:42<9:19:54, 87.03s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.047328233718872, 'learning_rate': 4.762067631165049e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 0.75, 'completion_length': 326.4375, 'kl': 0.003843471233267337, 'epoch': 1.52}
 23%|‚ñà‚ñà‚ñé       | 114/500 [2:27:42<9:19:54, 87.03s/it] 23%|‚ñà‚ñà‚ñé       | 115/500 [2:29:27<9:52:22, 92.32s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8679497838020325, 'learning_rate': 4.754581316012785e-06, 'rewards/cot_correctness_reward_func': 0.375, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.359375, 'reward': 1.203125, 'reward_std': 0.7435611337423325, 'completion_length': 387.875, 'kl': 0.004948684654664248, 'epoch': 1.53}
 23%|‚ñà‚ñà‚ñé       | 115/500 [2:29:27<9:52:22, 92.32s/it] 23%|‚ñà‚ñà‚ñé       | 116/500 [2:31:05<10:01:30, 93.99s/it]                                                      {'loss': 0.0001, 'grad_norm': 0.9521797895431519, 'learning_rate': 4.746985115747918e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.78125, 'reward_std': 0.9761751294136047, 'completion_length': 345.6875, 'kl': 0.0037492731935344636, 'epoch': 1.55}
 23%|‚ñà‚ñà‚ñé       | 116/500 [2:31:05<10:01:30, 93.99s/it] 23%|‚ñà‚ñà‚ñé       | 117/500 [2:32:19<9:21:45, 88.00s/it]                                                      {'loss': 0.0001, 'grad_norm': 0.7923899292945862, 'learning_rate': 4.7392794005985324e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0773502588272095, 'completion_length': 324.6875, 'kl': 0.002831972436979413, 'epoch': 1.56}
 23%|‚ñà‚ñà‚ñé       | 117/500 [2:32:19<9:21:45, 88.00s/it] 24%|‚ñà‚ñà‚ñé       | 118/500 [2:33:33<8:54:25, 83.94s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.5448644161224365, 'learning_rate': 4.731464546130315e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.5, 'completion_length': 338.0625, 'kl': 0.0029222877346910536, 'epoch': 1.57}
 24%|‚ñà‚ñà‚ñé       | 118/500 [2:33:33<8:54:25, 83.94s/it] 24%|‚ñà‚ñà‚ñç       | 119/500 [2:34:45<8:30:40, 80.42s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.8039255142211914, 'learning_rate': 4.723540933228245e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 311.0, 'kl': 0.0030346320127137005, 'epoch': 1.59}
 24%|‚ñà‚ñà‚ñç       | 119/500 [2:34:45<8:30:40, 80.42s/it] 24%|‚ñà‚ñà‚ñç       | 120/500 [2:35:54<8:07:50, 77.03s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.9193084239959717, 'learning_rate': 4.715508948078037e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0773502588272095, 'completion_length': 307.125, 'kl': 0.0029686308407690376, 'epoch': 1.6}
 24%|‚ñà‚ñà‚ñç       | 120/500 [2:35:54<8:07:50, 77.03s/it] 24%|‚ñà‚ñà‚ñç       | 121/500 [2:37:14<8:10:22, 77.63s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.9163585901260376, 'learning_rate': 4.707368982147318e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 1.0386751294136047, 'completion_length': 319.9375, 'kl': 0.0033503136946819723, 'epoch': 1.61}
 24%|‚ñà‚ñà‚ñç       | 121/500 [2:37:14<8:10:22, 77.63s/it] 24%|‚ñà‚ñà‚ñç       | 122/500 [2:38:30<8:06:08, 77.17s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.9249772429466248, 'learning_rate': 4.699121432166542e-06, 'rewards/cot_correctness_reward_func': 0.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.359375, 'reward_std': 0.5699251294136047, 'completion_length': 337.0, 'kl': 0.0048022565024439245, 'epoch': 1.63}
 24%|‚ñà‚ñà‚ñç       | 122/500 [2:38:30<8:06:08, 77.17s/it] 25%|‚ñà‚ñà‚ñç       | 123/500 [2:39:30<7:34:03, 72.26s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8767043352127075, 'learning_rate': 4.690766700109659e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.453125, 'reward': 1.671875, 'reward_std': 0.9843359738588333, 'completion_length': 296.25, 'kl': 0.0043706868891604245, 'epoch': 1.64}
 25%|‚ñà‚ñà‚ñç       | 123/500 [2:39:30<7:34:03, 72.26s/it] 25%|‚ñà‚ñà‚ñç       | 124/500 [2:40:52<7:51:00, 75.16s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8773902058601379, 'learning_rate': 4.682305193174524e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.5625, 'reward_std': 1.0348635613918304, 'completion_length': 337.125, 'kl': 0.004705650033429265, 'epoch': 1.65}
 25%|‚ñà‚ñà‚ñç       | 124/500 [2:40:52<7:51:00, 75.16s/it] 25%|‚ñà‚ñà‚ñå       | 125/500 [2:41:56<7:27:16, 71.57s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.6846337914466858, 'learning_rate': 4.673737323763048e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 0.8273502588272095, 'completion_length': 297.0625, 'kl': 0.002950150694232434, 'epoch': 1.67}
 25%|‚ñà‚ñà‚ñå       | 125/500 [2:41:56<7:27:16, 71.57s/it] 25%|‚ñà‚ñà‚ñå       | 126/500 [2:43:03<7:19:21, 70.49s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.9415751695632935, 'learning_rate': 4.665063509461098e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.0386751294136047, 'completion_length': 303.5, 'kl': 0.004026851675007492, 'epoch': 1.68}
 25%|‚ñà‚ñà‚ñå       | 126/500 [2:43:03<7:19:21, 70.49s/it] 25%|‚ñà‚ñà‚ñå       | 127/500 [2:44:33<7:52:48, 76.05s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.8225554823875427, 'learning_rate': 4.656284173018144e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.96875, 'reward_std': 1.117419570684433, 'completion_length': 345.25, 'kl': 0.0028774269740097225, 'epoch': 1.69}
 25%|‚ñà‚ñà‚ñå       | 127/500 [2:44:33<7:52:48, 76.05s/it] 26%|‚ñà‚ñà‚ñå       | 128/500 [2:45:43<7:41:44, 74.48s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.9292562007904053, 'learning_rate': 4.6473997423266615e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.6875, 'reward_std': 1.1419267058372498, 'completion_length': 312.875, 'kl': 0.003330117673613131, 'epoch': 1.71}
 26%|‚ñà‚ñà‚ñå       | 128/500 [2:45:43<7:41:44, 74.48s/it] 26%|‚ñà‚ñà‚ñå       | 129/500 [2:47:04<7:52:20, 76.39s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.8669087886810303, 'learning_rate': 4.638410650401267e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 1.0386751294136047, 'completion_length': 332.25, 'kl': 0.0030481116846203804, 'epoch': 1.72}
 26%|‚ñà‚ñà‚ñå       | 129/500 [2:47:04<7:52:20, 76.39s/it] 26%|‚ñà‚ñà‚ñå       | 130/500 [2:48:10<7:31:08, 73.16s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.4956667125225067, 'learning_rate': 4.62931733535762e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.28867512941360474, 'completion_length': 295.375, 'kl': 0.003452419536188245, 'epoch': 1.73}
 26%|‚ñà‚ñà‚ñå       | 130/500 [2:48:10<7:31:08, 73.16s/it] 26%|‚ñà‚ñà‚ñå       | 131/500 [2:49:19<7:23:01, 72.04s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8151602149009705, 'learning_rate': 4.620120240391065e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.96875, 'reward_std': 1.0271694660186768, 'completion_length': 304.125, 'kl': 0.004920228733681142, 'epoch': 1.75}
 26%|‚ñà‚ñà‚ñå       | 131/500 [2:49:19<7:23:01, 72.04s/it] 26%|‚ñà‚ñà‚ñã       | 132/500 [2:50:44<7:46:08, 76.00s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.6232132911682129, 'learning_rate': 4.610819813755038e-06, 'rewards/cot_correctness_reward_func': 0.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.40625, 'reward': 1.15625, 'reward_std': 0.5625, 'completion_length': 375.6875, 'kl': 0.0033156442805193365, 'epoch': 1.76}
 26%|‚ñà‚ñà‚ñã       | 132/500 [2:50:44<7:46:08, 76.00s/it] 27%|‚ñà‚ñà‚ñã       | 133/500 [2:51:53<7:31:16, 73.78s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.7379674315452576, 'learning_rate': 4.601416508739211e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 0.8273502588272095, 'completion_length': 308.3125, 'kl': 0.002833266102243215, 'epoch': 1.77}
 27%|‚ñà‚ñà‚ñã       | 133/500 [2:51:53<7:31:16, 73.78s/it] 27%|‚ñà‚ñà‚ñã       | 134/500 [2:53:02<7:20:35, 72.23s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.824405312538147, 'learning_rate': 4.591910783647405e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.71875, 'reward_std': 1.1045197248458862, 'completion_length': 323.5, 'kl': 0.0045344945974648, 'epoch': 1.79}
 27%|‚ñà‚ñà‚ñã       | 134/500 [2:53:02<7:20:35, 72.23s/it] 27%|‚ñà‚ñà‚ñã       | 135/500 [2:54:10<7:12:52, 71.16s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.9083787202835083, 'learning_rate': 4.582303101775249e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.6875, 'reward_std': 0.853251576423645, 'completion_length': 301.125, 'kl': 0.005309517378918827, 'epoch': 1.8}
 27%|‚ñà‚ñà‚ñã       | 135/500 [2:54:10<7:12:52, 71.16s/it] 27%|‚ñà‚ñà‚ñã       | 136/500 [2:54:54<6:22:07, 62.99s/it]                                                     {'loss': 0.0008, 'grad_norm': 0.9959949851036072, 'learning_rate': 4.572593931387604e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.34375, 'reward_std': 0.7366211712360382, 'completion_length': 151.625, 'kl': 0.018774526077322662, 'epoch': 1.81}
 27%|‚ñà‚ñà‚ñã       | 136/500 [2:54:54<6:22:07, 62.99s/it] 27%|‚ñà‚ñà‚ñã       | 137/500 [2:55:29<5:30:10, 54.57s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.3124732971191406, 'learning_rate': 4.562783745695738e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.359375, 'reward_std': 1.0300632566213608, 'completion_length': 137.0625, 'kl': 0.004314668360166252, 'epoch': 1.83}
 27%|‚ñà‚ñà‚ñã       | 137/500 [2:55:29<5:30:10, 54.57s/it] 28%|‚ñà‚ñà‚ñä       | 138/500 [2:56:03<4:51:41, 48.35s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.10869562625885, 'learning_rate': 4.55287302283426e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 0.8273502588272095, 'completion_length': 136.625, 'kl': 0.0037751104100607336, 'epoch': 1.84}
 28%|‚ñà‚ñà‚ñä       | 138/500 [2:56:03<4:51:41, 48.35s/it] 28%|‚ñà‚ñà‚ñä       | 139/500 [2:56:42<4:33:52, 45.52s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.0250890254974365, 'learning_rate': 4.542862245837821e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 0.8273502588272095, 'completion_length': 139.0, 'kl': 0.006827467994298786, 'epoch': 1.85}
 28%|‚ñà‚ñà‚ñä       | 139/500 [2:56:42<4:33:52, 45.52s/it] 28%|‚ñà‚ñà‚ñä       | 140/500 [2:57:18<4:16:50, 42.81s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.429362416267395, 'learning_rate': 4.5327519026175694e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.0386751294136047, 'completion_length': 149.9375, 'kl': 0.011310103815048933, 'epoch': 1.87}
 28%|‚ñà‚ñà‚ñä       | 140/500 [2:57:18<4:16:50, 42.81s/it] 28%|‚ñà‚ñà‚ñä       | 141/500 [2:57:56<4:07:04, 41.29s/it]                                                     {'loss': 0.0009, 'grad_norm': 1.4309477806091309, 'learning_rate': 4.522542485937369e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.453125, 'reward': 2.328125, 'reward_std': 1.016684427857399, 'completion_length': 140.9375, 'kl': 0.022611068794503808, 'epoch': 1.88}
 28%|‚ñà‚ñà‚ñä       | 141/500 [2:57:56<4:07:04, 41.29s/it] 28%|‚ñà‚ñà‚ñä       | 142/500 [2:58:27<3:48:00, 38.21s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.5443215370178223, 'learning_rate': 4.512234493389785e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.421875, 'reward': 2.171875, 'reward_std': 1.171307697892189, 'completion_length': 124.8125, 'kl': 0.015219877706840634, 'epoch': 1.89}
 28%|‚ñà‚ñà‚ñä       | 142/500 [2:58:27<3:48:00, 38.21s/it] 29%|‚ñà‚ñà‚ñä       | 143/500 [2:59:06<3:47:36, 38.25s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.2673497200012207, 'learning_rate': 4.501828427371834e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.1160253882408142, 'completion_length': 148.0625, 'kl': 0.006792927044443786, 'epoch': 1.91}
 29%|‚ñà‚ñà‚ñä       | 143/500 [2:59:06<3:47:36, 38.25s/it] 29%|‚ñà‚ñà‚ñâ       | 144/500 [2:59:38<3:35:55, 36.39s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.4418631792068481, 'learning_rate': 4.491324795060491e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.4375, 'reward': 2.1875, 'reward_std': 1.0896694660186768, 'completion_length': 120.6875, 'kl': 0.009131320053711534, 'epoch': 1.92}
 29%|‚ñà‚ñà‚ñâ       | 144/500 [2:59:38<3:35:55, 36.39s/it] 29%|‚ñà‚ñà‚ñâ       | 145/500 [3:00:11<3:30:39, 35.60s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.0446741580963135, 'learning_rate': 4.4807241083879774e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.234375, 'reward_std': 0.46875, 'completion_length': 132.875, 'kl': 0.005169861717149615, 'epoch': 1.93}
 29%|‚ñà‚ñà‚ñâ       | 145/500 [3:00:11<3:30:39, 35.60s/it] 29%|‚ñà‚ñà‚ñâ       | 146/500 [3:00:41<3:20:02, 33.91s/it]                                                     {'loss': 0.0009, 'grad_norm': 1.3953887224197388, 'learning_rate': 4.470026884016805e-06, 'rewards/cot_correctness_reward_func': 1.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.71875, 'reward_std': 0.5625, 'completion_length': 121.25, 'kl': 0.022844007704406977, 'epoch': 1.95}
 29%|‚ñà‚ñà‚ñâ       | 146/500 [3:00:41<3:20:02, 33.91s/it] 29%|‚ñà‚ñà‚ñâ       | 147/500 [3:01:20<3:28:20, 35.41s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.1993958950042725, 'learning_rate': 4.4592336433146e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 0.8273502588272095, 'completion_length': 134.4375, 'kl': 0.00679386593401432, 'epoch': 1.96}
 29%|‚ñà‚ñà‚ñâ       | 147/500 [3:01:20<3:28:20, 35.41s/it] 30%|‚ñà‚ñà‚ñâ       | 148/500 [3:02:05<3:43:23, 38.08s/it]                                                     {'loss': 0.0011, 'grad_norm': 0.985515296459198, 'learning_rate': 4.448344912328686e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.390625, 'reward': 2.015625, 'reward_std': 0.6252048090100288, 'completion_length': 146.125, 'kl': 0.027576992171816528, 'epoch': 1.97}
 30%|‚ñà‚ñà‚ñâ       | 148/500 [3:02:05<3:43:23, 38.08s/it] 30%|‚ñà‚ñà‚ñâ       | 149/500 [3:02:35<3:29:12, 35.76s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.0676450729370117, 'learning_rate': 4.437361221760449e-06, 'rewards/cot_correctness_reward_func': 1.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.5, 'reward_std': 0.7886751294136047, 'completion_length': 125.0625, 'kl': 0.005165995913557708, 'epoch': 1.99}
 30%|‚ñà‚ñà‚ñâ       | 149/500 [3:02:35<3:29:12, 35.76s/it] 30%|‚ñà‚ñà‚ñà       | 150/500 [3:03:07<3:22:31, 34.72s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.86019766330719, 'learning_rate': 4.426283106939474e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.453125, 'reward': 1.921875, 'reward_std': 0.9137440621852875, 'completion_length': 132.625, 'kl': 0.011363915633410215, 'epoch': 2.0}
 30%|‚ñà‚ñà‚ñà       | 150/500 [3:03:07<3:22:31, 34.72s/it] 30%|‚ñà‚ñà‚ñà       | 151/500 [3:03:59<3:51:20, 39.77s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.012041449546814, 'learning_rate': 4.415111107797445e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 1.0386751294136047, 'completion_length': 227.125, 'kl': 0.004931292147375643, 'epoch': 2.01}
 30%|‚ñà‚ñà‚ñà       | 151/500 [3:03:59<3:51:20, 39.77s/it] 30%|‚ñà‚ñà‚ñà       | 152/500 [3:04:54<4:17:52, 44.46s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.9178140163421631, 'learning_rate': 4.403845768841842e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.84375, 'reward_std': 1.0658445954322815, 'completion_length': 246.5625, 'kl': 0.005849914625287056, 'epoch': 2.03}
 30%|‚ñà‚ñà‚ñà       | 152/500 [3:04:54<4:17:52, 44.46s/it] 31%|‚ñà‚ñà‚ñà       | 153/500 [3:05:49<4:35:38, 47.66s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.9796277284622192, 'learning_rate': 4.3924876391293915e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.09375, 'reward_std': 1.025296300649643, 'completion_length': 216.25, 'kl': 0.013560253661125898, 'epoch': 2.04}
 31%|‚ñà‚ñà‚ñà       | 153/500 [3:05:49<4:35:38, 47.66s/it] 31%|‚ñà‚ñà‚ñà       | 154/500 [3:06:38<4:36:37, 47.97s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.0813783407211304, 'learning_rate': 4.381037272239311e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.59375, 'reward_std': 0.8585299849510193, 'completion_length': 208.75, 'kl': 0.015611646114848554, 'epoch': 2.05}
 31%|‚ñà‚ñà‚ñà       | 154/500 [3:06:38<4:36:37, 47.97s/it] 31%|‚ñà‚ñà‚ñà       | 155/500 [3:07:26<4:36:32, 48.09s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.7998929023742676, 'learning_rate': 4.36949522624633e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 0.75, 'completion_length': 216.375, 'kl': 0.004720397817436606, 'epoch': 2.07}
 31%|‚ñà‚ñà‚ñà       | 155/500 [3:07:26<4:36:32, 48.09s/it] 31%|‚ñà‚ñà‚ñà       | 156/500 [3:08:13<4:33:16, 47.66s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.144392967224121, 'learning_rate': 4.357862063693486e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 1.0773502588272095, 'completion_length': 209.875, 'kl': 0.005443814967293292, 'epoch': 2.08}
 31%|‚ñà‚ñà‚ñà       | 156/500 [3:08:13<4:33:16, 47.66s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 157/500 [3:09:12<4:51:22, 50.97s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.6932018399238586, 'learning_rate': 4.346138351564711e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.5, 'completion_length': 222.6875, 'kl': 0.004014856414869428, 'epoch': 2.09}
 31%|‚ñà‚ñà‚ñà‚ñè      | 157/500 [3:09:12<4:51:22, 50.97s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 158/500 [3:10:11<5:04:23, 53.40s/it]                                                     {'loss': 0.001, 'grad_norm': 1.3401360511779785, 'learning_rate': 4.334324661257191e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.09375, 'reward_std': 1.1011751294136047, 'completion_length': 226.625, 'kl': 0.02497372281504795, 'epoch': 2.11}
 32%|‚ñà‚ñà‚ñà‚ñè      | 158/500 [3:10:11<5:04:23, 53.40s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 159/500 [3:11:00<4:55:36, 52.01s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.088731288909912, 'learning_rate': 4.322421568553529e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.0386751294136047, 'completion_length': 206.9375, 'kl': 0.004007760144304484, 'epoch': 2.12}
 32%|‚ñà‚ñà‚ñà‚ñè      | 159/500 [3:11:00<4:55:36, 52.01s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 160/500 [3:11:54<4:59:24, 52.84s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8782205581665039, 'learning_rate': 4.3104296535936695e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 0.8273502588272095, 'completion_length': 225.75, 'kl': 0.005077148030977696, 'epoch': 2.13}
 32%|‚ñà‚ñà‚ñà‚ñè      | 160/500 [3:11:54<4:59:24, 52.84s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 161/500 [3:13:23<5:58:51, 63.51s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.960326075553894, 'learning_rate': 4.2983495008466285e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.71875, 'reward_std': 0.8287444412708282, 'completion_length': 277.1875, 'kl': 0.0038256437401287258, 'epoch': 2.15}
 32%|‚ñà‚ñà‚ñà‚ñè      | 161/500 [3:13:23<5:58:51, 63.51s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 162/500 [3:14:26<5:57:34, 63.48s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.9100473523139954, 'learning_rate': 4.286181699082008e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.0386751294136047, 'completion_length': 247.5, 'kl': 0.004131793160922825, 'epoch': 2.16}
 32%|‚ñà‚ñà‚ñà‚ñè      | 162/500 [3:14:26<5:57:34, 63.48s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 163/500 [3:15:35<6:06:25, 65.24s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.0072799921035767, 'learning_rate': 4.273926841341303e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 241.5, 'kl': 0.005789858172647655, 'epoch': 2.17}
 33%|‚ñà‚ñà‚ñà‚ñé      | 163/500 [3:15:35<6:06:25, 65.24s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 164/500 [3:16:54<6:27:34, 69.21s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.9189011454582214, 'learning_rate': 4.261585524908987e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.9375, 'reward_std': 1.1419267058372498, 'completion_length': 273.3125, 'kl': 0.01065246039070189, 'epoch': 2.19}
 33%|‚ñà‚ñà‚ñà‚ñé      | 164/500 [3:16:54<6:27:34, 69.21s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 165/500 [3:18:05<6:29:12, 69.71s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.0128238201141357, 'learning_rate': 4.249158351283414e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.5625, 'reward_std': 0.875, 'completion_length': 260.9375, 'kl': 0.006459906522650272, 'epoch': 2.2}
 33%|‚ñà‚ñà‚ñà‚ñé      | 165/500 [3:18:05<6:29:12, 69.71s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 166/500 [3:19:02<6:07:03, 65.94s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8492745161056519, 'learning_rate': 4.236645926147493e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 0.75, 'completion_length': 228.9375, 'kl': 0.005869488813914359, 'epoch': 2.21}
 33%|‚ñà‚ñà‚ñà‚ñé      | 166/500 [3:19:02<6:07:03, 65.94s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 167/500 [3:20:29<6:41:28, 72.34s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.2417205572128296, 'learning_rate': 4.224048859339175e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.8125, 'reward_std': 1.0666449964046478, 'completion_length': 275.5625, 'kl': 0.0066550542251206934, 'epoch': 2.23}
 33%|‚ñà‚ñà‚ñà‚ñé      | 167/500 [3:20:29<6:41:28, 72.34s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 168/500 [3:21:21<6:05:47, 66.11s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.9567153453826904, 'learning_rate': 4.211367764821722e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.0386751294136047, 'completion_length': 228.9375, 'kl': 0.004824180854484439, 'epoch': 2.24}
 34%|‚ñà‚ñà‚ñà‚ñé      | 168/500 [3:21:21<6:05:47, 66.11s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 169/500 [3:22:19<5:51:56, 63.80s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.003104329109192, 'learning_rate': 4.198603260653792e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.21875, 'reward_std': 1.0463692247867584, 'completion_length': 218.0, 'kl': 0.005478853010572493, 'epoch': 2.25}
 34%|‚ñà‚ñà‚ñà‚ñç      | 169/500 [3:22:19<5:51:56, 63.80s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 170/500 [3:23:15<5:38:09, 61.48s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.2571232318878174, 'learning_rate': 4.185755968959308e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 210.25, 'kl': 0.007014925358816981, 'epoch': 2.27}
 34%|‚ñà‚ñà‚ñà‚ñç      | 170/500 [3:23:15<5:38:09, 61.48s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 171/500 [3:24:12<5:29:40, 60.12s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.9724736213684082, 'learning_rate': 4.172826515897146e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.154700517654419, 'completion_length': 237.5625, 'kl': 0.005398827081080526, 'epoch': 2.28}
 34%|‚ñà‚ñà‚ñà‚ñç      | 171/500 [3:24:12<5:29:40, 60.12s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 172/500 [3:25:12<5:28:26, 60.08s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.2406961917877197, 'learning_rate': 4.159815531630604e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.109375, 'reward_std': 1.0699251294136047, 'completion_length': 231.375, 'kl': 0.011132833547890186, 'epoch': 2.29}
 34%|‚ñà‚ñà‚ñà‚ñç      | 172/500 [3:25:12<5:28:26, 60.08s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 173/500 [3:26:02<5:10:18, 56.94s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.0890363454818726, 'learning_rate': 4.146723650296701e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 0.8273502588272095, 'completion_length': 206.1875, 'kl': 0.0038465558900497854, 'epoch': 2.31}
 35%|‚ñà‚ñà‚ñà‚ñç      | 173/500 [3:26:02<5:10:18, 56.94s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 174/500 [3:27:00<5:12:05, 57.44s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.0088608264923096, 'learning_rate': 4.133551509975264e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.0386751294136047, 'completion_length': 229.25, 'kl': 0.004903107474092394, 'epoch': 2.32}
 35%|‚ñà‚ñà‚ñà‚ñç      | 174/500 [3:27:00<5:12:05, 57.44s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 175/500 [3:28:01<5:16:53, 58.50s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.926559567451477, 'learning_rate': 4.120299752657828e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 1.0386751294136047, 'completion_length': 243.1875, 'kl': 0.007063335448037833, 'epoch': 2.33}
 35%|‚ñà‚ñà‚ñà‚ñå      | 175/500 [3:28:01<5:16:53, 58.50s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 176/500 [3:29:15<5:41:08, 63.17s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.7710689902305603, 'learning_rate': 4.106969024216348e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.59375, 'reward_std': 0.8125, 'completion_length': 330.6875, 'kl': 0.005454557598568499, 'epoch': 2.35}
 35%|‚ñà‚ñà‚ñà‚ñå      | 176/500 [3:29:15<5:41:08, 63.17s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 177/500 [3:30:39<6:13:04, 69.30s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8479763865470886, 'learning_rate': 4.093559974371725e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0773502588272095, 'completion_length': 319.4375, 'kl': 0.0038142911507748067, 'epoch': 2.36}
 35%|‚ñà‚ñà‚ñà‚ñå      | 177/500 [3:30:39<6:13:04, 69.30s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 178/500 [3:31:41<5:59:25, 66.97s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.7881601452827454, 'learning_rate': 4.080073256662128e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.0386751294136047, 'completion_length': 291.8125, 'kl': 0.003383641771506518, 'epoch': 2.37}
 36%|‚ñà‚ñà‚ñà‚ñå      | 178/500 [3:31:41<5:59:25, 66.97s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 179/500 [3:32:38<5:42:46, 64.07s/it]                                                     {'loss': 0.0001, 'grad_norm': 1.0933194160461426, 'learning_rate': 4.066509528411151e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 263.125, 'kl': 0.003031206550076604, 'epoch': 2.39}
 36%|‚ñà‚ñà‚ñà‚ñå      | 179/500 [3:32:38<5:42:46, 64.07s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 180/500 [3:34:07<6:21:16, 71.49s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.7870288491249084, 'learning_rate': 4.052869450695776e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.96875, 'reward_std': 1.117419570684433, 'completion_length': 333.75, 'kl': 0.003660936141386628, 'epoch': 2.4}
 36%|‚ñà‚ñà‚ñà‚ñå      | 180/500 [3:34:07<6:21:16, 71.49s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 181/500 [3:35:20<6:22:48, 72.00s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.9002166390419006, 'learning_rate': 4.039153688314146e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 1.0386751294136047, 'completion_length': 303.6875, 'kl': 0.0034884034539572895, 'epoch': 2.41}
 36%|‚ñà‚ñà‚ñà‚ñå      | 181/500 [3:35:20<6:22:48, 72.00s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 182/500 [3:36:29<6:17:29, 71.22s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.8744024634361267, 'learning_rate': 4.02536290975317e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.1160253882408142, 'completion_length': 307.5, 'kl': 0.003574543457943946, 'epoch': 2.43}
 36%|‚ñà‚ñà‚ñà‚ñã      | 182/500 [3:36:29<6:17:29, 71.22s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 183/500 [3:37:38<6:13:01, 70.60s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.0373915433883667, 'learning_rate': 4.011497787155938e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 314.8125, 'kl': 0.005966372147668153, 'epoch': 2.44}
 37%|‚ñà‚ñà‚ñà‚ñã      | 183/500 [3:37:38<6:13:01, 70.60s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 184/500 [3:38:44<6:04:14, 69.16s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.7608738541603088, 'learning_rate': 3.997558996288965e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.0386751294136047, 'completion_length': 295.0, 'kl': 0.0035011042491532862, 'epoch': 2.45}
 37%|‚ñà‚ñà‚ñà‚ñã      | 184/500 [3:38:44<6:04:14, 69.16s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 185/500 [3:39:47<5:53:35, 67.35s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.8197507262229919, 'learning_rate': 3.983547216509254e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.84375, 'reward_std': 0.867419570684433, 'completion_length': 281.5625, 'kl': 0.00895448261871934, 'epoch': 2.47}
 37%|‚ñà‚ñà‚ñà‚ñã      | 185/500 [3:39:47<5:53:35, 67.35s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 186/500 [3:40:56<5:53:45, 67.60s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.8319401144981384, 'learning_rate': 3.969463130731183e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.0386751294136047, 'completion_length': 308.9375, 'kl': 0.009354649111628532, 'epoch': 2.48}
 37%|‚ñà‚ñà‚ñà‚ñã      | 186/500 [3:40:56<5:53:45, 67.60s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 187/500 [3:42:00<5:47:31, 66.62s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.9733369946479797, 'learning_rate': 3.955307425393224e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.859375, 'reward_std': 1.135127067565918, 'completion_length': 295.9375, 'kl': 0.011822067899629474, 'epoch': 2.49}
 37%|‚ñà‚ñà‚ñà‚ñã      | 187/500 [3:42:00<5:47:31, 66.62s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 188/500 [3:43:12<5:54:22, 68.15s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.9349250197410583, 'learning_rate': 3.941080790424483e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0, 'completion_length': 307.3125, 'kl': 0.004530443984549493, 'epoch': 2.51}
 38%|‚ñà‚ñà‚ñà‚ñä      | 188/500 [3:43:12<5:54:22, 68.15s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 189/500 [3:44:26<6:03:23, 70.11s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.835088849067688, 'learning_rate': 3.92678391921108e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.71875, 'reward_std': 0.8287444412708282, 'completion_length': 313.1875, 'kl': 0.005722391651943326, 'epoch': 2.52}
 38%|‚ñà‚ñà‚ñà‚ñä      | 189/500 [3:44:26<6:03:23, 70.11s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 190/500 [3:45:36<6:01:47, 70.03s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.0555721521377563, 'learning_rate': 3.912417508562345e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.0386751294136047, 'completion_length': 299.4375, 'kl': 0.005451487377285957, 'epoch': 2.53}
 38%|‚ñà‚ñà‚ñà‚ñä      | 190/500 [3:45:36<6:01:47, 70.03s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 191/500 [3:46:58<6:19:07, 73.62s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8820846080780029, 'learning_rate': 3.897982258676867e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.84375, 'reward_std': 1.1560947000980377, 'completion_length': 314.6875, 'kl': 0.006124768988229334, 'epoch': 2.55}
 38%|‚ñà‚ñà‚ñà‚ñä      | 191/500 [3:46:58<6:19:07, 73.62s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 192/500 [3:48:10<6:15:09, 73.08s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.9603968858718872, 'learning_rate': 3.88347887310836e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.71875, 'reward_std': 1.1045197248458862, 'completion_length': 309.75, 'kl': 0.00713229738175869, 'epoch': 2.56}
 38%|‚ñà‚ñà‚ñà‚ñä      | 192/500 [3:48:10<6:15:09, 73.08s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 193/500 [3:49:31<6:26:46, 75.59s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.8694034814834595, 'learning_rate': 3.868908058731376e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.1160253882408142, 'completion_length': 333.125, 'kl': 0.00847476621856913, 'epoch': 2.57}
 39%|‚ñà‚ñà‚ñà‚ñä      | 193/500 [3:49:31<6:26:46, 75.59s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 194/500 [3:50:36<6:09:16, 72.41s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.9909246563911438, 'learning_rate': 3.85427052570685e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 292.125, 'kl': 0.005319626361597329, 'epoch': 2.59}
 39%|‚ñà‚ñà‚ñà‚ñâ      | 194/500 [3:50:36<6:09:16, 72.41s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 195/500 [3:51:39<5:52:35, 69.36s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8447232246398926, 'learning_rate': 3.839566987447492e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 1.0386751294136047, 'completion_length': 303.875, 'kl': 0.005272582522593439, 'epoch': 2.6}
 39%|‚ñà‚ñà‚ñà‚ñâ      | 195/500 [3:51:39<5:52:35, 69.36s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 196/500 [3:52:47<5:50:39, 69.21s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.9012125730514526, 'learning_rate': 3.824798160583012e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.1160253882408142, 'completion_length': 302.8125, 'kl': 0.006746123894117773, 'epoch': 2.61}
 39%|‚ñà‚ñà‚ñà‚ñâ      | 196/500 [3:52:47<5:50:39, 69.21s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 197/500 [3:53:50<5:40:04, 67.34s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.8339331746101379, 'learning_rate': 3.8099647649251984e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.8660253882408142, 'completion_length': 288.5625, 'kl': 0.007233074284158647, 'epoch': 2.63}
 39%|‚ñà‚ñà‚ñà‚ñâ      | 197/500 [3:53:50<5:40:04, 67.34s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 198/500 [3:54:59<5:40:57, 67.74s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.048715353012085, 'learning_rate': 3.795067523432826e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 0.8273502588272095, 'completion_length': 297.375, 'kl': 0.007415497733745724, 'epoch': 2.64}
 40%|‚ñà‚ñà‚ñà‚ñâ      | 198/500 [3:54:59<5:40:57, 67.74s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 199/500 [3:56:13<5:48:28, 69.46s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.8944537043571472, 'learning_rate': 3.780107162176429e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 0.8273502588272095, 'completion_length': 312.1875, 'kl': 0.007427619420923293, 'epoch': 2.65}
 40%|‚ñà‚ñà‚ñà‚ñâ      | 199/500 [3:56:13<5:48:28, 69.46s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 200/500 [3:57:17<5:39:24, 67.88s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.6812288165092468, 'learning_rate': 3.7650844103029093e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.109375, 'reward_std': 0.762078046798706, 'completion_length': 283.1875, 'kl': 0.005532726063393056, 'epoch': 2.67}
 40%|‚ñà‚ñà‚ñà‚ñà      | 200/500 [3:57:17<5:39:24, 67.88s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 201/500 [3:58:19<5:30:19, 66.28s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.0128856897354126, 'learning_rate': 3.7500000000000005e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 1.0, 'completion_length': 290.125, 'kl': 0.006637709506321698, 'epoch': 2.68}
 40%|‚ñà‚ñà‚ñà‚ñà      | 201/500 [3:58:19<5:30:19, 66.28s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 202/500 [3:59:31<5:37:10, 67.89s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8628145456314087, 'learning_rate': 3.7348546664605777e-06, 'rewards/cot_correctness_reward_func': 1.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.5, 'reward_std': 0.7886751294136047, 'completion_length': 300.125, 'kl': 0.004994156071916223, 'epoch': 2.69}
 40%|‚ñà‚ñà‚ñà‚ñà      | 202/500 [3:59:31<5:37:10, 67.89s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 203/500 [4:00:44<5:43:39, 69.43s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.0197147130966187, 'learning_rate': 3.7196491478468322e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.1160253882408142, 'completion_length': 301.25, 'kl': 0.006508421269245446, 'epoch': 2.71}
 41%|‚ñà‚ñà‚ñà‚ñà      | 203/500 [4:00:44<5:43:39, 69.43s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 204/500 [4:01:52<5:40:07, 68.95s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.995638906955719, 'learning_rate': 3.7043841852542884e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.1160253882408142, 'completion_length': 294.625, 'kl': 0.008112820563837886, 'epoch': 2.72}
 41%|‚ñà‚ñà‚ñà‚ñà      | 204/500 [4:01:52<5:40:07, 68.95s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 205/500 [4:02:59<5:36:30, 68.44s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8000099658966064, 'learning_rate': 3.689060522675689e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.0386751294136047, 'completion_length': 307.5625, 'kl': 0.005103369418065995, 'epoch': 2.73}
 41%|‚ñà‚ñà‚ñà‚ñà      | 205/500 [4:02:59<5:36:30, 68.44s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 206/500 [4:04:05<5:31:41, 67.69s/it]                                                     {'loss': 0.0007, 'grad_norm': 0.7287665009498596, 'learning_rate': 3.6736789069647273e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.859375, 'reward_std': 0.762078046798706, 'completion_length': 300.25, 'kl': 0.01633638539351523, 'epoch': 2.75}
 41%|‚ñà‚ñà‚ñà‚ñà      | 206/500 [4:04:05<5:31:41, 67.69s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 207/500 [4:05:16<5:34:38, 68.53s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8044211864471436, 'learning_rate': 3.658240087799655e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0773502588272095, 'completion_length': 309.5625, 'kl': 0.006113548064604402, 'epoch': 2.76}
 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 207/500 [4:05:16<5:34:38, 68.53s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 208/500 [4:07:53<7:43:22, 95.21s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.5480991005897522, 'learning_rate': 3.642744817646736e-06, 'rewards/cot_correctness_reward_func': 0.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.453125, 'reward': 1.328125, 'reward_std': 0.5908224880695343, 'completion_length': 442.8125, 'kl': 0.009195488877594471, 'epoch': 2.77}
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 208/500 [4:07:53<7:43:22, 95.21s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 209/500 [4:09:06<7:10:07, 88.69s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.3143055438995361, 'learning_rate': 3.627193851723577e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.484375, 'reward_std': 0.8199251294136047, 'completion_length': 324.4375, 'kl': 0.00879831612110138, 'epoch': 2.79}
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 209/500 [4:09:06<7:10:07, 88.69s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 210/500 [4:10:15<6:38:51, 82.52s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.9763827323913574, 'learning_rate': 3.611587947962319e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 1.0, 'completion_length': 292.125, 'kl': 0.006082104868255556, 'epoch': 2.8}
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 210/500 [4:10:15<6:38:51, 82.52s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 211/500 [4:10:51<5:30:25, 68.60s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.4556878805160522, 'learning_rate': 3.595927866972694e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.21875, 'reward_std': 1.0271694660186768, 'completion_length': 136.5, 'kl': 0.015855692676268518, 'epoch': 2.81}
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 211/500 [4:10:51<5:30:25, 68.60s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 212/500 [4:11:22<4:35:14, 57.34s/it]                                                     {'loss': 0.0013, 'grad_norm': 1.0503995418548584, 'learning_rate': 3.5802143720049565e-06, 'rewards/cot_correctness_reward_func': 1.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.484375, 'reward_std': 0.53125, 'completion_length': 125.625, 'kl': 0.032168597215786576, 'epoch': 2.83}
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 212/500 [4:11:22<4:35:14, 57.34s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 213/500 [4:12:03<4:11:32, 52.59s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.1002535820007324, 'learning_rate': 3.564448228912682e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.9375, 'reward_std': 0.8257212191820145, 'completion_length': 158.0625, 'kl': 0.014806875260546803, 'epoch': 2.84}
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 213/500 [4:12:03<4:11:32, 52.59s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 214/500 [4:12:47<3:58:12, 49.97s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.2306772470474243, 'learning_rate': 3.5486302061154433e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.9375, 'reward_std': 1.1636751294136047, 'completion_length': 157.375, 'kl': 0.012424077605828643, 'epoch': 2.85}
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 214/500 [4:12:47<3:58:12, 49.97s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 215/500 [4:13:25<3:40:04, 46.33s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.3153798580169678, 'learning_rate': 3.532761074561355e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.359375, 'reward_std': 1.0300632566213608, 'completion_length': 138.3125, 'kl': 0.011794884456321597, 'epoch': 2.87}
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 215/500 [4:13:25<3:40:04, 46.33s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 216/500 [4:13:58<3:20:48, 42.42s/it]                                                     {'loss': 0.0011, 'grad_norm': 1.216529369354248, 'learning_rate': 3.516841607689501e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.234375, 'reward_std': 1.0605082213878632, 'completion_length': 134.4375, 'kl': 0.0274823063518852, 'epoch': 2.88}
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 216/500 [4:13:58<3:20:48, 42.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 217/500 [4:14:32<3:07:05, 39.66s/it]                                                     {'loss': 0.0007, 'grad_norm': 1.1391140222549438, 'learning_rate': 3.5008725813922383e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.34375, 'reward_std': 0.8139714300632477, 'completion_length': 129.25, 'kl': 0.018677931395359337, 'epoch': 2.89}
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 217/500 [4:14:32<3:07:05, 39.66s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 218/500 [4:15:01<2:52:36, 36.72s/it]                                                     {'loss': 0.0013, 'grad_norm': 1.4031270742416382, 'learning_rate': 3.4848547739773782e-06, 'rewards/cot_correctness_reward_func': 1.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.59375, 'reward_std': 0.8125, 'completion_length': 119.625, 'kl': 0.03303255466744304, 'epoch': 2.91}
 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 218/500 [4:15:01<2:52:36, 36.72s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 219/500 [4:15:31<2:41:58, 34.58s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.2594761848449707, 'learning_rate': 3.4687889661302577e-06, 'rewards/cot_correctness_reward_func': 1.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.453125, 'reward': 2.578125, 'reward_std': 0.803888127207756, 'completion_length': 120.5625, 'kl': 0.009341081604361534, 'epoch': 2.92}
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 219/500 [4:15:31<2:41:58, 34.58s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 220/500 [4:16:03<2:38:06, 33.88s/it]                                                     {'loss': 0.0011, 'grad_norm': 1.4221599102020264, 'learning_rate': 3.452675940875686e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.96875, 'reward_std': 1.0463692247867584, 'completion_length': 131.3125, 'kl': 0.02847558376379311, 'epoch': 2.93}
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 220/500 [4:16:03<2:38:06, 33.88s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 221/500 [4:16:34<2:33:49, 33.08s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.0609509944915771, 'learning_rate': 3.436516483539781e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 0.8273502588272095, 'completion_length': 124.0, 'kl': 0.011546181282028556, 'epoch': 2.95}
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 221/500 [4:16:34<2:33:49, 33.08s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 222/500 [4:17:07<2:32:27, 32.91s/it]                                                     {'loss': 0.0007, 'grad_norm': 1.3543505668640137, 'learning_rate': 3.4203113817116955e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.109375, 'reward_std': 1.0507531762123108, 'completion_length': 130.125, 'kl': 0.01714494195766747, 'epoch': 2.96}
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 222/500 [4:17:07<2:32:27, 32.91s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 223/500 [4:17:45<2:38:22, 34.30s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.0059369802474976, 'learning_rate': 3.4040614252052305e-06, 'rewards/cot_correctness_reward_func': 1.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.71875, 'reward_std': 0.3030830919742584, 'completion_length': 143.75, 'kl': 0.009846465312875807, 'epoch': 2.97}
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 223/500 [4:17:45<2:38:22, 34.30s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 224/500 [4:18:31<2:54:40, 37.97s/it]                                                     {'loss': 0.0009, 'grad_norm': 0.8842008709907532, 'learning_rate': 3.387767406020343e-06, 'rewards/cot_correctness_reward_func': 1.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.75, 'reward_std': 0.5, 'completion_length': 142.5, 'kl': 0.023328831186518073, 'epoch': 2.99}
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 224/500 [4:18:31<2:54:40, 37.97s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 225/500 [4:19:04<2:47:42, 36.59s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.2510333061218262, 'learning_rate': 3.3714301183045382e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 0.7886751294136047, 'completion_length': 129.6875, 'kl': 0.01129140192642808, 'epoch': 3.0}
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 225/500 [4:19:04<2:47:42, 36.59s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 226/500 [4:19:51<3:01:08, 39.67s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.0047852993011475, 'learning_rate': 3.3550503583141726e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 0.8273502588272095, 'completion_length': 208.0, 'kl': 0.009288016357459128, 'epoch': 3.01}
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 226/500 [4:19:51<3:01:08, 39.67s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 227/500 [4:20:54<3:31:34, 46.50s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.0577106475830078, 'learning_rate': 3.338628924375638e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.84375, 'reward_std': 1.143194854259491, 'completion_length': 239.25, 'kl': 0.011251589050516486, 'epoch': 3.03}
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 227/500 [4:20:54<3:31:34, 46.50s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 228/500 [4:21:45<3:37:46, 48.04s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.0707894563674927, 'learning_rate': 3.3221666168464584e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 218.75, 'kl': 0.009648604085668921, 'epoch': 3.04}
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 228/500 [4:21:45<3:37:46, 48.04s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 229/500 [4:22:53<4:03:52, 53.99s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.0543670654296875, 'learning_rate': 3.3056642380762783e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.46875, 'reward_std': 1.0271694660186768, 'completion_length': 234.4375, 'kl': 0.007671246421523392, 'epoch': 3.05}
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 229/500 [4:22:53<4:03:52, 53.99s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 230/500 [4:23:48<4:03:42, 54.16s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.0349080562591553, 'learning_rate': 3.2891225923677565e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 0.8273502588272095, 'completion_length': 220.5, 'kl': 0.009029501699842513, 'epoch': 3.07}
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 230/500 [4:23:48<4:03:42, 54.16s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 231/500 [4:24:36<3:54:58, 52.41s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.0749452114105225, 'learning_rate': 3.272542485937369e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 0.7886751294136047, 'completion_length': 202.4375, 'kl': 0.010979820042848587, 'epoch': 3.08}
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 231/500 [4:24:36<3:54:58, 52.41s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 232/500 [4:25:26<3:50:32, 51.61s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.9885283708572388, 'learning_rate': 3.2559247268761117e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 0.75, 'completion_length': 200.9375, 'kl': 0.009474208462052047, 'epoch': 3.09}
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 232/500 [4:25:26<3:50:32, 51.61s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 233/500 [4:26:14<3:45:04, 50.58s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.2558332681655884, 'learning_rate': 3.2392701251101172e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.453125, 'reward': 1.828125, 'reward_std': 0.9990822225809097, 'completion_length': 213.4375, 'kl': 0.0077470578253269196, 'epoch': 3.11}
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 233/500 [4:26:14<3:45:04, 50.58s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 234/500 [4:27:03<3:41:40, 50.00s/it]                                                     {'loss': 0.0008, 'grad_norm': 1.3263752460479736, 'learning_rate': 3.222579492361179e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.96875, 'reward_std': 1.1398502588272095, 'completion_length': 205.625, 'kl': 0.019394108443520963, 'epoch': 3.12}
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 234/500 [4:27:03<3:41:40, 50.00s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 235/500 [4:27:56<3:45:09, 50.98s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.1812958717346191, 'learning_rate': 3.205853642107192e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.0625, 'reward_std': 1.2023502588272095, 'completion_length': 203.9375, 'kl': 0.01509708701632917, 'epoch': 3.13}
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 235/500 [4:27:56<3:45:09, 50.98s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 236/500 [4:28:51<3:49:30, 52.16s/it]                                                     {'loss': 0.0011, 'grad_norm': 1.0303090810775757, 'learning_rate': 3.189093389542498e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.859375, 'reward_std': 1.0699251294136047, 'completion_length': 230.9375, 'kl': 0.02688766992650926, 'epoch': 3.15}
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 236/500 [4:28:51<3:49:30, 52.16s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 237/500 [4:29:44<3:49:56, 52.46s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.0518592596054077, 'learning_rate': 3.1722995515381644e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.21875, 'reward_std': 1.0463692247867584, 'completion_length': 220.625, 'kl': 0.009151834528893232, 'epoch': 3.16}
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 237/500 [4:29:44<3:49:56, 52.46s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 238/500 [4:30:36<3:49:00, 52.45s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.0347636938095093, 'learning_rate': 3.155472946602162e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0773502588272095, 'completion_length': 215.3125, 'kl': 0.013210643199272454, 'epoch': 3.17}
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 238/500 [4:30:36<3:49:00, 52.45s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 239/500 [4:31:26<3:43:47, 51.45s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.0502920150756836, 'learning_rate': 3.1386143948394764e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 0.7886751294136047, 'completion_length': 209.125, 'kl': 0.013059667777270079, 'epoch': 3.19}
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 239/500 [4:31:26<3:43:47, 51.45s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 240/500 [4:32:12<3:36:21, 49.93s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.8609883785247803, 'learning_rate': 3.121724717912138e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 0.7886751294136047, 'completion_length': 213.25, 'kl': 0.008545111515559256, 'epoch': 3.2}
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 240/500 [4:32:12<3:36:21, 49.93s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 241/500 [4:33:00<3:32:51, 49.31s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.881905734539032, 'learning_rate': 3.1048047389991693e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.5, 'completion_length': 214.625, 'kl': 0.006922099622897804, 'epoch': 3.21}
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 241/500 [4:33:00<3:32:51, 49.31s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 242/500 [4:33:53<3:37:08, 50.50s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.8592732548713684, 'learning_rate': 3.087855282756475e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 0.7886751294136047, 'completion_length': 227.125, 'kl': 0.008465297287330031, 'epoch': 3.23}
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 242/500 [4:33:53<3:37:08, 50.50s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 243/500 [4:34:51<3:45:27, 52.64s/it]                                                     {'loss': 0.001, 'grad_norm': 1.1287055015563965, 'learning_rate': 3.0708771752766397e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.421875, 'reward': 1.921875, 'reward_std': 1.1990212500095367, 'completion_length': 231.25, 'kl': 0.025353943230584264, 'epoch': 3.24}
 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 243/500 [4:34:51<3:45:27, 52.64s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 244/500 [4:35:59<4:04:59, 57.42s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.9290525317192078, 'learning_rate': 3.053871244048669e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 0.8660253882408142, 'completion_length': 238.875, 'kl': 0.008003450464457273, 'epoch': 3.25}
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 244/500 [4:35:59<4:04:59, 57.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 245/500 [4:36:53<3:59:05, 56.26s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.5099183320999146, 'learning_rate': 3.0368383179176584e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 209.125, 'kl': 0.0159052275121212, 'epoch': 3.27}
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 245/500 [4:36:53<3:59:05, 56.26s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 246/500 [4:37:44<3:52:13, 54.86s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.9862471222877502, 'learning_rate': 3.019779227044398e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 217.625, 'kl': 0.011096375528723001, 'epoch': 3.28}
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 246/500 [4:37:44<3:52:13, 54.86s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 247/500 [4:38:40<3:52:37, 55.17s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.3419840335845947, 'learning_rate': 3.002694802864912e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 218.75, 'kl': 0.016225092578679323, 'epoch': 3.29}
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 247/500 [4:38:40<3:52:37, 55.17s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 248/500 [4:39:25<3:38:11, 51.95s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.4053958654403687, 'learning_rate': 2.98558587804993e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.859375, 'reward_std': 1.135127067565918, 'completion_length': 192.625, 'kl': 0.007279327081050724, 'epoch': 3.31}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 248/500 [4:39:25<3:38:11, 51.95s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 249/500 [4:40:20<3:41:00, 52.83s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.9916949272155762, 'learning_rate': 2.9684532864643123e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0, 'completion_length': 223.75, 'kl': 0.011650672066025436, 'epoch': 3.32}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 249/500 [4:40:20<3:41:00, 52.83s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 250/500 [4:41:09<3:35:26, 51.71s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.6249660849571228, 'learning_rate': 2.9512978631264006e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 0.5386751294136047, 'completion_length': 202.5625, 'kl': 0.006643517583142966, 'epoch': 3.33}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 250/500 [4:41:09<3:35:26, 51.71s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 251/500 [4:42:17<3:55:13, 56.68s/it]                                                     {'loss': 0.0009, 'grad_norm': 1.0020941495895386, 'learning_rate': 2.9341204441673267e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.7886751294136047, 'completion_length': 301.875, 'kl': 0.021369385765865445, 'epoch': 3.35}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 251/500 [4:42:17<3:55:13, 56.68s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 252/500 [4:43:27<4:11:25, 60.83s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.134523630142212, 'learning_rate': 2.9169218667902562e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 1.0386751294136047, 'completion_length': 291.875, 'kl': 0.014398378552868962, 'epoch': 3.36}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 252/500 [4:43:27<4:11:25, 60.83s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 253/500 [4:44:29<4:10:41, 60.90s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.9022179245948792, 'learning_rate': 2.8997029692295875e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 0.7886751294136047, 'completion_length': 281.8125, 'kl': 0.010442197090014815, 'epoch': 3.37}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 253/500 [4:44:29<4:10:41, 60.90s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 254/500 [4:45:31<4:12:12, 61.51s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.000693917274475, 'learning_rate': 2.8824645907100957e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.0386751294136047, 'completion_length': 271.0625, 'kl': 0.007864228216931224, 'epoch': 3.39}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 254/500 [4:45:32<4:12:12, 61.51s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 255/500 [4:46:44<4:24:46, 64.84s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.7980882525444031, 'learning_rate': 2.8652075714060296e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.0386751294136047, 'completion_length': 317.5, 'kl': 0.008663865271955729, 'epoch': 3.4}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 255/500 [4:46:44<4:24:46, 64.84s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 256/500 [4:47:48<4:23:03, 64.69s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8564361333847046, 'learning_rate': 2.847932752400164e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0, 'completion_length': 300.875, 'kl': 0.005799998762086034, 'epoch': 3.41}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 256/500 [4:47:48<4:23:03, 64.69s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 257/500 [4:48:52<4:21:12, 64.50s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.9482267498970032, 'learning_rate': 2.8306409756428067e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 1.0386751294136047, 'completion_length': 279.625, 'kl': 0.008863149618264288, 'epoch': 3.43}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 257/500 [4:48:52<4:21:12, 64.50s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 258/500 [4:50:09<4:34:38, 68.09s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.8473843336105347, 'learning_rate': 2.813333083910761e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.8660253882408142, 'completion_length': 319.25, 'kl': 0.006598434643819928, 'epoch': 3.44}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 258/500 [4:50:09<4:34:38, 68.09s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 259/500 [4:51:18<4:34:02, 68.23s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.8681510090827942, 'learning_rate': 2.7960099207662535e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.1160253882408142, 'completion_length': 312.3125, 'kl': 0.007226053974591196, 'epoch': 3.45}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 259/500 [4:51:18<4:34:02, 68.23s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 260/500 [4:52:24<4:30:51, 67.72s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.93315589427948, 'learning_rate': 2.778672330515814e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.09375, 'reward_std': 0.867419570684433, 'completion_length': 281.875, 'kl': 0.009112612169701606, 'epoch': 3.47}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 260/500 [4:52:24<4:30:51, 67.72s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 261/500 [4:53:42<4:42:29, 70.92s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8570831418037415, 'learning_rate': 2.761321158169134e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 1.0773502588272095, 'completion_length': 318.6875, 'kl': 0.005574499722570181, 'epoch': 3.48}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 261/500 [4:53:42<4:42:29, 70.92s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 262/500 [4:54:55<4:43:35, 71.49s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.018480658531189, 'learning_rate': 2.743957249397874e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 315.75, 'kl': 0.006466073333285749, 'epoch': 3.49}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 262/500 [4:54:55<4:43:35, 71.49s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 263/500 [4:56:12<4:48:27, 73.03s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.6893652677536011, 'learning_rate': 2.726581450494451e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 0.5386751294136047, 'completion_length': 314.6875, 'kl': 0.008396210963837802, 'epoch': 3.51}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 263/500 [4:56:12<4:48:27, 73.03s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 264/500 [4:57:27<4:49:29, 73.60s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.8349155783653259, 'learning_rate': 2.70919460833079e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 0.7886751294136047, 'completion_length': 297.9375, 'kl': 0.00886987114790827, 'epoch': 3.52}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 264/500 [4:57:27<4:49:29, 73.60s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 265/500 [4:58:46<4:54:38, 75.23s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.7077311873435974, 'learning_rate': 2.6917975703170466e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.7886751294136047, 'completion_length': 350.0625, 'kl': 0.005682470859028399, 'epoch': 3.53}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 265/500 [4:58:46<4:54:38, 75.23s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 266/500 [4:59:52<4:42:32, 72.45s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.9092367887496948, 'learning_rate': 2.6743911843603134e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.0386751294136047, 'completion_length': 293.25, 'kl': 0.0070849324110895395, 'epoch': 3.55}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 266/500 [4:59:52<4:42:32, 72.45s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 267/500 [5:00:54<4:28:58, 69.27s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.9329735040664673, 'learning_rate': 2.6569762988232838e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.154700517654419, 'completion_length': 282.875, 'kl': 0.00521959486650303, 'epoch': 3.56}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 267/500 [5:00:54<4:28:58, 69.27s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 268/500 [5:02:01<4:25:22, 68.63s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.8240792751312256, 'learning_rate': 2.63955376248291e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.96875, 'reward_std': 1.1398502588272095, 'completion_length': 306.375, 'kl': 0.012170636560767889, 'epoch': 3.57}
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 268/500 [5:02:01<4:25:22, 68.63s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 269/500 [5:04:36<6:04:02, 94.56s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.900193989276886, 'learning_rate': 2.6221244244890336e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.96875, 'reward_std': 1.117419570684433, 'completion_length': 408.9375, 'kl': 0.006095793680287898, 'epoch': 3.59}
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 269/500 [5:04:36<6:04:02, 94.56s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 270/500 [5:05:48<5:36:25, 87.76s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.9991282224655151, 'learning_rate': 2.604689134322999e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 1.0386751294136047, 'completion_length': 320.75, 'kl': 0.009588702348992229, 'epoch': 3.6}
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 270/500 [5:05:48<5:36:25, 87.76s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 271/500 [5:07:00<5:17:16, 83.13s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.9964979887008667, 'learning_rate': 2.587248741756253e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0, 'completion_length': 301.0625, 'kl': 0.00954388128593564, 'epoch': 3.61}
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 271/500 [5:07:00<5:17:16, 83.13s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 272/500 [5:08:10<5:01:21, 79.31s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.9833196401596069, 'learning_rate': 2.569804096808923e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.5625, 'reward_std': 1.103251576423645, 'completion_length': 308.8125, 'kl': 0.009470094926655293, 'epoch': 3.63}
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 272/500 [5:08:10<5:01:21, 79.31s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 273/500 [5:09:19<4:47:55, 76.10s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.9242082834243774, 'learning_rate': 2.5523560497083927e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 0.8273502588272095, 'completion_length': 296.5625, 'kl': 0.0059543936513364315, 'epoch': 3.64}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 273/500 [5:09:19<4:47:55, 76.10s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 274/500 [5:10:32<4:43:06, 75.16s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.769424319267273, 'learning_rate': 2.5349054508478636e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.46875, 'reward_std': 0.8158445954322815, 'completion_length': 306.9375, 'kl': 0.006659833830781281, 'epoch': 3.65}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 274/500 [5:10:32<4:43:06, 75.16s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 275/500 [5:11:37<4:30:18, 72.08s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8817638754844666, 'learning_rate': 2.517453150744904e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.34375, 'reward_std': 0.8125, 'completion_length': 297.25, 'kl': 0.005473846395034343, 'epoch': 3.67}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 275/500 [5:11:37<4:30:18, 72.08s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 276/500 [5:12:50<4:30:25, 72.44s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.9820722341537476, 'learning_rate': 2.5e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.453125, 'reward': 2.203125, 'reward_std': 0.9746235311031342, 'completion_length': 291.9375, 'kl': 0.010373580385930836, 'epoch': 3.68}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 276/500 [5:12:50<4:30:25, 72.44s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 277/500 [5:14:02<4:28:53, 72.35s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.7535996437072754, 'learning_rate': 2.482546849255096e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 0.7886751294136047, 'completion_length': 316.3125, 'kl': 0.007985296426340938, 'epoch': 3.69}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 277/500 [5:14:02<4:28:53, 72.35s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 278/500 [5:15:12<4:24:51, 71.58s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.9879972338676453, 'learning_rate': 2.4650945491521372e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0773502588272095, 'completion_length': 300.5, 'kl': 0.0060297801392152905, 'epoch': 3.71}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 278/500 [5:15:12<4:24:51, 71.58s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 279/500 [5:16:22<4:22:14, 71.20s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.7827169895172119, 'learning_rate': 2.447643950291608e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.7886751294136047, 'completion_length': 307.3125, 'kl': 0.008424962405115366, 'epoch': 3.72}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 279/500 [5:16:22<4:22:14, 71.20s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 280/500 [5:17:43<4:31:36, 74.07s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.9664527773857117, 'learning_rate': 2.4301959031910785e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0773502588272095, 'completion_length': 331.6875, 'kl': 0.006553374230861664, 'epoch': 3.73}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 280/500 [5:17:43<4:31:36, 74.07s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 281/500 [5:18:53<4:25:37, 72.78s/it]                                                     {'loss': 0.0006, 'grad_norm': 0.9980664849281311, 'learning_rate': 2.4127512582437486e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.109375, 'reward_std': 1.0507531762123108, 'completion_length': 295.5625, 'kl': 0.015102081873919815, 'epoch': 3.75}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 281/500 [5:18:53<4:25:37, 72.78s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 282/500 [5:19:54<4:11:22, 69.19s/it]                                                     {'loss': 0.0009, 'grad_norm': 1.021619439125061, 'learning_rate': 2.3953108656770018e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.6875, 'reward_std': 1.1419267058372498, 'completion_length': 270.0625, 'kl': 0.02294199529569596, 'epoch': 3.76}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 282/500 [5:19:54<4:11:22, 69.19s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 283/500 [5:20:56<4:03:00, 67.19s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.7399342656135559, 'learning_rate': 2.377875575510967e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.5, 'reward_std': 0.7886751294136047, 'completion_length': 287.125, 'kl': 0.011871206690557301, 'epoch': 3.77}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 283/500 [5:20:56<4:03:00, 67.19s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 284/500 [5:22:08<4:06:21, 68.43s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.7926152944564819, 'learning_rate': 2.3604462375170905e-06, 'rewards/cot_correctness_reward_func': 0.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.453125, 'reward': 1.203125, 'reward_std': 0.5584194660186768, 'completion_length': 318.3125, 'kl': 0.012150914291851223, 'epoch': 3.79}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 284/500 [5:22:08<4:06:21, 68.43s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 285/500 [5:23:18<4:07:26, 69.05s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.7489076852798462, 'learning_rate': 2.3430237011767166e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 0.5, 'completion_length': 299.6875, 'kl': 0.005494185374118388, 'epoch': 3.8}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 285/500 [5:23:18<4:07:26, 69.05s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 286/500 [5:23:59<3:36:03, 60.58s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.85545814037323, 'learning_rate': 2.325608815639687e-06, 'rewards/cot_correctness_reward_func': 1.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.5, 'reward_std': 0.5773502588272095, 'completion_length': 141.0, 'kl': 0.012019194895401597, 'epoch': 3.81}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 286/500 [5:23:59<3:36:03, 60.58s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 287/500 [5:24:35<3:08:53, 53.21s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.278243899345398, 'learning_rate': 2.3082024296829538e-06, 'rewards/cot_correctness_reward_func': 1.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.46875, 'reward_std': 0.8113132566213608, 'completion_length': 133.8125, 'kl': 0.014212144538760185, 'epoch': 3.83}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 287/500 [5:24:35<3:08:53, 53.21s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 288/500 [5:25:18<2:57:02, 50.11s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.3720594644546509, 'learning_rate': 2.290805391669212e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 1.0386751294136047, 'completion_length': 156.8125, 'kl': 0.012188847293145955, 'epoch': 3.84}
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 288/500 [5:25:18<2:57:02, 50.11s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 289/500 [5:26:00<2:47:21, 47.59s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.0894131660461426, 'learning_rate': 2.2734185495055503e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.234375, 'reward_std': 0.7574251294136047, 'completion_length': 150.5, 'kl': 0.014211753383278847, 'epoch': 3.85}
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 289/500 [5:26:00<2:47:21, 47.59s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 290/500 [5:26:45<2:44:14, 46.93s/it]                                                     {'loss': 0.0013, 'grad_norm': 1.375766396522522, 'learning_rate': 2.256042750602127e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.9375, 'reward_std': 1.0862346291542053, 'completion_length': 159.375, 'kl': 0.033069428289309144, 'epoch': 3.87}
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 290/500 [5:26:45<2:44:14, 46.93s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 291/500 [5:27:16<2:26:42, 42.12s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.3065414428710938, 'learning_rate': 2.238678841830867e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.234375, 'reward_std': 0.991388127207756, 'completion_length': 124.875, 'kl': 0.012360656633973122, 'epoch': 3.88}
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 291/500 [5:27:16<2:26:42, 42.12s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 292/500 [5:27:54<2:22:25, 41.08s/it]                                                     {'loss': 0.0011, 'grad_norm': 1.466983675956726, 'learning_rate': 2.2213276694841866e-06, 'rewards/cot_correctness_reward_func': 1.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.453125, 'reward': 2.453125, 'reward_std': 1.09375, 'completion_length': 139.8125, 'kl': 0.02709193853661418, 'epoch': 3.89}
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 292/500 [5:27:54<2:22:25, 41.08s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 293/500 [5:28:24<2:09:43, 37.60s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.4834249019622803, 'learning_rate': 2.2039900792337477e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 1.0773502588272095, 'completion_length': 115.9375, 'kl': 0.01327479537576437, 'epoch': 3.91}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 293/500 [5:28:24<2:09:43, 37.60s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 294/500 [5:29:01<2:08:03, 37.30s/it]                                                     {'loss': 0.0007, 'grad_norm': 1.0960646867752075, 'learning_rate': 2.186666916089239e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 0.8273502588272095, 'completion_length': 137.9375, 'kl': 0.017751186154782772, 'epoch': 3.92}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 294/500 [5:29:01<2:08:03, 37.30s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 295/500 [5:29:39<2:08:50, 37.71s/it]                                                     {'loss': 0.0035, 'grad_norm': 2.6789584159851074, 'learning_rate': 2.1693590243571937e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.9375, 'reward_std': 1.077557697892189, 'completion_length': 139.375, 'kl': 0.08662800036836416, 'epoch': 3.93}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 295/500 [5:29:39<2:08:50, 37.71s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 296/500 [5:30:18<2:08:59, 37.94s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.3203063011169434, 'learning_rate': 2.1520672475998374e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.234375, 'reward_std': 1.0687383860349655, 'completion_length': 133.25, 'kl': 0.013737407163716853, 'epoch': 3.95}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 296/500 [5:30:18<2:08:59, 37.94s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 297/500 [5:30:49<2:01:24, 35.88s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.8393783569335938, 'learning_rate': 2.134792428593971e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 1.0386751294136047, 'completion_length': 123.75, 'kl': 0.013996005291119218, 'epoch': 3.96}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 297/500 [5:30:49<2:01:24, 35.88s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 298/500 [5:31:21<1:57:22, 34.86s/it]                                                     {'loss': 0.0016, 'grad_norm': 1.0501196384429932, 'learning_rate': 2.117535409289905e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.453125, 'reward': 2.296875, 'reward_std': 0.40625, 'completion_length': 127.875, 'kl': 0.039059600327163935, 'epoch': 3.97}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 298/500 [5:31:21<1:57:22, 34.86s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 299/500 [5:31:57<1:57:43, 35.14s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.2731484174728394, 'learning_rate': 2.1002970307704134e-06, 'rewards/cot_correctness_reward_func': 1.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.5, 'reward_std': 1.0, 'completion_length': 131.75, 'kl': 0.007815392746124417, 'epoch': 3.99}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 299/500 [5:31:57<1:57:43, 35.14s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 300/500 [5:32:32<1:57:02, 35.11s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.5351704359054565, 'learning_rate': 2.0830781332097446e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.1160253882408142, 'completion_length': 133.875, 'kl': 0.011179761844687164, 'epoch': 4.0}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 300/500 [5:32:32<1:57:02, 35.11s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 301/500 [5:33:23<2:12:18, 39.89s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.8774746656417847, 'learning_rate': 2.0658795558326745e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 0.8273502588272095, 'completion_length': 215.9375, 'kl': 0.008449395769275725, 'epoch': 4.01}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 301/500 [5:33:23<2:12:18, 39.89s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 302/500 [5:34:17<2:25:54, 44.21s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.0893138647079468, 'learning_rate': 2.0487021368736002e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.154700517654419, 'completion_length': 237.75, 'kl': 0.011322346632368863, 'epoch': 4.03}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 302/500 [5:34:17<2:25:54, 44.21s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 303/500 [5:35:10<2:33:45, 46.83s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.0569818019866943, 'learning_rate': 2.031546713535688e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0773502588272095, 'completion_length': 219.25, 'kl': 0.008045447058975697, 'epoch': 4.04}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 303/500 [5:35:10<2:33:45, 46.83s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 304/500 [5:36:09<2:44:21, 50.31s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.1021844148635864, 'learning_rate': 2.0144141219500707e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 1.0386751294136047, 'completion_length': 242.25, 'kl': 0.009218076709657907, 'epoch': 4.05}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 304/500 [5:36:09<2:44:21, 50.31s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 305/500 [5:37:09<2:52:42, 53.14s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.9818606376647949, 'learning_rate': 1.997305197135089e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.453125, 'reward': 2.078125, 'reward_std': 1.085804522037506, 'completion_length': 226.1875, 'kl': 0.013395167188718915, 'epoch': 4.07}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 305/500 [5:37:09<2:52:42, 53.14s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 306/500 [5:38:07<2:56:54, 54.71s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.0057156085968018, 'learning_rate': 1.9802207729556023e-06, 'rewards/cot_correctness_reward_func': 1.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.5, 'reward_std': 0.7886751294136047, 'completion_length': 215.5, 'kl': 0.007097845198586583, 'epoch': 4.08}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 306/500 [5:38:07<2:56:54, 54.71s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 307/500 [5:38:55<2:49:57, 52.84s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.0213170051574707, 'learning_rate': 1.963161682082342e-06, 'rewards/cot_correctness_reward_func': 1.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.5, 'reward_std': 0.7886751294136047, 'completion_length': 206.4375, 'kl': 0.007892464869655669, 'epoch': 4.09}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 307/500 [5:38:55<2:49:57, 52.84s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 308/500 [5:39:50<2:50:36, 53.32s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.001475214958191, 'learning_rate': 1.946128755951332e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 1.0, 'completion_length': 218.9375, 'kl': 0.005682895076461136, 'epoch': 4.11}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 308/500 [5:39:50<2:50:36, 53.32s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 309/500 [5:40:43<2:49:29, 53.24s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.0992965698242188, 'learning_rate': 1.9291228247233607e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.0386751294136047, 'completion_length': 221.125, 'kl': 0.010380475781857967, 'epoch': 4.12}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 309/500 [5:40:43<2:49:29, 53.24s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 310/500 [5:41:39<2:51:00, 54.00s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.0528950691223145, 'learning_rate': 1.912144717243525e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.359375, 'reward_std': 0.8586002588272095, 'completion_length': 221.9375, 'kl': 0.014267695252783597, 'epoch': 4.13}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 310/500 [5:41:39<2:51:00, 54.00s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 311/500 [5:42:30<2:47:08, 53.06s/it]                                                     {'loss': 0.0007, 'grad_norm': 0.6787773370742798, 'learning_rate': 1.895195261000831e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 0.5773502588272095, 'completion_length': 214.1875, 'kl': 0.0165282366797328, 'epoch': 4.15}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 311/500 [5:42:30<2:47:08, 53.06s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 312/500 [5:43:17<2:41:25, 51.52s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.0250139236450195, 'learning_rate': 1.8782752820878636e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.0386751294136047, 'completion_length': 217.4375, 'kl': 0.005873110610991716, 'epoch': 4.16}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 312/500 [5:43:17<2:41:25, 51.52s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 313/500 [5:44:01<2:32:59, 49.09s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.1152012348175049, 'learning_rate': 1.8613856051605242e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0, 'completion_length': 197.9375, 'kl': 0.009500469896011055, 'epoch': 4.17}
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 313/500 [5:44:01<2:32:59, 49.09s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 314/500 [5:45:08<2:48:30, 54.36s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.8326742053031921, 'learning_rate': 1.8445270533978387e-06, 'rewards/cot_correctness_reward_func': 1.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.625, 'reward_std': 0.5386751294136047, 'completion_length': 246.5, 'kl': 0.007585099432617426, 'epoch': 4.19}
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 314/500 [5:45:08<2:48:30, 54.36s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 315/500 [5:46:17<3:01:41, 58.92s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.8089378476142883, 'learning_rate': 1.827700448461836e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.71875, 'reward_std': 0.8158445954322815, 'completion_length': 259.125, 'kl': 0.007282392762135714, 'epoch': 4.2}
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 315/500 [5:46:17<3:01:41, 58.92s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 316/500 [5:47:07<2:52:45, 56.34s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.5303488373756409, 'learning_rate': 1.8109066104575023e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 0.25, 'completion_length': 212.9375, 'kl': 0.010156761156395078, 'epoch': 4.21}
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 316/500 [5:47:07<2:52:45, 56.34s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 317/500 [5:48:02<2:50:00, 55.74s/it]                                                     {'loss': 0.0006, 'grad_norm': 0.9955044984817505, 'learning_rate': 1.7941463578928088e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0773502588272095, 'completion_length': 229.9375, 'kl': 0.01431828155182302, 'epoch': 4.23}
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 317/500 [5:48:02<2:50:00, 55.74s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 318/500 [5:48:50<2:42:18, 53.51s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.1445904970169067, 'learning_rate': 1.7774205076388207e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.1160253882408142, 'completion_length': 203.875, 'kl': 0.0063245726632885635, 'epoch': 4.24}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 318/500 [5:48:50<2:42:18, 53.51s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 319/500 [5:49:42<2:40:23, 53.17s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.8258764147758484, 'learning_rate': 1.7607298748898844e-06, 'rewards/cot_correctness_reward_func': 1.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.5, 'reward_std': 0.5773502588272095, 'completion_length': 213.375, 'kl': 0.007229543756693602, 'epoch': 4.25}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 319/500 [5:49:42<2:40:23, 53.17s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 320/500 [5:51:02<3:03:20, 61.11s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.2324200868606567, 'learning_rate': 1.744075273123889e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.0386751294136047, 'completion_length': 242.875, 'kl': 0.007447367417626083, 'epoch': 4.27}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 320/500 [5:51:02<3:03:20, 61.11s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 321/500 [5:51:58<2:57:27, 59.48s/it]                                                     {'loss': 0.0012, 'grad_norm': 1.367077350616455, 'learning_rate': 1.7274575140626318e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.484375, 'reward_std': 0.96875, 'completion_length': 228.0, 'kl': 0.031167116714641452, 'epoch': 4.28}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 321/500 [5:51:58<2:57:27, 59.48s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 322/500 [5:54:28<4:16:56, 86.61s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.7775326371192932, 'learning_rate': 1.7108774076322443e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.09375, 'reward_std': 0.7771694660186768, 'completion_length': 362.9375, 'kl': 0.00808596657589078, 'epoch': 4.29}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 322/500 [5:54:28<4:16:56, 86.61s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 323/500 [5:55:16<3:41:29, 75.08s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.2426060438156128, 'learning_rate': 1.6943357619237227e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.734375, 'reward_std': 1.0894283056259155, 'completion_length': 202.5, 'kl': 0.008780969656072557, 'epoch': 4.31}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 323/500 [5:55:16<3:41:29, 75.08s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 324/500 [5:56:07<3:18:47, 67.77s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.0399463176727295, 'learning_rate': 1.677833383153542e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.7886751294136047, 'completion_length': 210.0, 'kl': 0.006421222700737417, 'epoch': 4.32}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 324/500 [5:56:07<3:18:47, 67.77s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 325/500 [5:56:57<3:02:50, 62.69s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.9769577980041504, 'learning_rate': 1.661371075624363e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.1160253882408142, 'completion_length': 214.5625, 'kl': 0.005162538145668805, 'epoch': 4.33}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 325/500 [5:56:57<3:02:50, 62.69s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 326/500 [5:58:03<3:04:09, 63.50s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.0267863273620605, 'learning_rate': 1.6449496416858285e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.484375, 'reward_std': 0.7574251294136047, 'completion_length': 296.1875, 'kl': 0.01576753461267799, 'epoch': 4.35}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 326/500 [5:58:03<3:04:09, 63.50s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 327/500 [5:59:08<3:04:51, 64.11s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.0390077829360962, 'learning_rate': 1.6285698816954626e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.0386751294136047, 'completion_length': 304.5625, 'kl': 0.00579758919775486, 'epoch': 4.36}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 327/500 [5:59:08<3:04:51, 64.11s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 328/500 [6:00:14<3:05:25, 64.69s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.7894570231437683, 'learning_rate': 1.612232593979658e-06, 'rewards/cot_correctness_reward_func': 1.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.5, 'reward_std': 0.7886751294136047, 'completion_length': 290.0625, 'kl': 0.005800345039460808, 'epoch': 4.37}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 328/500 [6:00:14<3:05:25, 64.69s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 329/500 [6:01:21<3:06:08, 65.32s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.8686428070068359, 'learning_rate': 1.5959385747947697e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.0386751294136047, 'completion_length': 285.75, 'kl': 0.00933048315346241, 'epoch': 4.39}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 329/500 [6:01:21<3:06:08, 65.32s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 330/500 [6:02:30<3:08:13, 66.43s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.860905110836029, 'learning_rate': 1.5796886182883053e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0773502588272095, 'completion_length': 303.9375, 'kl': 0.006882373709231615, 'epoch': 4.4}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 330/500 [6:02:30<3:08:13, 66.43s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 331/500 [6:04:22<3:45:36, 80.10s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8866181969642639, 'learning_rate': 1.56348351646022e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.96875, 'reward_std': 1.117419570684433, 'completion_length': 377.0625, 'kl': 0.004483207419980317, 'epoch': 4.41}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 331/500 [6:04:22<3:45:36, 80.10s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 332/500 [6:05:53<3:53:27, 83.38s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8027912974357605, 'learning_rate': 1.547324059124315e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.46875, 'reward_std': 1.0271694660186768, 'completion_length': 357.1875, 'kl': 0.0056946888216771185, 'epoch': 4.43}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 332/500 [6:05:53<3:53:27, 83.38s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 333/500 [6:07:00<3:38:08, 78.37s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.6718214750289917, 'learning_rate': 1.5312110338697427e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.7886751294136047, 'completion_length': 299.75, 'kl': 0.005144223105162382, 'epoch': 4.44}
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 333/500 [6:07:00<3:38:08, 78.37s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 334/500 [6:08:04<3:25:19, 74.21s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8323937654495239, 'learning_rate': 1.5151452260226224e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 1.0, 'completion_length': 298.6875, 'kl': 0.005193179007619619, 'epoch': 4.45}
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 334/500 [6:08:04<3:25:19, 74.21s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 335/500 [6:09:12<3:18:37, 72.23s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.8045186996459961, 'learning_rate': 1.4991274186077632e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 0.8660253882408142, 'completion_length': 288.9375, 'kl': 0.008524817181751132, 'epoch': 4.47}
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 335/500 [6:09:12<3:18:37, 72.23s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 336/500 [6:10:28<3:20:53, 73.50s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.0381094217300415, 'learning_rate': 1.4831583923105e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.109375, 'reward_std': 1.0507531762123108, 'completion_length': 314.1875, 'kl': 0.014215708361007273, 'epoch': 4.48}
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 336/500 [6:10:28<3:20:53, 73.50s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 337/500 [6:11:37<3:15:53, 72.11s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.9670249819755554, 'learning_rate': 1.467238925438646e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.71875, 'reward_std': 1.117419570684433, 'completion_length': 306.625, 'kl': 0.007836740231141448, 'epoch': 4.49}
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 337/500 [6:11:37<3:15:53, 72.11s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 338/500 [6:13:00<3:22:55, 75.16s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.9369950890541077, 'learning_rate': 1.4513697938845571e-06, 'rewards/cot_correctness_reward_func': 0.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.375, 'reward_std': 0.75, 'completion_length': 299.8125, 'kl': 0.008146294974721968, 'epoch': 4.51}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 338/500 [6:13:00<3:22:55, 75.16s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 339/500 [6:14:08<3:16:12, 73.12s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.066004753112793, 'learning_rate': 1.4355517710873184e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.46875, 'reward_std': 0.8511751294136047, 'completion_length': 305.5, 'kl': 0.010613422025926411, 'epoch': 4.52}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 339/500 [6:14:08<3:16:12, 73.12s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 340/500 [6:15:15<3:10:04, 71.28s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.9743037223815918, 'learning_rate': 1.419785627995044e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 0.75, 'completion_length': 291.6875, 'kl': 0.006006237177643925, 'epoch': 4.53}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 340/500 [6:15:15<3:10:04, 71.28s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 341/500 [6:16:35<3:15:36, 73.82s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.6497418880462646, 'learning_rate': 1.4040721330273063e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 0.5386751294136047, 'completion_length': 316.3125, 'kl': 0.004429698048625141, 'epoch': 4.55}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 341/500 [6:16:35<3:15:36, 73.82s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 342/500 [6:17:48<3:14:08, 73.72s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8907492756843567, 'learning_rate': 1.388412052037682e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0773502588272095, 'completion_length': 320.625, 'kl': 0.005196295911446214, 'epoch': 4.56}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 342/500 [6:17:48<3:14:08, 73.72s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 343/500 [6:18:53<3:05:44, 70.99s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.8593060970306396, 'learning_rate': 1.3728061482764238e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.84375, 'reward_std': 1.143194854259491, 'completion_length': 301.5, 'kl': 0.009926582803018391, 'epoch': 4.57}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 343/500 [6:18:53<3:05:44, 70.99s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 344/500 [6:20:00<3:01:55, 69.97s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.9038005471229553, 'learning_rate': 1.3572551823532654e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.09375, 'reward_std': 1.0850443542003632, 'completion_length': 304.625, 'kl': 0.007269481488037854, 'epoch': 4.59}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 344/500 [6:20:00<3:01:55, 69.97s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 345/500 [6:21:23<3:10:20, 73.68s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.9663606286048889, 'learning_rate': 1.3417599122003464e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.96875, 'reward_std': 1.1045197248458862, 'completion_length': 346.4375, 'kl': 0.006194439018145204, 'epoch': 4.6}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 345/500 [6:21:23<3:10:20, 73.68s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 346/500 [6:22:37<3:09:17, 73.75s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.0342144966125488, 'learning_rate': 1.3263210930352737e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 301.75, 'kl': 0.00794397690333426, 'epoch': 4.61}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 346/500 [6:22:37<3:09:17, 73.75s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 347/500 [6:23:41<3:01:05, 71.02s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.9428725242614746, 'learning_rate': 1.3109394773243117e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 0.75, 'completion_length': 287.5625, 'kl': 0.006379029247909784, 'epoch': 4.63}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 347/500 [6:23:41<3:01:05, 71.02s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 348/500 [6:24:51<2:58:47, 70.58s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.9444606900215149, 'learning_rate': 1.2956158147457116e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 0.8273502588272095, 'completion_length': 299.1875, 'kl': 0.009748670039698482, 'epoch': 4.64}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 348/500 [6:24:51<2:58:47, 70.58s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 349/500 [6:26:25<3:15:13, 77.57s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.8894540071487427, 'learning_rate': 1.280350852153168e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.7886751294136047, 'completion_length': 349.4375, 'kl': 0.006631495431065559, 'epoch': 4.65}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 349/500 [6:26:25<3:15:13, 77.57s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 350/500 [6:27:33<3:07:14, 74.90s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.0255930423736572, 'learning_rate': 1.2651453335394232e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 0.75, 'completion_length': 283.375, 'kl': 0.005023519915994257, 'epoch': 4.67}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 350/500 [6:27:33<3:07:14, 74.90s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 351/500 [6:28:38<2:58:17, 71.79s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.9290270209312439, 'learning_rate': 1.2500000000000007e-06, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 291.1875, 'kl': 0.006481059535872191, 'epoch': 4.68}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 351/500 [6:28:38<2:58:17, 71.79s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 352/500 [6:29:52<2:58:43, 72.45s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.8661218285560608, 'learning_rate': 1.234915589697091e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 0.7886751294136047, 'completion_length': 294.0, 'kl': 0.009288148605264723, 'epoch': 4.69}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 352/500 [6:29:52<2:58:43, 72.45s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 353/500 [6:31:39<3:23:19, 82.99s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.9956579804420471, 'learning_rate': 1.2198928378235717e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.5625, 'reward_std': 1.105913907289505, 'completion_length': 350.625, 'kl': 0.008059867424890399, 'epoch': 4.71}
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 353/500 [6:31:39<3:23:19, 82.99s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 354/500 [6:32:44<3:08:38, 77.52s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.886538028717041, 'learning_rate': 1.204932476567175e-06, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.7886751294136047, 'completion_length': 295.5625, 'kl': 0.008292560814879835, 'epoch': 4.72}
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 354/500 [6:32:44<3:08:38, 77.52s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 355/500 [6:33:59<3:05:36, 76.80s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.0620958805084229, 'learning_rate': 1.1900352350748026e-06, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.578125, 'reward_std': 1.1012440621852875, 'completion_length': 304.4375, 'kl': 0.010499558236915618, 'epoch': 4.73}
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 355/500 [6:33:59<3:05:36, 76.80s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 356/500 [6:35:08<2:58:47, 74.50s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.9921562075614929, 'learning_rate': 1.1752018394169882e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.0386751294136047, 'completion_length': 304.25, 'kl': 0.007524672197178006, 'epoch': 4.75}
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 356/500 [6:35:08<2:58:47, 74.50s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 357/500 [6:36:21<2:56:12, 73.94s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8909348249435425, 'learning_rate': 1.160433012552508e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.5, 'reward_std': 1.0, 'completion_length': 305.9375, 'kl': 0.005359219678211957, 'epoch': 4.76}
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 357/500 [6:36:21<2:56:12, 73.94s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 358/500 [6:37:32<2:52:46, 73.00s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.7461050152778625, 'learning_rate': 1.1457294742931508e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.5, 'reward_std': 0.7886751294136047, 'completion_length': 313.1875, 'kl': 0.0073780257953330874, 'epoch': 4.77}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 358/500 [6:37:32<2:52:46, 73.00s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 359/500 [6:38:49<2:54:06, 74.09s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.9011503458023071, 'learning_rate': 1.1310919412686248e-06, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.5, 'reward_std': 1.0, 'completion_length': 337.625, 'kl': 0.010167031607124954, 'epoch': 4.79}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 359/500 [6:38:49<2:54:06, 74.09s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 360/500 [6:39:54<2:47:03, 71.60s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.7034633755683899, 'learning_rate': 1.11652112689164e-06, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 0.5386751294136047, 'completion_length': 300.0625, 'kl': 0.005421105888672173, 'epoch': 4.8}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 360/500 [6:39:54<2:47:03, 71.60s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 361/500 [6:40:32<2:22:30, 61.51s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.0057121515274048, 'learning_rate': 1.1020177413231334e-06, 'rewards/cot_correctness_reward_func': 1.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.5, 'reward_std': 0.7886751294136047, 'completion_length': 129.125, 'kl': 0.011110636172816157, 'epoch': 4.81}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 361/500 [6:40:32<2:22:30, 61.51s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 362/500 [6:41:04<2:01:07, 52.67s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.42499577999115, 'learning_rate': 1.0875824914376555e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.234375, 'reward_std': 0.8199251294136047, 'completion_length': 123.6875, 'kl': 0.01476147654466331, 'epoch': 4.83}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 362/500 [6:41:04<2:01:07, 52.67s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 363/500 [6:41:41<1:49:10, 47.81s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.9668908715248108, 'learning_rate': 1.073216080788921e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 0.75, 'completion_length': 136.0625, 'kl': 0.012424886925145984, 'epoch': 4.84}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 363/500 [6:41:41<1:49:10, 47.81s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 364/500 [6:42:16<1:39:34, 43.93s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.9059655666351318, 'learning_rate': 1.0589192095755172e-06, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 0.75, 'completion_length': 135.0, 'kl': 0.008823501993902028, 'epoch': 4.85}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 364/500 [6:42:16<1:39:34, 43.93s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 365/500 [6:42:56<1:36:31, 42.90s/it]                                                     {'loss': 0.0012, 'grad_norm': 1.4827767610549927, 'learning_rate': 1.0446925746067768e-06, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.453125, 'reward': 1.828125, 'reward_std': 1.1393289864063263, 'completion_length': 146.5, 'kl': 0.02964415878523141, 'epoch': 4.87}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 365/500 [6:42:56<1:36:31, 42.90s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 366/500 [6:43:29<1:28:50, 39.78s/it]                                                     {'loss': 0.001, 'grad_norm': 1.3586630821228027, 'learning_rate': 1.0305368692688175e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.21875, 'reward_std': 1.0625, 'completion_length': 129.625, 'kl': 0.02452627196907997, 'epoch': 4.88}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 366/500 [6:43:29<1:28:50, 39.78s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 367/500 [6:44:10<1:29:02, 40.17s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.2023143768310547, 'learning_rate': 1.0164527834907468e-06, 'rewards/cot_correctness_reward_func': 1.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.609375, 'reward_std': 0.5699251294136047, 'completion_length': 140.1875, 'kl': 0.009776882245205343, 'epoch': 4.89}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 367/500 [6:44:10<1:29:02, 40.17s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 368/500 [6:44:44<1:24:21, 38.34s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.2737725973129272, 'learning_rate': 1.0024410037110358e-06, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.234375, 'reward_std': 1.0605082213878632, 'completion_length': 127.0625, 'kl': 0.01274081994779408, 'epoch': 4.91}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 368/500 [6:44:44<1:24:21, 38.34s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 369/500 [6:45:25<1:25:40, 39.24s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.2330106496810913, 'learning_rate': 9.88502212844063e-07, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.359375, 'reward_std': 1.0300632566213608, 'completion_length': 145.1875, 'kl': 0.014027048833668232, 'epoch': 4.92}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 369/500 [6:45:25<1:25:40, 39.24s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 370/500 [6:46:01<1:22:54, 38.27s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.482061743736267, 'learning_rate': 9.746370902468311e-07, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.859375, 'reward_std': 0.8464519381523132, 'completion_length': 135.8125, 'kl': 0.013715180335566401, 'epoch': 4.93}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 370/500 [6:46:01<1:22:54, 38.27s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 371/500 [6:46:41<1:22:57, 38.59s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.8213074207305908, 'learning_rate': 9.608463116858544e-07, 'rewards/cot_correctness_reward_func': 1.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.46875, 'reward_std': 0.5796099007129669, 'completion_length': 136.5625, 'kl': 0.012935820035636425, 'epoch': 4.95}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 371/500 [6:46:41<1:22:57, 38.59s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 372/500 [6:47:25<1:26:13, 40.42s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.3507198095321655, 'learning_rate': 9.471305493042243e-07, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.234375, 'reward_std': 0.8972753882408142, 'completion_length': 143.6875, 'kl': 0.011753682047128677, 'epoch': 4.96}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 372/500 [6:47:25<1:26:13, 40.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 373/500 [6:47:59<1:21:03, 38.30s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.2013143301010132, 'learning_rate': 9.334904715888496e-07, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.359375, 'reward_std': 1.0300632566213608, 'completion_length': 125.25, 'kl': 0.010981842642650008, 'epoch': 4.97}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 373/500 [6:47:59<1:21:03, 38.30s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 374/500 [6:48:30<1:16:14, 36.30s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.2562147378921509, 'learning_rate': 9.199267433378728e-07, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 0.8273502588272095, 'completion_length': 123.0, 'kl': 0.012878297595307231, 'epoch': 4.99}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 374/500 [6:48:30<1:16:14, 36.30s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 375/500 [6:49:05<1:14:46, 35.89s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.2809364795684814, 'learning_rate': 9.064400256282757e-07, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 0.8273502588272095, 'completion_length': 133.0625, 'kl': 0.009075609617866576, 'epoch': 5.0}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 375/500 [6:49:05<1:14:46, 35.89s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 376/500 [6:49:56<1:23:38, 40.47s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.092426061630249, 'learning_rate': 8.930309757836517e-07, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 0.8273502588272095, 'completion_length': 208.4375, 'kl': 0.010550608043558896, 'epoch': 5.01}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 376/500 [6:49:56<1:23:38, 40.47s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 377/500 [6:50:45<1:28:10, 43.01s/it]                                                     {'loss': 0.0008, 'grad_norm': 1.3333922624588013, 'learning_rate': 8.797002473421729e-07, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.6875, 'reward_std': 0.8912444412708282, 'completion_length': 204.5, 'kl': 0.020951658836565912, 'epoch': 5.03}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 377/500 [6:50:45<1:28:10, 43.01s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 378/500 [6:51:39<1:33:58, 46.22s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.1402618885040283, 'learning_rate': 8.664484900247363e-07, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.0386751294136047, 'completion_length': 225.6875, 'kl': 0.014966607908718288, 'epoch': 5.04}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 378/500 [6:51:39<1:33:58, 46.22s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 379/500 [6:52:31<1:36:46, 47.99s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.0490556955337524, 'learning_rate': 8.532763497032987e-07, 'rewards/cot_correctness_reward_func': 0.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.453125, 'reward': 1.328125, 'reward_std': 0.5074251294136047, 'completion_length': 214.625, 'kl': 0.010574570740573108, 'epoch': 5.05}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 379/500 [6:52:31<1:36:46, 47.99s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 380/500 [6:53:34<1:44:54, 52.46s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.1204142570495605, 'learning_rate': 8.40184468369396e-07, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.1160253882408142, 'completion_length': 240.25, 'kl': 0.010998978512361646, 'epoch': 5.07}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 380/500 [6:53:34<1:44:54, 52.46s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 381/500 [6:54:30<1:45:59, 53.44s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.5750774145126343, 'learning_rate': 8.271734841028553e-07, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.0386751294136047, 'completion_length': 216.125, 'kl': 0.008567230426706374, 'epoch': 5.08}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 381/500 [6:54:30<1:45:59, 53.44s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 382/500 [6:55:27<1:47:15, 54.54s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.8915998339653015, 'learning_rate': 8.142440310406923e-07, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 0.75, 'completion_length': 231.6875, 'kl': 0.008821386494673789, 'epoch': 5.09}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 382/500 [6:55:27<1:47:15, 54.54s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 383/500 [6:56:22<1:46:41, 54.72s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.9693184494972229, 'learning_rate': 8.013967393462094e-07, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.0386751294136047, 'completion_length': 230.75, 'kl': 0.005823691957630217, 'epoch': 5.11}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 383/500 [6:56:22<1:46:41, 54.72s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 384/500 [6:57:14<1:44:14, 53.92s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.3901344537734985, 'learning_rate': 7.886322351782782e-07, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 214.125, 'kl': 0.01220225146971643, 'epoch': 5.12}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 384/500 [6:57:14<1:44:14, 53.92s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 385/500 [6:58:04<1:40:57, 52.67s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.0357216596603394, 'learning_rate': 7.759511406608255e-07, 'rewards/cot_correctness_reward_func': 1.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.5, 'reward_std': 0.7886751294136047, 'completion_length': 215.1875, 'kl': 0.007073649554513395, 'epoch': 5.13}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 385/500 [6:58:04<1:40:57, 52.67s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 386/500 [6:58:59<1:41:46, 53.57s/it]                                                     {'loss': 0.0007, 'grad_norm': 1.2277194261550903, 'learning_rate': 7.633540738525066e-07, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.109375, 'reward_std': 0.78125, 'completion_length': 228.125, 'kl': 0.016842430573888123, 'epoch': 5.15}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 386/500 [6:58:59<1:41:46, 53.57s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 387/500 [6:59:55<1:42:08, 54.24s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.1007888317108154, 'learning_rate': 7.508416487165862e-07, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 221.125, 'kl': 0.011660955904517323, 'epoch': 5.16}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 387/500 [6:59:55<1:42:08, 54.24s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 388/500 [7:00:47<1:40:03, 53.61s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.099888801574707, 'learning_rate': 7.384144750910133e-07, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0773502588272095, 'completion_length': 224.6875, 'kl': 0.01094668300356716, 'epoch': 5.17}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 388/500 [7:00:47<1:40:03, 53.61s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 389/500 [7:01:43<1:40:13, 54.18s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.9371972680091858, 'learning_rate': 7.260731586586983e-07, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 226.875, 'kl': 0.00923574308399111, 'epoch': 5.19}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 389/500 [7:01:43<1:40:13, 54.18s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 390/500 [7:02:50<1:46:32, 58.12s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.1482512950897217, 'learning_rate': 7.138183009179922e-07, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0773502588272095, 'completion_length': 257.1875, 'kl': 0.006864691851660609, 'epoch': 5.2}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 390/500 [7:02:50<1:46:32, 58.12s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 391/500 [7:03:49<1:46:06, 58.41s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.5138086080551147, 'learning_rate': 7.016504991533727e-07, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.28867512941360474, 'completion_length': 225.0625, 'kl': 0.007748615578748286, 'epoch': 5.21}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 391/500 [7:03:49<1:46:06, 58.41s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 392/500 [7:04:43<1:42:50, 57.14s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.004421591758728, 'learning_rate': 6.895703464063319e-07, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.96875, 'reward_std': 1.117419570684433, 'completion_length': 223.1875, 'kl': 0.011739080888219178, 'epoch': 5.23}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 392/500 [7:04:43<1:42:50, 57.14s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 393/500 [7:05:39<1:40:56, 56.61s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.8024279475212097, 'learning_rate': 6.775784314464717e-07, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 0.8273502588272095, 'completion_length': 216.6875, 'kl': 0.010421291925013065, 'epoch': 5.24}
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 393/500 [7:05:39<1:40:56, 56.61s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 394/500 [7:06:28<1:36:03, 54.37s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.5763141512870789, 'learning_rate': 6.656753387428089e-07, 'rewards/cot_correctness_reward_func': 1.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.875, 'reward_std': 0.25, 'completion_length': 203.125, 'kl': 0.009164818795397878, 'epoch': 5.25}
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 394/500 [7:06:28<1:36:03, 54.37s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 395/500 [7:07:13<1:30:23, 51.65s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.06935715675354, 'learning_rate': 6.538616484352902e-07, 'rewards/cot_correctness_reward_func': 0.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.375, 'reward_std': 0.75, 'completion_length': 179.875, 'kl': 0.01380239543505013, 'epoch': 5.27}
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 395/500 [7:07:13<1:30:23, 51.65s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 396/500 [7:08:04<1:28:49, 51.25s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.1104154586791992, 'learning_rate': 6.421379363065142e-07, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.859375, 'reward_std': 1.0507531762123108, 'completion_length': 210.3125, 'kl': 0.008606726420111954, 'epoch': 5.28}
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 396/500 [7:08:04<1:28:49, 51.25s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 397/500 [7:08:58<1:29:50, 52.34s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.9837054014205933, 'learning_rate': 6.305047737536707e-07, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.7886751294136047, 'completion_length': 223.6875, 'kl': 0.007350174128077924, 'epoch': 5.29}
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 397/500 [7:08:58<1:29:50, 52.34s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 398/500 [7:09:55<1:31:22, 53.75s/it]                                                     {'loss': 0.001, 'grad_norm': 1.1541856527328491, 'learning_rate': 6.189627277606894e-07, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.59375, 'reward_std': 1.0658445954322815, 'completion_length': 221.6875, 'kl': 0.024969455669634044, 'epoch': 5.31}
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 398/500 [7:09:55<1:31:22, 53.75s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 399/500 [7:11:13<1:42:41, 61.00s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.0996158123016357, 'learning_rate': 6.075123608706093e-07, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.609375, 'reward_std': 1.0074251294136047, 'completion_length': 222.3125, 'kl': 0.010781214688904583, 'epoch': 5.32}
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 399/500 [7:11:13<1:42:41, 61.00s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 400/500 [7:12:02<1:35:23, 57.24s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.0829194784164429, 'learning_rate': 5.961542311581586e-07, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.1160253882408142, 'completion_length': 205.25, 'kl': 0.013233629404567182, 'epoch': 5.33}
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 400/500 [7:12:02<1:35:23, 57.24s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 401/500 [7:13:11<1:40:24, 60.85s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.9632596373558044, 'learning_rate': 5.848888922025553e-07, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 0.7886751294136047, 'completion_length': 292.3125, 'kl': 0.007695769425481558, 'epoch': 5.35}
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 401/500 [7:13:11<1:40:24, 60.85s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 402/500 [7:14:42<1:54:04, 69.84s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.012286901473999, 'learning_rate': 5.737168930605272e-07, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.1160253882408142, 'completion_length': 331.3125, 'kl': 0.006415344891138375, 'epoch': 5.36}
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 402/500 [7:14:42<1:54:04, 69.84s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 403/500 [7:15:50<1:52:04, 69.32s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.0044890642166138, 'learning_rate': 5.626387782395512e-07, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.84375, 'reward_std': 0.8898502588272095, 'completion_length': 301.375, 'kl': 0.005507975409273058, 'epoch': 5.37}
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 403/500 [7:15:50<1:52:04, 69.32s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 404/500 [7:16:53<1:47:37, 67.26s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.0038577318191528, 'learning_rate': 5.516550876713142e-07, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0773502588272095, 'completion_length': 274.25, 'kl': 0.006149424647446722, 'epoch': 5.39}
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 404/500 [7:16:53<1:47:37, 67.26s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 405/500 [7:18:01<1:47:09, 67.68s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.9934887290000916, 'learning_rate': 5.407663566854008e-07, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 1.0386751294136047, 'completion_length': 281.9375, 'kl': 0.0073468832997605205, 'epoch': 5.4}
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 405/500 [7:18:01<1:47:09, 67.68s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 406/500 [7:19:25<1:53:43, 72.59s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.8086238503456116, 'learning_rate': 5.299731159831953e-07, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.7886751294136047, 'completion_length': 325.4375, 'kl': 0.006573728402145207, 'epoch': 5.41}
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 406/500 [7:19:25<1:53:43, 72.59s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 407/500 [7:20:30<1:48:46, 70.18s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.8504322171211243, 'learning_rate': 5.192758916120236e-07, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0773502588272095, 'completion_length': 301.6875, 'kl': 0.006765600468497723, 'epoch': 5.43}
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 407/500 [7:20:30<1:48:46, 70.18s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 408/500 [7:21:37<1:46:27, 69.43s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.0266573429107666, 'learning_rate': 5.086752049395094e-07, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.154700517654419, 'completion_length': 303.375, 'kl': 0.009392634965479374, 'epoch': 5.44}
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 408/500 [7:21:37<1:46:27, 69.43s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 409/500 [7:22:44<1:44:02, 68.60s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.832789421081543, 'learning_rate': 4.981715726281666e-07, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.0386751294136047, 'completion_length': 301.375, 'kl': 0.00899343192577362, 'epoch': 5.45}
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 409/500 [7:22:44<1:44:02, 68.60s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 410/500 [7:23:58<1:45:30, 70.33s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.825965166091919, 'learning_rate': 4.87765506610215e-07, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.09375, 'reward_std': 0.867419570684433, 'completion_length': 300.125, 'kl': 0.006672712275758386, 'epoch': 5.47}
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 410/500 [7:23:58<1:45:30, 70.33s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 411/500 [7:25:06<1:42:58, 69.42s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.7645404934883118, 'learning_rate': 4.774575140626317e-07, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 0.7886751294136047, 'completion_length': 269.5625, 'kl': 0.006911796284839511, 'epoch': 5.48}
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 411/500 [7:25:06<1:42:58, 69.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 412/500 [7:26:24<1:45:46, 72.12s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.970931887626648, 'learning_rate': 4.672480973824312e-07, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.4375, 'reward': 2.0625, 'reward_std': 1.2185947000980377, 'completion_length': 342.8125, 'kl': 0.008994157309643924, 'epoch': 5.49}
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 412/500 [7:26:24<1:45:46, 72.12s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 413/500 [7:27:30<1:41:42, 70.14s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.2117120027542114, 'learning_rate': 4.5713775416217884e-07, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.6875, 'reward_std': 1.1574888825416565, 'completion_length': 288.0, 'kl': 0.01405497151426971, 'epoch': 5.51}
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 413/500 [7:27:30<1:41:42, 70.14s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 414/500 [7:28:37<1:39:28, 69.41s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.7653054594993591, 'learning_rate': 4.4712697716573994e-07, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.21875, 'reward_std': 0.8158445954322815, 'completion_length': 291.8125, 'kl': 0.010423467261716723, 'epoch': 5.52}
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 414/500 [7:28:37<1:39:28, 69.41s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 415/500 [7:29:48<1:38:41, 69.66s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.9057141542434692, 'learning_rate': 4.372162543042624e-07, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.734375, 'reward_std': 0.31992512941360474, 'completion_length': 294.25, 'kl': 0.010814500041306019, 'epoch': 5.53}
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 415/500 [7:29:48<1:38:41, 69.66s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 416/500 [7:31:03<1:40:04, 71.48s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.8315344452857971, 'learning_rate': 4.27406068612396e-07, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.7886751294136047, 'completion_length': 303.0625, 'kl': 0.01307690207613632, 'epoch': 5.55}
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 416/500 [7:31:03<1:40:04, 71.48s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 417/500 [7:32:08<1:36:07, 69.49s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.9390268325805664, 'learning_rate': 4.1769689822475147e-07, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0773502588272095, 'completion_length': 296.75, 'kl': 0.0065112399170175195, 'epoch': 5.56}
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 417/500 [7:32:08<1:36:07, 69.49s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 418/500 [7:33:12<1:32:36, 67.77s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8893262147903442, 'learning_rate': 4.0808921635259595e-07, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.1160253882408142, 'completion_length': 303.375, 'kl': 0.005131582845933735, 'epoch': 5.57}
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 418/500 [7:33:12<1:32:36, 67.77s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 419/500 [7:34:22<1:32:22, 68.42s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.9374181628227234, 'learning_rate': 3.9858349126078945e-07, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 0.8273502588272095, 'completion_length': 290.8125, 'kl': 0.007386866956949234, 'epoch': 5.59}
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 419/500 [7:34:22<1:32:22, 68.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 420/500 [7:35:39<1:34:30, 70.88s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.8107778429985046, 'learning_rate': 3.891801862449629e-07, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.84375, 'reward_std': 0.8898502588272095, 'completion_length': 327.8125, 'kl': 0.00797317735850811, 'epoch': 5.6}
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 420/500 [7:35:39<1:34:30, 70.88s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 421/500 [7:36:47<1:32:20, 70.14s/it]                                                     {'loss': 0.0011, 'grad_norm': 1.0304796695709229, 'learning_rate': 3.798797596089351e-07, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.0386751294136047, 'completion_length': 304.4375, 'kl': 0.028449416044168174, 'epoch': 5.61}
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 421/500 [7:36:47<1:32:20, 70.14s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 422/500 [7:37:58<1:31:33, 70.44s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.03822922706604, 'learning_rate': 3.7068266464238085e-07, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.1160253882408142, 'completion_length': 299.8125, 'kl': 0.006722310092300177, 'epoch': 5.63}
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 422/500 [7:37:58<1:31:33, 70.44s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 423/500 [7:39:10<1:30:54, 70.84s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.8734092712402344, 'learning_rate': 3.615893495987335e-07, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 0.7886751294136047, 'completion_length': 300.1875, 'kl': 0.004984224680811167, 'epoch': 5.64}
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 423/500 [7:39:10<1:30:54, 70.84s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 424/500 [7:40:16<1:27:50, 69.35s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.1217081546783447, 'learning_rate': 3.5260025767333894e-07, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 289.8125, 'kl': 0.008017926244065166, 'epoch': 5.65}
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 424/500 [7:40:16<1:27:50, 69.35s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 425/500 [7:41:18<1:23:57, 67.17s/it]                                                     {'loss': 0.0012, 'grad_norm': 1.201221227645874, 'learning_rate': 3.4371582698185636e-07, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 281.3125, 'kl': 0.028932714252732694, 'epoch': 5.67}
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 425/500 [7:41:18<1:23:57, 67.17s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 426/500 [7:42:29<1:24:28, 68.49s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.04580819606781, 'learning_rate': 3.3493649053890325e-07, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.453125, 'reward': 1.953125, 'reward_std': 1.0760494768619537, 'completion_length': 297.9375, 'kl': 0.013331014662981033, 'epoch': 5.68}
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 426/500 [7:42:29<1:24:28, 68.49s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 427/500 [7:43:34<1:21:50, 67.26s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.7656412720680237, 'learning_rate': 3.262626762369525e-07, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 0.7886751294136047, 'completion_length': 298.0625, 'kl': 0.006561003450769931, 'epoch': 5.69}
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 427/500 [7:43:34<1:21:50, 67.26s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 428/500 [7:44:51<1:24:09, 70.13s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.9060868620872498, 'learning_rate': 3.176948068254762e-07, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.154700517654419, 'completion_length': 318.25, 'kl': 0.009070249856449664, 'epoch': 5.71}
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 428/500 [7:44:51<1:24:09, 70.13s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 429/500 [7:46:06<1:24:50, 71.69s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.0077862739562988, 'learning_rate': 3.092332998903416e-07, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 312.5, 'kl': 0.007078301394358277, 'epoch': 5.72}
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 429/500 [7:46:06<1:24:50, 71.69s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 430/500 [7:47:10<1:21:07, 69.53s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.9658101797103882, 'learning_rate': 3.0087856783345916e-07, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 1.0386751294136047, 'completion_length': 276.0625, 'kl': 0.006988573586568236, 'epoch': 5.73}
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 430/500 [7:47:10<1:21:07, 69.53s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 431/500 [7:48:12<1:17:19, 67.24s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.0899572372436523, 'learning_rate': 2.9263101785268253e-07, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.09375, 'reward_std': 1.0850443542003632, 'completion_length': 284.8125, 'kl': 0.009110697894357145, 'epoch': 5.75}
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 431/500 [7:48:12<1:17:19, 67.24s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 432/500 [7:49:24<1:17:46, 68.63s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.606908917427063, 'learning_rate': 2.844910519219632e-07, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 0.5386751294136047, 'completion_length': 296.5, 'kl': 0.011785791371949017, 'epoch': 5.76}
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 432/500 [7:49:24<1:17:46, 68.63s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 433/500 [7:50:32<1:16:17, 68.33s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.0091006755828857, 'learning_rate': 2.764590667717562e-07, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.5, 'reward_std': 0.7886751294136047, 'completion_length': 299.1875, 'kl': 0.010885707917623222, 'epoch': 5.77}
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 433/500 [7:50:32<1:16:17, 68.33s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 434/500 [7:51:37<1:13:57, 67.24s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.9422088861465454, 'learning_rate': 2.6853545386968607e-07, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.0386751294136047, 'completion_length': 287.4375, 'kl': 0.007495667785406113, 'epoch': 5.79}
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 434/500 [7:51:37<1:13:57, 67.24s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 435/500 [7:52:43<1:12:43, 67.13s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.7316561937332153, 'learning_rate': 2.6072059940146775e-07, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 0.5386751294136047, 'completion_length': 296.8125, 'kl': 0.013042586389929056, 'epoch': 5.8}
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 435/500 [7:52:43<1:12:43, 67.13s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 436/500 [7:53:18<1:01:16, 57.44s/it]                                                     {'loss': 0.0005, 'grad_norm': 1.1100355386734009, 'learning_rate': 2.53014884252083e-07, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 0.75, 'completion_length': 125.5, 'kl': 0.012510158820077777, 'epoch': 5.81}
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 436/500 [7:53:18<1:01:16, 57.44s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 437/500 [7:53:56<53:57, 51.39s/it]                                                     {'loss': 0.001, 'grad_norm': 1.5942637920379639, 'learning_rate': 2.454186839872158e-07, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.859375, 'reward_std': 1.0074251294136047, 'completion_length': 140.125, 'kl': 0.024028908810578287, 'epoch': 5.83}
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 437/500 [7:53:56<53:57, 51.39s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 438/500 [7:54:31<48:11, 46.63s/it]                                                   {'loss': 0.0003, 'grad_norm': 1.2191160917282104, 'learning_rate': 2.3793236883495164e-07, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 0.8273502588272095, 'completion_length': 135.375, 'kl': 0.007935065194033086, 'epoch': 5.84}
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 438/500 [7:54:31<48:11, 46.63s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 439/500 [7:55:05<43:41, 42.98s/it]                                                   {'loss': 0.0004, 'grad_norm': 1.200376272201538, 'learning_rate': 2.3055630366772857e-07, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.1160253882408142, 'completion_length': 129.9375, 'kl': 0.010701753199100494, 'epoch': 5.85}
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 439/500 [7:55:05<43:41, 42.98s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 440/500 [7:55:43<41:16, 41.28s/it]                                                   {'loss': 0.0006, 'grad_norm': 1.3649991750717163, 'learning_rate': 2.2329084798455747e-07, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.984375, 'reward_std': 1.0461002588272095, 'completion_length': 135.0, 'kl': 0.014160821679979563, 'epoch': 5.87}
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 440/500 [7:55:43<41:16, 41.28s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 441/500 [7:56:18<38:46, 39.44s/it]                                                   {'loss': 0.0009, 'grad_norm': 1.240151047706604, 'learning_rate': 2.1613635589349756e-07, 'rewards/cot_correctness_reward_func': 1.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.484375, 'reward_std': 0.5605082213878632, 'completion_length': 127.8125, 'kl': 0.02230223617516458, 'epoch': 5.88}
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 441/500 [7:56:18<38:46, 39.44s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 442/500 [7:56:51<36:20, 37.59s/it]                                                   {'loss': 0.0007, 'grad_norm': 1.651182770729065, 'learning_rate': 2.0909317609440093e-07, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.21875, 'reward_std': 1.0463692247867584, 'completion_length': 124.625, 'kl': 0.017745827790349722, 'epoch': 5.89}
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 442/500 [7:56:51<36:20, 37.59s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 443/500 [7:57:24<34:19, 36.13s/it]                                                   {'loss': 0.0008, 'grad_norm': 1.572829008102417, 'learning_rate': 2.0216165186191406e-07, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.4375, 'reward': 2.1875, 'reward_std': 1.140057697892189, 'completion_length': 119.25, 'kl': 0.018897689413279295, 'epoch': 5.91}
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 443/500 [7:57:24<34:19, 36.13s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 444/500 [7:57:58<33:05, 35.46s/it]                                                   {'loss': 0.0004, 'grad_norm': 1.4041798114776611, 'learning_rate': 1.95342121028749e-07, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 0.7886751294136047, 'completion_length': 127.3125, 'kl': 0.010141792707145214, 'epoch': 5.92}
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 444/500 [7:57:58<33:05, 35.46s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 445/500 [7:58:34<32:35, 35.56s/it]                                                   {'loss': 0.0006, 'grad_norm': 1.214882493019104, 'learning_rate': 1.8863491596921745e-07, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 0.8273502588272095, 'completion_length': 129.75, 'kl': 0.014254152309149504, 'epoch': 5.93}
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 445/500 [7:58:34<32:35, 35.56s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 446/500 [7:59:07<31:25, 34.91s/it]                                                   {'loss': 0.0008, 'grad_norm': 1.625199794769287, 'learning_rate': 1.8204036358303173e-07, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.984375, 'reward_std': 1.1086002588272095, 'completion_length': 127.4375, 'kl': 0.019064356805756688, 'epoch': 5.95}
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 446/500 [7:59:07<31:25, 34.91s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 447/500 [7:59:39<30:05, 34.07s/it]                                                   {'loss': 0.0012, 'grad_norm': 1.4336066246032715, 'learning_rate': 1.7555878527937164e-07, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.21875, 'reward_std': 0.8511751294136047, 'completion_length': 123.5, 'kl': 0.029872683342546225, 'epoch': 5.96}
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 447/500 [7:59:39<30:05, 34.07s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 448/500 [8:00:16<30:11, 34.84s/it]                                                   {'loss': 0.0007, 'grad_norm': 1.4079415798187256, 'learning_rate': 1.6919049696121957e-07, 'rewards/cot_correctness_reward_func': 1.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.46875, 'reward_std': 0.9827762544155121, 'completion_length': 130.75, 'kl': 0.016408320982009172, 'epoch': 5.97}
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 448/500 [8:00:16<30:11, 34.84s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 449/500 [8:00:49<29:18, 34.47s/it]                                                   {'loss': 0.0019, 'grad_norm': 1.2512513399124146, 'learning_rate': 1.629358090099639e-07, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.4375, 'reward': 2.03125, 'reward_std': 1.2100443542003632, 'completion_length': 127.25, 'kl': 0.04684347356669605, 'epoch': 5.99}
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 449/500 [8:00:49<29:18, 34.47s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 450/500 [8:01:27<29:36, 35.54s/it]                                                   {'loss': 0.0006, 'grad_norm': 1.3133574724197388, 'learning_rate': 1.567950262702714e-07, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 0.8273502588272095, 'completion_length': 141.375, 'kl': 0.014570666244253516, 'epoch': 6.0}
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 450/500 [8:01:27<29:36, 35.54s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 451/500 [8:02:19<32:53, 40.27s/it]                                                   {'loss': 0.0005, 'grad_norm': 1.0611803531646729, 'learning_rate': 1.507684480352292e-07, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 1.0773502588272095, 'completion_length': 212.75, 'kl': 0.011396563146263361, 'epoch': 6.01}
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 451/500 [8:02:19<32:53, 40.27s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 452/500 [8:03:13<35:34, 44.46s/it]                                                   {'loss': 0.0005, 'grad_norm': 1.0706974267959595, 'learning_rate': 1.4485636803175828e-07, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 0.75, 'completion_length': 221.9375, 'kl': 0.01326362055260688, 'epoch': 6.03}
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 452/500 [8:03:13<35:34, 44.46s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 453/500 [8:04:04<36:27, 46.55s/it]                                                   {'loss': 0.0008, 'grad_norm': 1.3620247840881348, 'learning_rate': 1.3905907440629752e-07, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.453125, 'reward': 1.703125, 'reward_std': 0.9258645847439766, 'completion_length': 216.4375, 'kl': 0.018893042288254946, 'epoch': 6.04}
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 453/500 [8:04:04<36:27, 46.55s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 454/500 [8:04:52<35:55, 46.85s/it]                                                   {'loss': 0.0009, 'grad_norm': 1.3474200963974, 'learning_rate': 1.3337684971075932e-07, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.109375, 'reward_std': 1.0300632566213608, 'completion_length': 193.3125, 'kl': 0.02271948812995106, 'epoch': 6.05}
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 454/500 [8:04:52<35:55, 46.85s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 455/500 [8:05:41<35:32, 47.40s/it]                                                   {'loss': 0.0004, 'grad_norm': 1.1904537677764893, 'learning_rate': 1.278099708887587e-07, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 1.0386751294136047, 'completion_length': 203.1875, 'kl': 0.010473321890458465, 'epoch': 6.07}
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 455/500 [8:05:41<35:32, 47.40s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 456/500 [8:06:43<38:01, 51.85s/it]                                                   {'loss': 0.0003, 'grad_norm': 1.4940344095230103, 'learning_rate': 1.223587092621162e-07, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.0386751294136047, 'completion_length': 226.125, 'kl': 0.008551836479455233, 'epoch': 6.08}
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 456/500 [8:06:43<38:01, 51.85s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 457/500 [8:07:41<38:32, 53.79s/it]                                                   {'loss': 0.0009, 'grad_norm': 1.2154250144958496, 'learning_rate': 1.1702333051763271e-07, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.09375, 'reward_std': 0.7724311947822571, 'completion_length': 226.25, 'kl': 0.023592068813741207, 'epoch': 6.09}
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 457/500 [8:07:41<38:32, 53.79s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 458/500 [8:08:37<38:02, 54.34s/it]                                                   {'loss': 0.0003, 'grad_norm': 1.096488356590271, 'learning_rate': 1.1180409469414094e-07, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.154700517654419, 'completion_length': 222.1875, 'kl': 0.008165075909346342, 'epoch': 6.11}
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 458/500 [8:08:37<38:02, 54.34s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 459/500 [8:09:31<37:00, 54.16s/it]                                                   {'loss': 0.0005, 'grad_norm': 1.113502025604248, 'learning_rate': 1.067012561698319e-07, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.96875, 'reward_std': 0.8287444412708282, 'completion_length': 208.9375, 'kl': 0.01131857791915536, 'epoch': 6.12}
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 459/500 [8:09:31<37:00, 54.16s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 460/500 [8:10:25<36:09, 54.23s/it]                                                   {'loss': 0.0005, 'grad_norm': 0.9913535714149475, 'learning_rate': 1.0171506364985622e-07, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.71875, 'reward_std': 0.7576940953731537, 'completion_length': 215.0625, 'kl': 0.01245077489875257, 'epoch': 6.13}
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 460/500 [8:10:25<36:09, 54.23s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 461/500 [8:11:30<37:18, 57.39s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.9613576531410217, 'learning_rate': 9.684576015420277e-08, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.71875, 'reward_std': 1.117419570684433, 'completion_length': 237.3125, 'kl': 0.007080941228196025, 'epoch': 6.15}
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 461/500 [8:11:30<37:18, 57.39s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 462/500 [8:12:26<36:06, 57.01s/it]                                                   {'loss': 0.0003, 'grad_norm': 1.1703182458877563, 'learning_rate': 9.209358300585474e-08, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 228.0625, 'kl': 0.00824191642459482, 'epoch': 6.16}
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 462/500 [8:12:26<36:06, 57.01s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 463/500 [8:13:16<33:50, 54.87s/it]                                                   {'loss': 0.0005, 'grad_norm': 1.2229480743408203, 'learning_rate': 8.745876381922147e-08, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 1.0773502588272095, 'completion_length': 205.125, 'kl': 0.01125250500626862, 'epoch': 6.17}
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 463/500 [8:13:16<33:50, 54.87s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 464/500 [8:14:08<32:27, 54.09s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.9587563872337341, 'learning_rate': 8.294152848885156e-08, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 0.8273502588272095, 'completion_length': 210.0, 'kl': 0.0073310608277097344, 'epoch': 6.19}
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 464/500 [8:14:08<32:27, 54.09s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 465/500 [8:14:58<30:48, 52.82s/it]                                                   {'loss': 0.0004, 'grad_norm': 0.9783694744110107, 'learning_rate': 7.854209717842231e-08, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.09375, 'reward_std': 0.7963692247867584, 'completion_length': 209.375, 'kl': 0.009809245239011943, 'epoch': 6.2}
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 465/500 [8:14:58<30:48, 52.82s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 466/500 [8:15:51<30:01, 52.98s/it]                                                   {'loss': 0.0003, 'grad_norm': 1.1093459129333496, 'learning_rate': 7.426068431000883e-08, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.109375, 'reward_std': 0.5699251294136047, 'completion_length': 224.375, 'kl': 0.007664479780942202, 'epoch': 6.21}
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 466/500 [8:15:51<30:01, 52.98s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 467/500 [8:16:45<29:18, 53.28s/it]                                                   {'loss': 0.0004, 'grad_norm': 1.0191035270690918, 'learning_rate': 7.009749855363457e-08, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.453125, 'reward': 1.546875, 'reward_std': 1.0864095389842987, 'completion_length': 213.9375, 'kl': 0.009801660664379597, 'epoch': 6.23}
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 467/500 [8:16:45<29:18, 53.28s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 468/500 [8:17:41<28:50, 54.07s/it]                                                   {'loss': 0.0005, 'grad_norm': 1.2746881246566772, 'learning_rate': 6.605274281709929e-08, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.1160253882408142, 'completion_length': 212.75, 'kl': 0.012919181492179632, 'epoch': 6.24}
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 468/500 [8:17:41<28:50, 54.07s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 469/500 [8:18:40<28:39, 55.48s/it]                                                   {'loss': 0.0004, 'grad_norm': 1.1684845685958862, 'learning_rate': 6.212661423609184e-08, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 0.8273502588272095, 'completion_length': 210.875, 'kl': 0.01018638361711055, 'epoch': 6.25}
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 469/500 [8:18:40<28:39, 55.48s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 470/500 [8:19:38<28:11, 56.39s/it]                                                   {'loss': 0.0005, 'grad_norm': 1.12924063205719, 'learning_rate': 5.83193041645802e-08, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.6875, 'reward_std': 1.0645764470100403, 'completion_length': 223.25, 'kl': 0.012739571277052164, 'epoch': 6.27}
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 470/500 [8:19:38<28:11, 56.39s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 471/500 [8:20:29<26:29, 54.80s/it]                                                   {'loss': 0.0006, 'grad_norm': 1.2123661041259766, 'learning_rate': 5.463099816548578e-08, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.109375, 'reward_std': 1.0507531762123108, 'completion_length': 219.3125, 'kl': 0.015950694680213928, 'epoch': 6.28}
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 471/500 [8:20:29<26:29, 54.80s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 472/500 [8:21:30<26:24, 56.58s/it]                                                   {'loss': 0.0013, 'grad_norm': 1.0613009929656982, 'learning_rate': 5.106187600163987e-08, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.4375, 'reward': 1.53125, 'reward_std': 0.8803886324167252, 'completion_length': 218.5, 'kl': 0.03260532103013247, 'epoch': 6.29}
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 472/500 [8:21:30<26:24, 56.58s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 473/500 [8:22:20<24:33, 54.57s/it]                                                   {'loss': 0.0005, 'grad_norm': 1.2178032398223877, 'learning_rate': 4.761211162702117e-08, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.0386751294136047, 'completion_length': 203.0, 'kl': 0.011933441506698728, 'epoch': 6.31}
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 473/500 [8:22:20<24:33, 54.57s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 474/500 [8:23:09<22:58, 53.02s/it]                                                   {'loss': 0.0002, 'grad_norm': 0.9824369549751282, 'learning_rate': 4.428187317827848e-08, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.7886751294136047, 'completion_length': 197.375, 'kl': 0.006215405068360269, 'epoch': 6.32}
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 474/500 [8:23:09<22:58, 53.02s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 475/500 [8:24:09<22:55, 55.02s/it]                                                   {'loss': 0.0004, 'grad_norm': 0.987920343875885, 'learning_rate': 4.1071322966535487e-08, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0, 'completion_length': 227.125, 'kl': 0.008871072437614202, 'epoch': 6.33}
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 475/500 [8:24:09<22:55, 55.02s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 476/500 [8:25:19<23:44, 59.34s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.7568769454956055, 'learning_rate': 3.798061746947995e-08, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 0.5386751294136047, 'completion_length': 313.125, 'kl': 0.007858570432290435, 'epoch': 6.35}
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 476/500 [8:25:19<23:44, 59.34s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 477/500 [8:26:30<24:05, 62.85s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.8489591479301453, 'learning_rate': 3.5009907323737826e-08, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 0.8273502588272095, 'completion_length': 307.75, 'kl': 0.00757322704885155, 'epoch': 6.36}
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 477/500 [8:26:30<24:05, 62.85s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 478/500 [8:27:42<24:08, 65.83s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.9982801079750061, 'learning_rate': 3.2159337317530234e-08, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.1160253882408142, 'completion_length': 307.25, 'kl': 0.00774168164934963, 'epoch': 6.37}
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 478/500 [8:27:42<24:08, 65.83s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 479/500 [8:28:46<22:49, 65.23s/it]                                                   {'loss': 0.0003, 'grad_norm': 1.0243405103683472, 'learning_rate': 2.9429046383618042e-08, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 272.125, 'kl': 0.007404366508126259, 'epoch': 6.39}
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 479/500 [8:28:46<22:49, 65.23s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 480/500 [8:30:06<23:10, 69.54s/it]                                                   {'loss': 0.0004, 'grad_norm': 0.9986616969108582, 'learning_rate': 2.681916759252917e-08, 'rewards/cot_correctness_reward_func': 0.5, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 1.484375, 'reward_std': 1.012078046798706, 'completion_length': 319.75, 'kl': 0.01120968209579587, 'epoch': 6.4}
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 480/500 [8:30:06<23:10, 69.54s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 481/500 [8:31:11<21:36, 68.26s/it]                                                   {'loss': 0.0002, 'grad_norm': 0.8994562029838562, 'learning_rate': 2.4329828146074096e-08, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.875, 'reward_std': 1.1160253882408142, 'completion_length': 296.0, 'kl': 0.00481262436369434, 'epoch': 6.41}
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 481/500 [8:31:11<21:36, 68.26s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 482/500 [8:32:22<20:40, 68.94s/it]                                                   {'loss': 0.0004, 'grad_norm': 0.8919596076011658, 'learning_rate': 2.1961149371145795e-08, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.09375, 'reward_std': 1.025296300649643, 'completion_length': 318.5625, 'kl': 0.009911841189023107, 'epoch': 6.43}
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 482/500 [8:32:22<20:40, 68.94s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 483/500 [8:33:39<20:16, 71.59s/it]                                                   {'loss': 0.0004, 'grad_norm': 0.9720802903175354, 'learning_rate': 1.9713246713805588e-08, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 2.34375, 'reward_std': 0.7963692247867584, 'completion_length': 313.375, 'kl': 0.009806933929212391, 'epoch': 6.44}
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 483/500 [8:33:39<20:16, 71.59s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 484/500 [8:34:49<18:53, 70.85s/it]                                                   {'loss': 0.0002, 'grad_norm': 0.8250128626823425, 'learning_rate': 1.7586229733657646e-08, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 0.8273502588272095, 'completion_length': 306.5, 'kl': 0.006136565352790058, 'epoch': 6.45}
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 484/500 [8:34:49<18:53, 70.85s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 485/500 [8:35:56<17:29, 69.98s/it]                                                   {'loss': 0.0002, 'grad_norm': 0.9017651081085205, 'learning_rate': 1.5580202098509078e-08, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 0.7886751294136047, 'completion_length': 285.0, 'kl': 0.006169058149680495, 'epoch': 6.47}
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 485/500 [8:35:56<17:29, 69.98s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 486/500 [8:37:01<15:57, 68.37s/it]                                                   {'loss': 0.0002, 'grad_norm': 0.8948915600776672, 'learning_rate': 1.3695261579316776e-08, 'rewards/cot_correctness_reward_func': 1.375, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.375, 'reward_std': 1.0386751294136047, 'completion_length': 285.625, 'kl': 0.005787559726741165, 'epoch': 6.48}
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 486/500 [8:37:01<15:57, 68.37s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 487/500 [8:39:32<20:09, 93.06s/it]                                                   {'loss': 0.0003, 'grad_norm': 1.012366771697998, 'learning_rate': 1.193150004542204e-08, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.484375, 'reward': 2.109375, 'reward_std': 1.135127067565918, 'completion_length': 441.875, 'kl': 0.007369750877842307, 'epoch': 6.49}
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 487/500 [8:39:32<20:09, 93.06s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 488/500 [8:40:36<16:54, 84.51s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.8481347560882568, 'learning_rate': 1.0289003460074165e-08, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 0.7886751294136047, 'completion_length': 292.4375, 'kl': 0.006250170699786395, 'epoch': 6.51}
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 488/500 [8:40:36<16:54, 84.51s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 489/500 [8:41:44<14:35, 79.60s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.9720094203948975, 'learning_rate': 8.767851876239075e-09, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.0386751294136047, 'completion_length': 291.5625, 'kl': 0.007197907543741167, 'epoch': 6.52}
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 489/500 [8:41:44<14:35, 79.60s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 490/500 [8:43:03<13:12, 79.20s/it]                                                   {'loss': 0.0002, 'grad_norm': 0.6326643228530884, 'learning_rate': 7.368119432699383e-09, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.5, 'completion_length': 327.8125, 'kl': 0.005920304334722459, 'epoch': 6.53}
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 490/500 [8:43:03<13:12, 79.20s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 491/500 [8:44:13<11:28, 76.52s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.7935389876365662, 'learning_rate': 6.089874350439507e-09, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 0.7886751294136047, 'completion_length': 295.25, 'kl': 0.006341811502352357, 'epoch': 6.55}
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 491/500 [8:44:13<11:28, 76.52s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 492/500 [8:45:17<09:43, 72.92s/it]                                                   {'loss': 0.0002, 'grad_norm': 1.029398798942566, 'learning_rate': 4.933178929321103e-09, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.625, 'reward_std': 1.0386751294136047, 'completion_length': 289.375, 'kl': 0.005514239950571209, 'epoch': 6.56}
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 492/500 [8:45:17<09:43, 72.92s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 493/500 [8:46:26<08:21, 71.71s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.9953204989433289, 'learning_rate': 3.8980895450474455e-09, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.84375, 'reward_std': 1.143194854259491, 'completion_length': 307.3125, 'kl': 0.007452041725628078, 'epoch': 6.57}
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 493/500 [8:46:26<08:21, 71.71s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 494/500 [8:47:32<06:58, 69.78s/it]                                                   {'loss': 0.0003, 'grad_norm': 1.26371169090271, 'learning_rate': 2.984656646415063e-09, 'rewards/cot_correctness_reward_func': 1.125, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.125, 'reward_std': 1.0386751294136047, 'completion_length': 276.625, 'kl': 0.006278567248955369, 'epoch': 6.59}
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 494/500 [8:47:32<06:58, 69.78s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 495/500 [8:48:34<05:37, 67.57s/it]                                                   {'loss': 0.0004, 'grad_norm': 0.8536490797996521, 'learning_rate': 2.192924752854042e-09, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.71875, 'reward_std': 0.9060947000980377, 'completion_length': 284.4375, 'kl': 0.009434447973035276, 'epoch': 6.6}
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 495/500 [8:48:34<05:37, 67.57s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 496/500 [8:49:43<04:31, 67.97s/it]                                                   {'loss': 0.0004, 'grad_norm': 1.1071956157684326, 'learning_rate': 1.5229324522605949e-09, 'rewards/cot_correctness_reward_func': 1.0, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.0, 'reward_std': 1.0773502588272095, 'completion_length': 302.625, 'kl': 0.009541237261146307, 'epoch': 6.61}
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 496/500 [8:49:43<04:31, 67.97s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 497/500 [8:50:47<03:20, 66.69s/it]                                                   {'loss': 0.0006, 'grad_norm': 0.971896231174469, 'learning_rate': 9.747123991141193e-10, 'rewards/cot_correctness_reward_func': 0.625, 'rewards/cot_letter_reward_func': 0.46875, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.5625, 'reward_std': 0.9523502588272095, 'completion_length': 294.25, 'kl': 0.015277424245141447, 'epoch': 6.63}
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 497/500 [8:50:47<03:20, 66.69s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 498/500 [8:52:04<02:19, 69.74s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.9280261397361755, 'learning_rate': 5.48291312886251e-10, 'rewards/cot_correctness_reward_func': 0.875, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.46875, 'reward': 1.84375, 'reward_std': 0.8898502588272095, 'completion_length': 317.6875, 'kl': 0.008673731121234596, 'epoch': 6.64}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 498/500 [8:52:04<02:19, 69.74s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 499/500 [8:53:12<01:09, 69.39s/it]                                                   {'loss': 0.0006, 'grad_norm': 1.0554308891296387, 'learning_rate': 2.43689976739403e-10, 'rewards/cot_correctness_reward_func': 0.75, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 1.75, 'reward_std': 0.8660253882408142, 'completion_length': 300.5, 'kl': 0.014294678694568574, 'epoch': 6.65}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 499/500 [8:53:12<01:09, 69.39s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [8:54:24<00:00, 70.07s/it]                                                   {'loss': 0.0002, 'grad_norm': 0.9437529444694519, 'learning_rate': 6.092323651313293e-11, 'rewards/cot_correctness_reward_func': 1.25, 'rewards/cot_letter_reward_func': 0.5, 'rewards/cot_format_reward_func': 0.5, 'reward': 2.25, 'reward_std': 1.0, 'completion_length': 299.75, 'kl': 0.003979526984039694, 'epoch': 6.67}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [8:54:24<00:00, 70.07s/it]                                                   {'train_runtime': 32074.507, 'train_samples_per_second': 0.249, 'train_steps_per_second': 0.016, 'train_loss': 0.00033079219715358474, 'epoch': 6.67}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [8:54:27<00:00, 70.07s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [8:54:27<00:00, 64.13s/it]
Saving LoRA adapter to lora_adapters_experiment_6/grpo_saved_lora
Processing sample logical_deduction_36 (iteration 0) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.67s/it, est. speed input: 165.40 toks/s, output: 23.41 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.67s/it, est. speed input: 165.40 toks/s, output: 23.41 toks/s]
Completed sample logical_deduction_36 (iteration 0) for method cot
Processing sample logical_deduction_331 (iteration 1) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.68s/it, est. speed input: 166.09 toks/s, output: 24.20 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.68s/it, est. speed input: 166.09 toks/s, output: 24.20 toks/s]
Completed sample logical_deduction_331 (iteration 1) for method cot
Processing sample logical_deduction_349 (iteration 2) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.05s/it, est. speed input: 180.58 toks/s, output: 23.99 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.05s/it, est. speed input: 180.58 toks/s, output: 23.99 toks/s]
Completed sample logical_deduction_349 (iteration 2) for method cot
Processing sample logical_deduction_70 (iteration 3) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.56s/it, est. speed input: 167.85 toks/s, output: 24.18 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.56s/it, est. speed input: 167.85 toks/s, output: 24.18 toks/s]
Completed sample logical_deduction_70 (iteration 3) for method cot
Processing sample logical_deduction_136 (iteration 4) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.31s/it, est. speed input: 223.62 toks/s, output: 23.79 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.31s/it, est. speed input: 223.62 toks/s, output: 23.79 toks/s]
Completed sample logical_deduction_136 (iteration 4) for method cot
Processing sample logical_deduction_343 (iteration 5) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.43s/it, est. speed input: 171.14 toks/s, output: 24.09 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.43s/it, est. speed input: 171.14 toks/s, output: 24.09 toks/s]
Completed sample logical_deduction_343 (iteration 5) for method cot
Processing sample logical_deduction_107 (iteration 6) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.25s/it, est. speed input: 157.16 toks/s, output: 23.99 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.25s/it, est. speed input: 157.16 toks/s, output: 23.99 toks/s]
Completed sample logical_deduction_107 (iteration 6) for method cot
Processing sample logical_deduction_181 (iteration 7) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.10s/it, est. speed input: 179.03 toks/s, output: 24.18 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.11s/it, est. speed input: 179.03 toks/s, output: 24.18 toks/s]
Completed sample logical_deduction_181 (iteration 7) for method cot
Processing sample logical_deduction_189 (iteration 8) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.25s/it, est. speed input: 141.52 toks/s, output: 24.09 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.25s/it, est. speed input: 141.52 toks/s, output: 24.09 toks/s]
Completed sample logical_deduction_189 (iteration 8) for method cot
Processing sample logical_deduction_83 (iteration 9) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.92s/it, est. speed input: 236.57 toks/s, output: 23.83 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.92s/it, est. speed input: 236.57 toks/s, output: 23.83 toks/s]
Completed sample logical_deduction_83 (iteration 9) for method cot
Processing sample logical_deduction_186 (iteration 10) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.89s/it, est. speed input: 163.64 toks/s, output: 24.18 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.89s/it, est. speed input: 163.64 toks/s, output: 24.18 toks/s]
Completed sample logical_deduction_186 (iteration 10) for method cot
Processing sample logical_deduction_325 (iteration 11) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.53s/it, est. speed input: 193.06 toks/s, output: 24.32 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.53s/it, est. speed input: 193.06 toks/s, output: 24.32 toks/s]
Completed sample logical_deduction_325 (iteration 11) for method cot
Processing sample logical_deduction_232 (iteration 12) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.14s/it, est. speed input: 228.01 toks/s, output: 23.47 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.14s/it, est. speed input: 228.01 toks/s, output: 23.47 toks/s]
Completed sample logical_deduction_232 (iteration 12) for method cot
Processing sample logical_deduction_54 (iteration 13) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.36s/it, est. speed input: 172.01 toks/s, output: 23.68 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.36s/it, est. speed input: 172.01 toks/s, output: 23.68 toks/s]
Completed sample logical_deduction_54 (iteration 13) for method cot
Processing sample logical_deduction_47 (iteration 14) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.88s/it, est. speed input: 183.48 toks/s, output: 23.73 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.88s/it, est. speed input: 183.48 toks/s, output: 23.73 toks/s]
Completed sample logical_deduction_47 (iteration 14) for method cot
Processing sample logical_deduction_51 (iteration 15) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.20s/it, est. speed input: 159.29 toks/s, output: 23.70 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.20s/it, est. speed input: 159.29 toks/s, output: 23.70 toks/s]
Completed sample logical_deduction_51 (iteration 15) for method cot
Processing sample logical_deduction_78 (iteration 16) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.55s/it, est. speed input: 192.17 toks/s, output: 23.84 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.55s/it, est. speed input: 192.17 toks/s, output: 23.84 toks/s]
Completed sample logical_deduction_78 (iteration 16) for method cot
Processing sample logical_deduction_44 (iteration 17) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.06s/it, est. speed input: 159.33 toks/s, output: 24.05 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.06s/it, est. speed input: 159.33 toks/s, output: 24.05 toks/s]
Completed sample logical_deduction_44 (iteration 17) for method cot
Processing sample logical_deduction_148 (iteration 18) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.36s/it, est. speed input: 261.73 toks/s, output: 23.68 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.36s/it, est. speed input: 261.73 toks/s, output: 23.68 toks/s]
Completed sample logical_deduction_148 (iteration 18) for method cot
Processing sample logical_deduction_395 (iteration 19) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.91s/it, est. speed input: 163.69 toks/s, output: 24.03 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.91s/it, est. speed input: 163.69 toks/s, output: 24.03 toks/s]
Completed sample logical_deduction_395 (iteration 19) for method cot
Processing sample logical_deduction_116 (iteration 20) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.13s/it, est. speed input: 177.52 toks/s, output: 24.09 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.14s/it, est. speed input: 177.52 toks/s, output: 24.09 toks/s]
Completed sample logical_deduction_116 (iteration 20) for method cot
Processing sample logical_deduction_338 (iteration 21) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.96s/it, est. speed input: 140.80 toks/s, output: 24.19 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.97s/it, est. speed input: 140.80 toks/s, output: 24.19 toks/s]
Completed sample logical_deduction_338 (iteration 21) for method cot
Processing sample logical_deduction_23 (iteration 22) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.69s/it, est. speed input: 148.68 toks/s, output: 24.25 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.69s/it, est. speed input: 148.68 toks/s, output: 24.25 toks/s]
Completed sample logical_deduction_23 (iteration 22) for method cot
Processing sample logical_deduction_35 (iteration 23) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.23s/it, est. speed input: 177.67 toks/s, output: 23.92 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.24s/it, est. speed input: 177.67 toks/s, output: 23.92 toks/s]
Completed sample logical_deduction_35 (iteration 23) for method cot
Processing sample logical_deduction_360 (iteration 24) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.37s/it, est. speed input: 153.75 toks/s, output: 24.13 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.37s/it, est. speed input: 153.75 toks/s, output: 24.13 toks/s]
Completed sample logical_deduction_360 (iteration 24) for method cot
Processing sample logical_deduction_98 (iteration 25) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.73s/it, est. speed input: 186.22 toks/s, output: 23.94 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.73s/it, est. speed input: 186.22 toks/s, output: 23.94 toks/s]
Completed sample logical_deduction_98 (iteration 25) for method cot
Processing sample logical_deduction_295 (iteration 26) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.96s/it, est. speed input: 163.37 toks/s, output: 24.01 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.96s/it, est. speed input: 163.37 toks/s, output: 24.01 toks/s]
Completed sample logical_deduction_295 (iteration 26) for method cot
Processing sample logical_deduction_185 (iteration 27) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.44s/it, est. speed input: 196.42 toks/s, output: 23.93 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.44s/it, est. speed input: 196.42 toks/s, output: 23.93 toks/s]
Completed sample logical_deduction_185 (iteration 27) for method cot
Processing sample logical_deduction_316 (iteration 28) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.38s/it, est. speed input: 170.44 toks/s, output: 23.97 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.39s/it, est. speed input: 170.44 toks/s, output: 23.97 toks/s]
Completed sample logical_deduction_316 (iteration 28) for method cot
Processing sample logical_deduction_321 (iteration 29) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.37s/it, est. speed input: 261.34 toks/s, output: 24.01 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.37s/it, est. speed input: 261.34 toks/s, output: 24.01 toks/s]
Completed sample logical_deduction_321 (iteration 29) for method cot
Processing sample logical_deduction_24 (iteration 30) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.07s/it, est. speed input: 179.74 toks/s, output: 24.05 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.07s/it, est. speed input: 179.74 toks/s, output: 24.05 toks/s]
Completed sample logical_deduction_24 (iteration 30) for method cot
Processing sample logical_deduction_150 (iteration 31) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.32s/it, est. speed input: 223.21 toks/s, output: 23.90 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.32s/it, est. speed input: 223.21 toks/s, output: 23.90 toks/s]
Completed sample logical_deduction_150 (iteration 31) for method cot
Processing sample logical_deduction_282 (iteration 32) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.93s/it, est. speed input: 160.95 toks/s, output: 24.06 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.93s/it, est. speed input: 160.95 toks/s, output: 24.06 toks/s]
Completed sample logical_deduction_282 (iteration 32) for method cot
Processing sample logical_deduction_40 (iteration 33) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.53s/it, est. speed input: 151.02 toks/s, output: 24.24 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.53s/it, est. speed input: 151.02 toks/s, output: 24.24 toks/s]
Completed sample logical_deduction_40 (iteration 33) for method cot
Processing sample logical_deduction_193 (iteration 34) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.14s/it, est. speed input: 159.44 toks/s, output: 23.96 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.14s/it, est. speed input: 159.44 toks/s, output: 23.96 toks/s]
Completed sample logical_deduction_193 (iteration 34) for method cot
Processing sample logical_deduction_63 (iteration 35) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.39s/it, est. speed input: 194.98 toks/s, output: 24.08 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.39s/it, est. speed input: 194.98 toks/s, output: 24.08 toks/s]
Completed sample logical_deduction_63 (iteration 35) for method cot
Processing sample logical_deduction_274 (iteration 36) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.53s/it, est. speed input: 139.27 toks/s, output: 24.11 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.53s/it, est. speed input: 139.27 toks/s, output: 24.11 toks/s]
Completed sample logical_deduction_274 (iteration 36) for method cot
Processing sample logical_deduction_235 (iteration 37) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.38s/it, est. speed input: 195.74 toks/s, output: 24.11 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.38s/it, est. speed input: 195.74 toks/s, output: 24.11 toks/s]
Completed sample logical_deduction_235 (iteration 37) for method cot
Processing sample logical_deduction_373 (iteration 38) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.26s/it, est. speed input: 139.90 toks/s, output: 23.79 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.26s/it, est. speed input: 139.90 toks/s, output: 23.79 toks/s]
Completed sample logical_deduction_373 (iteration 38) for method cot
Processing sample logical_deduction_22 (iteration 39) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.78s/it, est. speed input: 206.74 toks/s, output: 23.61 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.78s/it, est. speed input: 206.74 toks/s, output: 23.61 toks/s]
Completed sample logical_deduction_22 (iteration 39) for method cot
Processing sample logical_deduction_13 (iteration 40) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.01s/it, est. speed input: 178.55 toks/s, output: 23.72 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.01s/it, est. speed input: 178.55 toks/s, output: 23.72 toks/s]
Completed sample logical_deduction_13 (iteration 40) for method cot
Processing sample logical_deduction_135 (iteration 41) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.85s/it, est. speed input: 186.37 toks/s, output: 23.57 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.85s/it, est. speed input: 186.37 toks/s, output: 23.57 toks/s]
Completed sample logical_deduction_135 (iteration 41) for method cot
Processing sample logical_deduction_309 (iteration 42) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.46s/it, est. speed input: 165.90 toks/s, output: 23.87 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.46s/it, est. speed input: 165.90 toks/s, output: 23.87 toks/s]
Completed sample logical_deduction_309 (iteration 42) for method cot
Processing sample logical_deduction_176 (iteration 43) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.34s/it, est. speed input: 190.84 toks/s, output: 23.86 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.34s/it, est. speed input: 190.84 toks/s, output: 23.86 toks/s]
Completed sample logical_deduction_176 (iteration 43) for method cot
Processing sample logical_deduction_33 (iteration 44) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.78s/it, est. speed input: 165.42 toks/s, output: 24.14 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.78s/it, est. speed input: 165.42 toks/s, output: 24.14 toks/s]
Completed sample logical_deduction_33 (iteration 44) for method cot
Processing sample logical_deduction_183 (iteration 45) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.25s/it, est. speed input: 141.04 toks/s, output: 24.11 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.25s/it, est. speed input: 141.04 toks/s, output: 24.11 toks/s]
Completed sample logical_deduction_183 (iteration 45) for method cot
Processing sample logical_deduction_49 (iteration 46) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.67s/it, est. speed input: 216.29 toks/s, output: 23.98 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.67s/it, est. speed input: 216.29 toks/s, output: 23.98 toks/s]
Completed sample logical_deduction_49 (iteration 46) for method cot
Processing sample logical_deduction_194 (iteration 47) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.20s/it, est. speed input: 232.37 toks/s, output: 23.87 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.20s/it, est. speed input: 232.37 toks/s, output: 23.87 toks/s]
Completed sample logical_deduction_194 (iteration 47) for method cot
Processing sample logical_deduction_80 (iteration 48) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.35s/it, est. speed input: 141.34 toks/s, output: 24.15 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.35s/it, est. speed input: 141.34 toks/s, output: 24.15 toks/s]
Completed sample logical_deduction_80 (iteration 48) for method cot
Processing sample logical_deduction_90 (iteration 49) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.35s/it, est. speed input: 199.03 toks/s, output: 23.94 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.35s/it, est. speed input: 199.03 toks/s, output: 23.94 toks/s]
Completed sample logical_deduction_90 (iteration 49) for method cot
Processing sample logical_deduction_172 (iteration 50) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.43s/it, est. speed input: 172.44 toks/s, output: 24.09 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.43s/it, est. speed input: 172.44 toks/s, output: 24.09 toks/s]
Completed sample logical_deduction_172 (iteration 50) for method cot
Processing sample logical_deduction_390 (iteration 51) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.31s/it, est. speed input: 141.19 toks/s, output: 24.16 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.31s/it, est. speed input: 141.19 toks/s, output: 24.16 toks/s]
Completed sample logical_deduction_390 (iteration 51) for method cot
Processing sample logical_deduction_110 (iteration 52) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.05s/it, est. speed input: 161.60 toks/s, output: 23.97 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.05s/it, est. speed input: 161.60 toks/s, output: 23.97 toks/s]
Completed sample logical_deduction_110 (iteration 52) for method cot
Processing sample logical_deduction_79 (iteration 53) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.99s/it, est. speed input: 182.16 toks/s, output: 23.90 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.99s/it, est. speed input: 182.16 toks/s, output: 23.90 toks/s]
Completed sample logical_deduction_79 (iteration 53) for method cot
Processing sample logical_deduction_64 (iteration 54) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.71s/it, est. speed input: 189.70 toks/s, output: 23.87 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.71s/it, est. speed input: 189.70 toks/s, output: 23.87 toks/s]
Completed sample logical_deduction_64 (iteration 54) for method cot
Processing sample logical_deduction_174 (iteration 55) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.21s/it, est. speed input: 177.50 toks/s, output: 24.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.21s/it, est. speed input: 177.50 toks/s, output: 24.00 toks/s]
Completed sample logical_deduction_174 (iteration 55) for method cot
Processing sample logical_deduction_83 (iteration 56) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.06s/it, est. speed input: 198.42 toks/s, output: 23.95 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.06s/it, est. speed input: 198.42 toks/s, output: 23.95 toks/s]
Completed sample logical_deduction_83 (iteration 56) for method cot
Processing sample logical_deduction_357 (iteration 57) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.19s/it, est. speed input: 228.27 toks/s, output: 23.76 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.19s/it, est. speed input: 228.27 toks/s, output: 23.76 toks/s]
Completed sample logical_deduction_357 (iteration 57) for method cot
Processing sample logical_deduction_81 (iteration 58) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.84s/it, est. speed input: 165.22 toks/s, output: 23.97 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.84s/it, est. speed input: 165.22 toks/s, output: 23.97 toks/s]
Completed sample logical_deduction_81 (iteration 58) for method cot
Processing sample logical_deduction_12 (iteration 59) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.95s/it, est. speed input: 235.74 toks/s, output: 23.71 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.95s/it, est. speed input: 235.74 toks/s, output: 23.71 toks/s]
Completed sample logical_deduction_12 (iteration 59) for method cot
Processing sample logical_deduction_388 (iteration 60) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.91s/it, est. speed input: 147.37 toks/s, output: 24.11 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.91s/it, est. speed input: 147.37 toks/s, output: 24.11 toks/s]
Completed sample logical_deduction_388 (iteration 60) for method cot
Processing sample logical_deduction_3 (iteration 61) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.88s/it, est. speed input: 184.21 toks/s, output: 23.98 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.88s/it, est. speed input: 184.21 toks/s, output: 23.98 toks/s]
Completed sample logical_deduction_3 (iteration 61) for method cot
Processing sample logical_deduction_45 (iteration 62) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.51s/it, est. speed input: 153.42 toks/s, output: 24.18 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.51s/it, est. speed input: 153.42 toks/s, output: 24.18 toks/s]
Completed sample logical_deduction_45 (iteration 62) for method cot
Processing sample logical_deduction_14 (iteration 63) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.23s/it, est. speed input: 175.90 toks/s, output: 24.19 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.23s/it, est. speed input: 175.90 toks/s, output: 24.19 toks/s]
Completed sample logical_deduction_14 (iteration 63) for method cot
Processing sample logical_deduction_142 (iteration 64) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.18s/it, est. speed input: 203.53 toks/s, output: 23.82 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.18s/it, est. speed input: 203.53 toks/s, output: 23.82 toks/s]
Completed sample logical_deduction_142 (iteration 64) for method cot
Processing sample logical_deduction_301 (iteration 65) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.07s/it, est. speed input: 179.97 toks/s, output: 23.67 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.07s/it, est. speed input: 179.97 toks/s, output: 23.67 toks/s]
Completed sample logical_deduction_301 (iteration 65) for method cot
Processing sample logical_deduction_229 (iteration 66) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.01s/it, est. speed input: 179.22 toks/s, output: 23.73 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.01s/it, est. speed input: 179.22 toks/s, output: 23.73 toks/s]
Completed sample logical_deduction_229 (iteration 66) for method cot
Processing sample logical_deduction_112 (iteration 67) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.15s/it, est. speed input: 202.95 toks/s, output: 23.36 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.15s/it, est. speed input: 202.95 toks/s, output: 23.36 toks/s]
Completed sample logical_deduction_112 (iteration 67) for method cot
Processing sample logical_deduction_214 (iteration 68) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.18s/it, est. speed input: 177.09 toks/s, output: 23.73 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.18s/it, est. speed input: 177.09 toks/s, output: 23.73 toks/s]
Completed sample logical_deduction_214 (iteration 68) for method cot
Processing sample logical_deduction_86 (iteration 69) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.49s/it, est. speed input: 187.48 toks/s, output: 23.90 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.49s/it, est. speed input: 187.48 toks/s, output: 23.90 toks/s]
Completed sample logical_deduction_86 (iteration 69) for method cot
Processing sample logical_deduction_359 (iteration 70) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.16s/it, est. speed input: 227.62 toks/s, output: 23.87 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.16s/it, est. speed input: 227.62 toks/s, output: 23.87 toks/s]
Completed sample logical_deduction_359 (iteration 70) for method cot
Processing sample logical_deduction_332 (iteration 71) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.70s/it, est. speed input: 167.60 toks/s, output: 24.02 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.70s/it, est. speed input: 167.60 toks/s, output: 24.02 toks/s]
Completed sample logical_deduction_332 (iteration 71) for method cot
Processing sample logical_deduction_366 (iteration 72) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.15s/it, est. speed input: 160.02 toks/s, output: 24.14 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.16s/it, est. speed input: 160.02 toks/s, output: 24.14 toks/s]
Completed sample logical_deduction_366 (iteration 72) for method cot
Processing sample logical_deduction_101 (iteration 73) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.10s/it, est. speed input: 160.37 toks/s, output: 24.06 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.10s/it, est. speed input: 160.37 toks/s, output: 24.06 toks/s]
Completed sample logical_deduction_101 (iteration 73) for method cot
Processing sample logical_deduction_287 (iteration 74) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.88s/it, est. speed input: 163.57 toks/s, output: 24.09 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.88s/it, est. speed input: 163.57 toks/s, output: 24.09 toks/s]
Completed sample logical_deduction_287 (iteration 74) for method cot
Processing sample logical_deduction_13 (iteration 75) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.56s/it, est. speed input: 146.44 toks/s, output: 24.06 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.56s/it, est. speed input: 146.44 toks/s, output: 24.06 toks/s]
Completed sample logical_deduction_13 (iteration 75) for method cot
Processing sample logical_deduction_308 (iteration 76) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.91s/it, est. speed input: 163.32 toks/s, output: 24.02 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.91s/it, est. speed input: 163.32 toks/s, output: 24.02 toks/s]
Completed sample logical_deduction_308 (iteration 76) for method cot
Processing sample logical_deduction_258 (iteration 77) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.67s/it, est. speed input: 189.10 toks/s, output: 23.98 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.67s/it, est. speed input: 189.10 toks/s, output: 23.98 toks/s]
Completed sample logical_deduction_258 (iteration 77) for method cot
Processing sample logical_deduction_119 (iteration 78) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.52s/it, est. speed input: 214.78 toks/s, output: 23.92 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.52s/it, est. speed input: 214.78 toks/s, output: 23.92 toks/s]
Completed sample logical_deduction_119 (iteration 78) for method cot
Processing sample logical_deduction_111 (iteration 79) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.88s/it, est. speed input: 163.21 toks/s, output: 24.10 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.88s/it, est. speed input: 163.21 toks/s, output: 24.10 toks/s]
Completed sample logical_deduction_111 (iteration 79) for method cot
Processing sample logical_deduction_47 (iteration 80) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.78s/it, est. speed input: 147.69 toks/s, output: 24.22 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.78s/it, est. speed input: 147.69 toks/s, output: 24.22 toks/s]
Completed sample logical_deduction_47 (iteration 80) for method cot
Processing sample logical_deduction_15 (iteration 81) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.08s/it, est. speed input: 180.34 toks/s, output: 24.14 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.08s/it, est. speed input: 180.34 toks/s, output: 24.14 toks/s]
Completed sample logical_deduction_15 (iteration 81) for method cot
Processing sample logical_deduction_16 (iteration 82) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.79s/it, est. speed input: 148.59 toks/s, output: 24.22 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.79s/it, est. speed input: 148.59 toks/s, output: 24.22 toks/s]
Completed sample logical_deduction_16 (iteration 82) for method cot
Processing sample logical_deduction_216 (iteration 83) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.61s/it, est. speed input: 212.08 toks/s, output: 23.92 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.61s/it, est. speed input: 212.08 toks/s, output: 23.92 toks/s]
Completed sample logical_deduction_216 (iteration 83) for method cot
Processing sample logical_deduction_302 (iteration 84) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.35s/it, est. speed input: 195.63 toks/s, output: 24.23 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.35s/it, est. speed input: 195.63 toks/s, output: 24.23 toks/s]
Completed sample logical_deduction_302 (iteration 84) for method cot
Processing sample logical_deduction_44 (iteration 85) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.84s/it, est. speed input: 163.86 toks/s, output: 24.09 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.84s/it, est. speed input: 163.86 toks/s, output: 24.09 toks/s]
Completed sample logical_deduction_44 (iteration 85) for method cot
Processing sample logical_deduction_279 (iteration 86) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.70s/it, est. speed input: 149.23 toks/s, output: 24.13 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.70s/it, est. speed input: 149.23 toks/s, output: 24.13 toks/s]
Completed sample logical_deduction_279 (iteration 86) for method cot
Processing sample logical_deduction_56 (iteration 87) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.26s/it, est. speed input: 175.01 toks/s, output: 23.98 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.26s/it, est. speed input: 175.01 toks/s, output: 23.98 toks/s]
Completed sample logical_deduction_56 (iteration 87) for method cot
Processing sample logical_deduction_96 (iteration 88) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.20s/it, est. speed input: 140.23 toks/s, output: 24.21 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.21s/it, est. speed input: 140.23 toks/s, output: 24.21 toks/s]
Completed sample logical_deduction_96 (iteration 88) for method cot
Processing sample logical_deduction_346 (iteration 89) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.93s/it, est. speed input: 144.45 toks/s, output: 24.28 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.93s/it, est. speed input: 144.45 toks/s, output: 24.28 toks/s]
Completed sample logical_deduction_346 (iteration 89) for method cot
Processing sample logical_deduction_52 (iteration 90) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.42s/it, est. speed input: 171.96 toks/s, output: 23.63 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.42s/it, est. speed input: 171.96 toks/s, output: 23.63 toks/s]
Completed sample logical_deduction_52 (iteration 90) for method cot
Processing sample logical_deduction_377 (iteration 91) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.96s/it, est. speed input: 183.77 toks/s, output: 23.49 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.96s/it, est. speed input: 183.77 toks/s, output: 23.49 toks/s]
Completed sample logical_deduction_377 (iteration 91) for method cot
Processing sample logical_deduction_71 (iteration 92) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.97s/it, est. speed input: 181.91 toks/s, output: 23.46 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.97s/it, est. speed input: 181.91 toks/s, output: 23.46 toks/s]
Completed sample logical_deduction_71 (iteration 92) for method cot
Processing sample logical_deduction_114 (iteration 93) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.11s/it, est. speed input: 159.90 toks/s, output: 23.50 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.11s/it, est. speed input: 159.90 toks/s, output: 23.50 toks/s]
Completed sample logical_deduction_114 (iteration 93) for method cot
Processing sample logical_deduction_125 (iteration 94) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.95s/it, est. speed input: 162.12 toks/s, output: 23.69 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.95s/it, est. speed input: 162.12 toks/s, output: 23.69 toks/s]
Completed sample logical_deduction_125 (iteration 94) for method cot
Processing sample logical_deduction_140 (iteration 95) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.66s/it, est. speed input: 151.41 toks/s, output: 23.61 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.66s/it, est. speed input: 151.41 toks/s, output: 23.61 toks/s]
Completed sample logical_deduction_140 (iteration 95) for method cot
Processing sample logical_deduction_379 (iteration 96) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.92s/it, est. speed input: 156.91 toks/s, output: 23.65 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.92s/it, est. speed input: 156.91 toks/s, output: 23.65 toks/s]
Completed sample logical_deduction_379 (iteration 96) for method cot
Processing sample logical_deduction_12 (iteration 97) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.30s/it, est. speed input: 157.37 toks/s, output: 23.66 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.30s/it, est. speed input: 157.37 toks/s, output: 23.66 toks/s]
Completed sample logical_deduction_12 (iteration 97) for method cot
Processing sample logical_deduction_57 (iteration 98) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.93s/it, est. speed input: 162.29 toks/s, output: 23.73 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.94s/it, est. speed input: 162.29 toks/s, output: 23.73 toks/s]
Completed sample logical_deduction_57 (iteration 98) for method cot
Processing sample logical_deduction_327 (iteration 99) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.85s/it, est. speed input: 184.00 toks/s, output: 23.45 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.85s/it, est. speed input: 184.00 toks/s, output: 23.45 toks/s]
Completed sample logical_deduction_327 (iteration 99) for method cot
Processing sample logical_deduction_463 (iteration 100) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.73s/it, est. speed input: 128.17 toks/s, output: 23.79 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.73s/it, est. speed input: 128.17 toks/s, output: 23.79 toks/s]
Completed sample logical_deduction_463 (iteration 100) for method cot
Processing sample logical_deduction_825 (iteration 101) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.96s/it, est. speed input: 151.86 toks/s, output: 23.79 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.96s/it, est. speed input: 151.86 toks/s, output: 23.79 toks/s]
Completed sample logical_deduction_825 (iteration 101) for method cot
Processing sample logical_deduction_877 (iteration 102) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.05s/it, est. speed input: 107.22 toks/s, output: 23.92 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.05s/it, est. speed input: 107.22 toks/s, output: 23.92 toks/s]
Completed sample logical_deduction_877 (iteration 102) for method cot
Processing sample logical_deduction_955 (iteration 103) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:15<00:00, 15.48s/it, est. speed input: 96.18 toks/s, output: 23.84 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:15<00:00, 15.48s/it, est. speed input: 96.18 toks/s, output: 23.84 toks/s]
Completed sample logical_deduction_955 (iteration 103) for method cot
Processing sample logical_deduction_216 (iteration 104) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.11s/it, est. speed input: 114.25 toks/s, output: 23.87 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.11s/it, est. speed input: 114.25 toks/s, output: 23.87 toks/s]
Completed sample logical_deduction_216 (iteration 104) for method cot
Processing sample logical_deduction_817 (iteration 105) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.45s/it, est. speed input: 169.08 toks/s, output: 23.68 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.45s/it, est. speed input: 169.08 toks/s, output: 23.68 toks/s]
Completed sample logical_deduction_817 (iteration 105) for method cot
Processing sample logical_deduction_162 (iteration 106) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.43s/it, est. speed input: 110.69 toks/s, output: 23.90 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.43s/it, est. speed input: 110.69 toks/s, output: 23.90 toks/s]
Completed sample logical_deduction_162 (iteration 106) for method cot
Processing sample logical_deduction_465 (iteration 107) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.75s/it, est. speed input: 117.85 toks/s, output: 23.84 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.75s/it, est. speed input: 117.85 toks/s, output: 23.84 toks/s]
Completed sample logical_deduction_465 (iteration 107) for method cot
Processing sample logical_deduction_619 (iteration 108) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.36s/it, est. speed input: 131.32 toks/s, output: 23.85 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.36s/it, est. speed input: 131.32 toks/s, output: 23.85 toks/s]
Completed sample logical_deduction_619 (iteration 108) for method cot
Processing sample logical_deduction_556 (iteration 109) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.51s/it, est. speed input: 121.08 toks/s, output: 23.82 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.51s/it, est. speed input: 121.08 toks/s, output: 23.82 toks/s]
Completed sample logical_deduction_556 (iteration 109) for method cot
Processing sample logical_deduction_792 (iteration 110) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.57s/it, est. speed input: 149.31 toks/s, output: 23.72 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.57s/it, est. speed input: 149.31 toks/s, output: 23.72 toks/s]
Completed sample logical_deduction_792 (iteration 110) for method cot
Processing sample logical_deduction_636 (iteration 111) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.49s/it, est. speed input: 130.71 toks/s, output: 23.58 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.49s/it, est. speed input: 130.71 toks/s, output: 23.58 toks/s]
Completed sample logical_deduction_636 (iteration 111) for method cot
Processing sample logical_deduction_554 (iteration 112) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.33s/it, est. speed input: 133.71 toks/s, output: 23.48 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.33s/it, est. speed input: 133.71 toks/s, output: 23.48 toks/s]
Completed sample logical_deduction_554 (iteration 112) for method cot
Processing sample logical_deduction_541 (iteration 113) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.72s/it, est. speed input: 128.42 toks/s, output: 23.64 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.72s/it, est. speed input: 128.42 toks/s, output: 23.64 toks/s]
Completed sample logical_deduction_541 (iteration 113) for method cot
Processing sample logical_deduction_482 (iteration 114) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.77s/it, est. speed input: 117.43 toks/s, output: 23.82 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.77s/it, est. speed input: 117.43 toks/s, output: 23.82 toks/s]
Completed sample logical_deduction_482 (iteration 114) for method cot
Processing sample logical_deduction_953 (iteration 115) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.76s/it, est. speed input: 117.43 toks/s, output: 23.89 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.77s/it, est. speed input: 117.43 toks/s, output: 23.89 toks/s]
Completed sample logical_deduction_953 (iteration 115) for method cot
Processing sample logical_deduction_727 (iteration 116) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.54s/it, est. speed input: 119.21 toks/s, output: 23.84 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.54s/it, est. speed input: 119.21 toks/s, output: 23.84 toks/s]
Completed sample logical_deduction_727 (iteration 116) for method cot
Processing sample logical_deduction_175 (iteration 117) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.03s/it, est. speed input: 116.54 toks/s, output: 23.78 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.03s/it, est. speed input: 116.54 toks/s, output: 23.78 toks/s]
Completed sample logical_deduction_175 (iteration 117) for method cot
Processing sample logical_deduction_678 (iteration 118) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.45s/it, est. speed input: 111.64 toks/s, output: 23.93 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.46s/it, est. speed input: 111.64 toks/s, output: 23.93 toks/s]
Completed sample logical_deduction_678 (iteration 118) for method cot
Processing sample logical_deduction_173 (iteration 119) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.25s/it, est. speed input: 105.30 toks/s, output: 23.87 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.25s/it, est. speed input: 105.30 toks/s, output: 23.87 toks/s]
Completed sample logical_deduction_173 (iteration 119) for method cot
Processing sample logical_deduction_692 (iteration 120) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.08s/it, est. speed input: 110.60 toks/s, output: 23.85 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.08s/it, est. speed input: 110.60 toks/s, output: 23.85 toks/s]
Completed sample logical_deduction_692 (iteration 120) for method cot
Processing sample logical_deduction_479 (iteration 121) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.45s/it, est. speed input: 158.78 toks/s, output: 23.70 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.45s/it, est. speed input: 158.78 toks/s, output: 23.70 toks/s]
Completed sample logical_deduction_479 (iteration 121) for method cot
Processing sample logical_deduction_850 (iteration 122) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.82s/it, est. speed input: 109.78 toks/s, output: 23.88 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.82s/it, est. speed input: 109.78 toks/s, output: 23.88 toks/s]
Completed sample logical_deduction_850 (iteration 122) for method cot
Processing sample logical_deduction_681 (iteration 123) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:16<00:00, 16.34s/it, est. speed input: 91.98 toks/s, output: 23.93 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:16<00:00, 16.34s/it, est. speed input: 91.98 toks/s, output: 23.93 toks/s]
Completed sample logical_deduction_681 (iteration 123) for method cot
Processing sample logical_deduction_644 (iteration 124) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.67s/it, est. speed input: 102.10 toks/s, output: 23.92 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.67s/it, est. speed input: 102.10 toks/s, output: 23.92 toks/s]
Completed sample logical_deduction_644 (iteration 124) for method cot
Processing sample logical_deduction_896 (iteration 125) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.94s/it, est. speed input: 100.34 toks/s, output: 23.76 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.94s/it, est. speed input: 100.34 toks/s, output: 23.76 toks/s]
Completed sample logical_deduction_896 (iteration 125) for method cot
Processing sample logical_deduction_933 (iteration 126) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.52s/it, est. speed input: 118.63 toks/s, output: 23.97 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.52s/it, est. speed input: 118.63 toks/s, output: 23.97 toks/s]
Completed sample logical_deduction_933 (iteration 126) for method cot
Processing sample logical_deduction_683 (iteration 127) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.20s/it, est. speed input: 123.25 toks/s, output: 23.52 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.20s/it, est. speed input: 123.25 toks/s, output: 23.52 toks/s]
Completed sample logical_deduction_683 (iteration 127) for method cot
Processing sample logical_deduction_653 (iteration 128) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.16s/it, est. speed input: 113.53 toks/s, output: 23.56 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.16s/it, est. speed input: 113.53 toks/s, output: 23.56 toks/s]
Completed sample logical_deduction_653 (iteration 128) for method cot
Processing sample logical_deduction_665 (iteration 129) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.96s/it, est. speed input: 108.26 toks/s, output: 23.72 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.96s/it, est. speed input: 108.26 toks/s, output: 23.72 toks/s]
Completed sample logical_deduction_665 (iteration 129) for method cot
Processing sample logical_deduction_860 (iteration 130) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.91s/it, est. speed input: 115.06 toks/s, output: 23.86 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.91s/it, est. speed input: 115.06 toks/s, output: 23.86 toks/s]
Completed sample logical_deduction_860 (iteration 130) for method cot
Processing sample logical_deduction_165 (iteration 131) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.12s/it, est. speed input: 124.71 toks/s, output: 23.69 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.12s/it, est. speed input: 124.71 toks/s, output: 23.69 toks/s]
Completed sample logical_deduction_165 (iteration 131) for method cot
Processing sample logical_deduction_562 (iteration 132) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.26s/it, est. speed input: 146.77 toks/s, output: 23.78 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.26s/it, est. speed input: 146.77 toks/s, output: 23.78 toks/s]
Completed sample logical_deduction_562 (iteration 132) for method cot
Processing sample logical_deduction_856 (iteration 133) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.90s/it, est. speed input: 101.21 toks/s, output: 23.83 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.90s/it, est. speed input: 101.21 toks/s, output: 23.83 toks/s]
Completed sample logical_deduction_856 (iteration 133) for method cot
Processing sample logical_deduction_195 (iteration 134) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.71s/it, est. speed input: 119.08 toks/s, output: 23.85 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.71s/it, est. speed input: 119.08 toks/s, output: 23.85 toks/s]
Completed sample logical_deduction_195 (iteration 134) for method cot
Processing sample logical_deduction_836 (iteration 135) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.59s/it, est. speed input: 117.64 toks/s, output: 23.75 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.59s/it, est. speed input: 117.64 toks/s, output: 23.75 toks/s]
Completed sample logical_deduction_836 (iteration 135) for method cot
Processing sample logical_deduction_916 (iteration 136) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.20s/it, est. speed input: 106.02 toks/s, output: 23.79 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.21s/it, est. speed input: 106.02 toks/s, output: 23.79 toks/s]
Completed sample logical_deduction_916 (iteration 136) for method cot
Processing sample logical_deduction_853 (iteration 137) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.65s/it, est. speed input: 110.30 toks/s, output: 23.80 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.65s/it, est. speed input: 110.30 toks/s, output: 23.80 toks/s]
Completed sample logical_deduction_853 (iteration 137) for method cot
Processing sample logical_deduction_724 (iteration 138) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.50s/it, est. speed input: 111.15 toks/s, output: 23.92 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.50s/it, est. speed input: 111.15 toks/s, output: 23.92 toks/s]
Completed sample logical_deduction_724 (iteration 138) for method cot
Processing sample logical_deduction_112 (iteration 139) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.95s/it, est. speed input: 126.79 toks/s, output: 23.77 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.95s/it, est. speed input: 126.79 toks/s, output: 23.77 toks/s]
Completed sample logical_deduction_112 (iteration 139) for method cot
Processing sample logical_deduction_943 (iteration 140) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.55s/it, est. speed input: 166.76 toks/s, output: 23.76 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.55s/it, est. speed input: 166.76 toks/s, output: 23.76 toks/s]
Completed sample logical_deduction_943 (iteration 140) for method cot
Processing sample logical_deduction_148 (iteration 141) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.66s/it, est. speed input: 130.14 toks/s, output: 23.92 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.66s/it, est. speed input: 130.14 toks/s, output: 23.92 toks/s]
Completed sample logical_deduction_148 (iteration 141) for method cot
Processing sample logical_deduction_536 (iteration 142) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.90s/it, est. speed input: 144.15 toks/s, output: 23.74 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.90s/it, est. speed input: 144.15 toks/s, output: 23.74 toks/s]
Completed sample logical_deduction_536 (iteration 142) for method cot
Processing sample logical_deduction_867 (iteration 143) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.54s/it, est. speed input: 135.83 toks/s, output: 23.81 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.54s/it, est. speed input: 135.83 toks/s, output: 23.81 toks/s]
Completed sample logical_deduction_867 (iteration 143) for method cot
Processing sample logical_deduction_524 (iteration 144) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.97s/it, est. speed input: 158.96 toks/s, output: 23.63 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.97s/it, est. speed input: 158.96 toks/s, output: 23.63 toks/s]
Completed sample logical_deduction_524 (iteration 144) for method cot
Processing sample logical_deduction_655 (iteration 145) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.13s/it, est. speed input: 113.08 toks/s, output: 23.61 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.13s/it, est. speed input: 113.08 toks/s, output: 23.61 toks/s]
Completed sample logical_deduction_655 (iteration 145) for method cot
Processing sample logical_deduction_110 (iteration 146) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.32s/it, est. speed input: 104.77 toks/s, output: 23.61 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.32s/it, est. speed input: 104.77 toks/s, output: 23.61 toks/s]
Completed sample logical_deduction_110 (iteration 146) for method cot
Processing sample logical_deduction_451 (iteration 147) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:16<00:00, 16.97s/it, est. speed input: 83.96 toks/s, output: 23.86 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:16<00:00, 16.97s/it, est. speed input: 83.96 toks/s, output: 23.86 toks/s]
Completed sample logical_deduction_451 (iteration 147) for method cot
Processing sample logical_deduction_875 (iteration 148) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.81s/it, est. speed input: 102.44 toks/s, output: 23.91 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.81s/it, est. speed input: 102.44 toks/s, output: 23.91 toks/s]
Completed sample logical_deduction_875 (iteration 148) for method cot
Processing sample logical_deduction_930 (iteration 149) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.20s/it, est. speed input: 121.67 toks/s, output: 23.86 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.20s/it, est. speed input: 121.67 toks/s, output: 23.86 toks/s]
Completed sample logical_deduction_930 (iteration 149) for method cot
Processing sample logical_deduction_580 (iteration 150) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.17s/it, est. speed input: 133.62 toks/s, output: 23.81 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.17s/it, est. speed input: 133.62 toks/s, output: 23.81 toks/s]
Completed sample logical_deduction_580 (iteration 150) for method cot
Processing sample logical_deduction_624 (iteration 151) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.03s/it, est. speed input: 159.87 toks/s, output: 23.71 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.03s/it, est. speed input: 159.87 toks/s, output: 23.71 toks/s]
Completed sample logical_deduction_624 (iteration 151) for method cot
Processing sample logical_deduction_835 (iteration 152) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.78s/it, est. speed input: 126.30 toks/s, output: 23.77 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.78s/it, est. speed input: 126.30 toks/s, output: 23.77 toks/s]
Completed sample logical_deduction_835 (iteration 152) for method cot
Processing sample logical_deduction_509 (iteration 153) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.95s/it, est. speed input: 125.48 toks/s, output: 23.77 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.95s/it, est. speed input: 125.48 toks/s, output: 23.77 toks/s]
Completed sample logical_deduction_509 (iteration 153) for method cot
Processing sample logical_deduction_405 (iteration 154) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.26s/it, est. speed input: 108.84 toks/s, output: 23.83 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.26s/it, est. speed input: 108.84 toks/s, output: 23.83 toks/s]
Completed sample logical_deduction_405 (iteration 154) for method cot
Processing sample logical_deduction_551 (iteration 155) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.30s/it, est. speed input: 132.12 toks/s, output: 23.80 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.30s/it, est. speed input: 132.12 toks/s, output: 23.80 toks/s]
Completed sample logical_deduction_551 (iteration 155) for method cot
Processing sample logical_deduction_649 (iteration 156) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.99s/it, est. speed input: 106.09 toks/s, output: 23.38 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.99s/it, est. speed input: 106.09 toks/s, output: 23.38 toks/s]
Completed sample logical_deduction_649 (iteration 156) for method cot
Processing sample logical_deduction_809 (iteration 157) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.68s/it, est. speed input: 109.00 toks/s, output: 23.54 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.68s/it, est. speed input: 109.00 toks/s, output: 23.54 toks/s]
Completed sample logical_deduction_809 (iteration 157) for method cot
Processing sample logical_deduction_906 (iteration 158) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.82s/it, est. speed input: 136.64 toks/s, output: 23.19 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.83s/it, est. speed input: 136.64 toks/s, output: 23.19 toks/s]
Completed sample logical_deduction_906 (iteration 158) for method cot
Processing sample logical_deduction_793 (iteration 159) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.24s/it, est. speed input: 112.13 toks/s, output: 23.33 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.24s/it, est. speed input: 112.13 toks/s, output: 23.33 toks/s]
Completed sample logical_deduction_793 (iteration 159) for method cot
Processing sample logical_deduction_599 (iteration 160) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.42s/it, est. speed input: 112.92 toks/s, output: 23.55 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.42s/it, est. speed input: 112.92 toks/s, output: 23.55 toks/s]
Completed sample logical_deduction_599 (iteration 160) for method cot
Processing sample logical_deduction_129 (iteration 161) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.31s/it, est. speed input: 120.19 toks/s, output: 23.81 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.31s/it, est. speed input: 120.19 toks/s, output: 23.81 toks/s]
Completed sample logical_deduction_129 (iteration 161) for method cot
Processing sample logical_deduction_824 (iteration 162) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.81s/it, est. speed input: 138.62 toks/s, output: 23.50 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.81s/it, est. speed input: 138.62 toks/s, output: 23.50 toks/s]
Completed sample logical_deduction_824 (iteration 162) for method cot
Processing sample logical_deduction_866 (iteration 163) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.87s/it, est. speed input: 101.38 toks/s, output: 23.73 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.88s/it, est. speed input: 101.38 toks/s, output: 23.73 toks/s]
Completed sample logical_deduction_866 (iteration 163) for method cot
Processing sample logical_deduction_474 (iteration 164) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.89s/it, est. speed input: 100.07 toks/s, output: 21.09 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.89s/it, est. speed input: 100.07 toks/s, output: 21.09 toks/s]
Completed sample logical_deduction_474 (iteration 164) for method cot
Processing sample logical_deduction_886 (iteration 165) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.52s/it, est. speed input: 111.82 toks/s, output: 23.37 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.52s/it, est. speed input: 111.82 toks/s, output: 23.37 toks/s]
Completed sample logical_deduction_886 (iteration 165) for method cot
Processing sample logical_deduction_650 (iteration 166) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.39s/it, est. speed input: 142.83 toks/s, output: 23.77 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.39s/it, est. speed input: 142.83 toks/s, output: 23.77 toks/s]
Completed sample logical_deduction_650 (iteration 166) for method cot
Processing sample logical_deduction_447 (iteration 167) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.42s/it, est. speed input: 112.90 toks/s, output: 23.85 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.42s/it, est. speed input: 112.90 toks/s, output: 23.85 toks/s]
Completed sample logical_deduction_447 (iteration 167) for method cot
Processing sample logical_deduction_425 (iteration 168) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.71s/it, est. speed input: 129.12 toks/s, output: 23.83 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.71s/it, est. speed input: 129.12 toks/s, output: 23.83 toks/s]
Completed sample logical_deduction_425 (iteration 168) for method cot
Processing sample logical_deduction_550 (iteration 169) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.71s/it, est. speed input: 109.02 toks/s, output: 23.85 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.71s/it, est. speed input: 109.02 toks/s, output: 23.85 toks/s]
Completed sample logical_deduction_550 (iteration 169) for method cot
Processing sample logical_deduction_603 (iteration 170) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.42s/it, est. speed input: 119.97 toks/s, output: 23.83 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.42s/it, est. speed input: 119.97 toks/s, output: 23.83 toks/s]
Completed sample logical_deduction_603 (iteration 170) for method cot
Processing sample logical_deduction_630 (iteration 171) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.95s/it, est. speed input: 135.94 toks/s, output: 24.21 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.95s/it, est. speed input: 135.94 toks/s, output: 24.21 toks/s]
Completed sample logical_deduction_630 (iteration 171) for method cot
Processing sample logical_deduction_717 (iteration 172) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.87s/it, est. speed input: 161.06 toks/s, output: 24.01 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.87s/it, est. speed input: 161.06 toks/s, output: 24.01 toks/s]
Completed sample logical_deduction_717 (iteration 172) for method cot
Processing sample logical_deduction_640 (iteration 173) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.65s/it, est. speed input: 118.46 toks/s, output: 24.18 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.65s/it, est. speed input: 118.46 toks/s, output: 24.18 toks/s]
Completed sample logical_deduction_640 (iteration 173) for method cot
Processing sample logical_deduction_495 (iteration 174) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.51s/it, est. speed input: 119.27 toks/s, output: 24.14 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.51s/it, est. speed input: 119.27 toks/s, output: 24.14 toks/s]
Completed sample logical_deduction_495 (iteration 174) for method cot
Processing sample logical_deduction_743 (iteration 175) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.01s/it, est. speed input: 125.85 toks/s, output: 24.15 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.01s/it, est. speed input: 125.85 toks/s, output: 24.15 toks/s]
Completed sample logical_deduction_743 (iteration 175) for method cot
Processing sample logical_deduction_174 (iteration 176) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.65s/it, est. speed input: 102.32 toks/s, output: 24.09 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.65s/it, est. speed input: 102.32 toks/s, output: 24.09 toks/s]
Completed sample logical_deduction_174 (iteration 176) for method cot
Processing sample logical_deduction_927 (iteration 177) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.40s/it, est. speed input: 126.35 toks/s, output: 24.03 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.41s/it, est. speed input: 126.35 toks/s, output: 24.03 toks/s]
Completed sample logical_deduction_927 (iteration 177) for method cot
Processing sample logical_deduction_690 (iteration 178) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.29s/it, est. speed input: 146.85 toks/s, output: 24.10 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.29s/it, est. speed input: 146.85 toks/s, output: 24.10 toks/s]
Completed sample logical_deduction_690 (iteration 178) for method cot
Processing sample logical_deduction_486 (iteration 179) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.58s/it, est. speed input: 110.73 toks/s, output: 23.78 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.58s/it, est. speed input: 110.73 toks/s, output: 23.78 toks/s]
Completed sample logical_deduction_486 (iteration 179) for method cot
Processing sample logical_deduction_573 (iteration 180) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.53s/it, est. speed input: 167.59 toks/s, output: 23.69 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.53s/it, est. speed input: 167.59 toks/s, output: 23.69 toks/s]
Completed sample logical_deduction_573 (iteration 180) for method cot
Processing sample logical_deduction_884 (iteration 181) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.78s/it, est. speed input: 117.26 toks/s, output: 23.86 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.78s/it, est. speed input: 117.26 toks/s, output: 23.86 toks/s]
Completed sample logical_deduction_884 (iteration 181) for method cot
Processing sample logical_deduction_231 (iteration 182) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.29s/it, est. speed input: 132.96 toks/s, output: 24.09 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.29s/it, est. speed input: 132.96 toks/s, output: 24.09 toks/s]
Completed sample logical_deduction_231 (iteration 182) for method cot
Processing sample logical_deduction_618 (iteration 183) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.17s/it, est. speed input: 122.02 toks/s, output: 23.99 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.17s/it, est. speed input: 122.02 toks/s, output: 23.99 toks/s]
Completed sample logical_deduction_618 (iteration 183) for method cot
Processing sample logical_deduction_185 (iteration 184) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.90s/it, est. speed input: 101.84 toks/s, output: 24.17 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.90s/it, est. speed input: 101.84 toks/s, output: 24.17 toks/s]
Completed sample logical_deduction_185 (iteration 184) for method cot
Processing sample logical_deduction_852 (iteration 185) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.25s/it, est. speed input: 122.96 toks/s, output: 24.25 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.25s/it, est. speed input: 122.96 toks/s, output: 24.25 toks/s]
Completed sample logical_deduction_852 (iteration 185) for method cot
Processing sample logical_deduction_876 (iteration 186) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.61s/it, est. speed input: 101.95 toks/s, output: 23.55 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.61s/it, est. speed input: 101.95 toks/s, output: 23.55 toks/s]
Completed sample logical_deduction_876 (iteration 186) for method cot
Processing sample logical_deduction_729 (iteration 187) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.72s/it, est. speed input: 119.09 toks/s, output: 24.05 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.72s/it, est. speed input: 119.09 toks/s, output: 24.05 toks/s]
Completed sample logical_deduction_729 (iteration 187) for method cot
Processing sample logical_deduction_161 (iteration 188) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.54s/it, est. speed input: 103.56 toks/s, output: 24.14 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.54s/it, est. speed input: 103.56 toks/s, output: 24.14 toks/s]
Completed sample logical_deduction_161 (iteration 188) for method cot
Processing sample logical_deduction_133 (iteration 189) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.41s/it, est. speed input: 121.88 toks/s, output: 24.09 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.41s/it, est. speed input: 121.88 toks/s, output: 24.09 toks/s]
Completed sample logical_deduction_133 (iteration 189) for method cot
Processing sample logical_deduction_840 (iteration 190) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.43s/it, est. speed input: 143.59 toks/s, output: 23.96 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.43s/it, est. speed input: 143.59 toks/s, output: 23.96 toks/s]
Completed sample logical_deduction_840 (iteration 190) for method cot
Processing sample logical_deduction_615 (iteration 191) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.13s/it, est. speed input: 133.38 toks/s, output: 24.07 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.14s/it, est. speed input: 133.38 toks/s, output: 24.07 toks/s]
Completed sample logical_deduction_615 (iteration 191) for method cot
Processing sample logical_deduction_693 (iteration 192) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.03s/it, est. speed input: 116.09 toks/s, output: 24.09 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.03s/it, est. speed input: 116.09 toks/s, output: 24.09 toks/s]
Completed sample logical_deduction_693 (iteration 192) for method cot
Processing sample logical_deduction_711 (iteration 193) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.07s/it, est. speed input: 106.35 toks/s, output: 23.96 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.07s/it, est. speed input: 106.35 toks/s, output: 23.96 toks/s]
Completed sample logical_deduction_711 (iteration 193) for method cot
Processing sample logical_deduction_400 (iteration 194) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.64s/it, est. speed input: 147.85 toks/s, output: 24.07 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.64s/it, est. speed input: 147.85 toks/s, output: 24.07 toks/s]
Completed sample logical_deduction_400 (iteration 194) for method cot
Processing sample logical_deduction_101 (iteration 195) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.79s/it, est. speed input: 101.32 toks/s, output: 24.20 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.80s/it, est. speed input: 101.32 toks/s, output: 24.20 toks/s]
Completed sample logical_deduction_101 (iteration 195) for method cot
Processing sample logical_deduction_815 (iteration 196) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.66s/it, est. speed input: 141.02 toks/s, output: 23.74 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.66s/it, est. speed input: 141.02 toks/s, output: 23.74 toks/s]
Completed sample logical_deduction_815 (iteration 196) for method cot
Processing sample logical_deduction_708 (iteration 197) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.68s/it, est. speed input: 103.48 toks/s, output: 23.84 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.68s/it, est. speed input: 103.48 toks/s, output: 23.84 toks/s]
Completed sample logical_deduction_708 (iteration 197) for method cot
Processing sample logical_deduction_122 (iteration 198) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.55s/it, est. speed input: 111.80 toks/s, output: 23.91 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.55s/it, est. speed input: 111.80 toks/s, output: 23.91 toks/s]
Completed sample logical_deduction_122 (iteration 198) for method cot
Processing sample logical_deduction_170 (iteration 199) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.60s/it, est. speed input: 156.75 toks/s, output: 24.06 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.60s/it, est. speed input: 156.75 toks/s, output: 24.06 toks/s]
Completed sample logical_deduction_170 (iteration 199) for method cot
Processing sample logical_deduction_578 (iteration 200) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.46s/it, est. speed input: 124.34 toks/s, output: 23.99 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.46s/it, est. speed input: 124.34 toks/s, output: 23.99 toks/s]
Completed sample logical_deduction_578 (iteration 200) for method cot
Processing sample logical_deduction_788 (iteration 201) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.67s/it, est. speed input: 109.92 toks/s, output: 24.13 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.67s/it, est. speed input: 109.92 toks/s, output: 24.13 toks/s]
Completed sample logical_deduction_788 (iteration 201) for method cot
Processing sample logical_deduction_830 (iteration 202) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.45s/it, est. speed input: 158.95 toks/s, output: 23.92 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.45s/it, est. speed input: 158.95 toks/s, output: 23.92 toks/s]
Completed sample logical_deduction_830 (iteration 202) for method cot
Processing sample logical_deduction_596 (iteration 203) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.03s/it, est. speed input: 148.82 toks/s, output: 24.04 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.03s/it, est. speed input: 148.82 toks/s, output: 24.04 toks/s]
Completed sample logical_deduction_596 (iteration 203) for method cot
Processing sample logical_deduction_530 (iteration 204) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.07s/it, est. speed input: 118.94 toks/s, output: 24.10 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.07s/it, est. speed input: 118.94 toks/s, output: 24.10 toks/s]
Completed sample logical_deduction_530 (iteration 204) for method cot
Processing sample logical_deduction_107 (iteration 205) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:15<00:00, 15.16s/it, est. speed input: 99.31 toks/s, output: 24.20 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:15<00:00, 15.16s/it, est. speed input: 99.31 toks/s, output: 24.20 toks/s]
Completed sample logical_deduction_107 (iteration 205) for method cot
Processing sample logical_deduction_702 (iteration 206) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.47s/it, est. speed input: 130.43 toks/s, output: 24.06 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.47s/it, est. speed input: 130.43 toks/s, output: 24.06 toks/s]
Completed sample logical_deduction_702 (iteration 206) for method cot
Processing sample logical_deduction_812 (iteration 207) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:15<00:00, 15.03s/it, est. speed input: 99.28 toks/s, output: 24.22 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:15<00:00, 15.03s/it, est. speed input: 99.28 toks/s, output: 24.22 toks/s]
Completed sample logical_deduction_812 (iteration 207) for method cot
Processing sample logical_deduction_734 (iteration 208) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.55s/it, est. speed input: 190.51 toks/s, output: 23.83 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.55s/it, est. speed input: 190.51 toks/s, output: 23.83 toks/s]
Completed sample logical_deduction_734 (iteration 208) for method cot
Processing sample logical_deduction_818 (iteration 209) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.58s/it, est. speed input: 109.32 toks/s, output: 24.09 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.58s/it, est. speed input: 109.32 toks/s, output: 24.09 toks/s]
Completed sample logical_deduction_818 (iteration 209) for method cot
Processing sample logical_deduction_716 (iteration 210) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.58s/it, est. speed input: 124.66 toks/s, output: 24.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.58s/it, est. speed input: 124.66 toks/s, output: 24.00 toks/s]
Completed sample logical_deduction_716 (iteration 210) for method cot
Processing sample logical_deduction_919 (iteration 211) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:15<00:00, 15.64s/it, est. speed input: 96.43 toks/s, output: 24.11 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:15<00:00, 15.64s/it, est. speed input: 96.43 toks/s, output: 24.11 toks/s]
Completed sample logical_deduction_919 (iteration 211) for method cot
Processing sample logical_deduction_707 (iteration 212) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.38s/it, est. speed input: 132.67 toks/s, output: 23.99 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.38s/it, est. speed input: 132.67 toks/s, output: 23.99 toks/s]
Completed sample logical_deduction_707 (iteration 212) for method cot
Processing sample logical_deduction_527 (iteration 213) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.94s/it, est. speed input: 137.54 toks/s, output: 24.04 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.94s/it, est. speed input: 137.54 toks/s, output: 24.04 toks/s]
Completed sample logical_deduction_527 (iteration 213) for method cot
Processing sample logical_deduction_234 (iteration 214) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.60s/it, est. speed input: 142.05 toks/s, output: 23.67 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.60s/it, est. speed input: 142.05 toks/s, output: 23.67 toks/s]
Completed sample logical_deduction_234 (iteration 214) for method cot
Processing sample logical_deduction_178 (iteration 215) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.87s/it, est. speed input: 161.16 toks/s, output: 23.57 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.87s/it, est. speed input: 161.16 toks/s, output: 23.57 toks/s]
Completed sample logical_deduction_178 (iteration 215) for method cot
Processing sample logical_deduction_738 (iteration 216) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.37s/it, est. speed input: 152.19 toks/s, output: 23.69 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.37s/it, est. speed input: 152.19 toks/s, output: 23.69 toks/s]
Completed sample logical_deduction_738 (iteration 216) for method cot
Processing sample logical_deduction_471 (iteration 217) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.87s/it, est. speed input: 127.33 toks/s, output: 24.02 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.87s/it, est. speed input: 127.33 toks/s, output: 24.02 toks/s]
Completed sample logical_deduction_471 (iteration 217) for method cot
Processing sample logical_deduction_841 (iteration 218) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.87s/it, est. speed input: 108.31 toks/s, output: 24.16 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.87s/it, est. speed input: 108.31 toks/s, output: 24.16 toks/s]
Completed sample logical_deduction_841 (iteration 218) for method cot
Processing sample logical_deduction_772 (iteration 219) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.56s/it, est. speed input: 150.94 toks/s, output: 23.95 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.56s/it, est. speed input: 150.94 toks/s, output: 23.95 toks/s]
Completed sample logical_deduction_772 (iteration 219) for method cot
Processing sample logical_deduction_601 (iteration 220) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.36s/it, est. speed input: 103.71 toks/s, output: 24.17 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.36s/it, est. speed input: 103.71 toks/s, output: 24.17 toks/s]
Completed sample logical_deduction_601 (iteration 220) for method cot
Processing sample logical_deduction_951 (iteration 221) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.47s/it, est. speed input: 158.97 toks/s, output: 23.98 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.47s/it, est. speed input: 158.97 toks/s, output: 23.98 toks/s]
Completed sample logical_deduction_951 (iteration 221) for method cot
Processing sample logical_deduction_932 (iteration 222) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.07s/it, est. speed input: 115.38 toks/s, output: 24.10 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.07s/it, est. speed input: 115.38 toks/s, output: 24.10 toks/s]
Completed sample logical_deduction_932 (iteration 222) for method cot
Processing sample logical_deduction_401 (iteration 223) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:15<00:00, 15.52s/it, est. speed input: 97.36 toks/s, output: 24.10 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:15<00:00, 15.52s/it, est. speed input: 97.36 toks/s, output: 24.10 toks/s]
Completed sample logical_deduction_401 (iteration 223) for method cot
Processing sample logical_deduction_233 (iteration 224) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.20s/it, est. speed input: 134.88 toks/s, output: 24.01 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.20s/it, est. speed input: 134.88 toks/s, output: 24.01 toks/s]
Completed sample logical_deduction_233 (iteration 224) for method cot
Processing sample logical_deduction_445 (iteration 225) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.89s/it, est. speed input: 137.79 toks/s, output: 24.05 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:10<00:00, 10.89s/it, est. speed input: 137.79 toks/s, output: 24.05 toks/s]
Completed sample logical_deduction_445 (iteration 225) for method cot
Processing sample logical_deduction_660 (iteration 226) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.02s/it, est. speed input: 108.34 toks/s, output: 24.18 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.02s/it, est. speed input: 108.34 toks/s, output: 24.18 toks/s]
Completed sample logical_deduction_660 (iteration 226) for method cot
Processing sample logical_deduction_594 (iteration 227) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.01s/it, est. speed input: 137.59 toks/s, output: 24.07 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:11<00:00, 11.01s/it, est. speed input: 137.59 toks/s, output: 24.07 toks/s]
Completed sample logical_deduction_594 (iteration 227) for method cot
Processing sample logical_deduction_130 (iteration 228) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.85s/it, est. speed input: 108.05 toks/s, output: 23.98 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.85s/it, est. speed input: 108.05 toks/s, output: 23.98 toks/s]
Completed sample logical_deduction_130 (iteration 228) for method cot
Processing sample logical_deduction_794 (iteration 229) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.80s/it, est. speed input: 115.68 toks/s, output: 24.06 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.80s/it, est. speed input: 115.68 toks/s, output: 24.06 toks/s]
Completed sample logical_deduction_794 (iteration 229) for method cot
Processing sample logical_deduction_518 (iteration 230) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.52s/it, est. speed input: 111.48 toks/s, output: 24.04 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.52s/it, est. speed input: 111.48 toks/s, output: 24.04 toks/s]
Completed sample logical_deduction_518 (iteration 230) for method cot
Processing sample logical_deduction_923 (iteration 231) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.36s/it, est. speed input: 119.54 toks/s, output: 24.02 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.36s/it, est. speed input: 119.54 toks/s, output: 24.02 toks/s]
Completed sample logical_deduction_923 (iteration 231) for method cot
Processing sample logical_deduction_160 (iteration 232) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.69s/it, est. speed input: 153.95 toks/s, output: 23.54 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.69s/it, est. speed input: 153.95 toks/s, output: 23.54 toks/s]
Completed sample logical_deduction_160 (iteration 232) for method cot
Processing sample logical_deduction_846 (iteration 233) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.79s/it, est. speed input: 101.36 toks/s, output: 23.80 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.79s/it, est. speed input: 101.36 toks/s, output: 23.80 toks/s]
Completed sample logical_deduction_846 (iteration 233) for method cot
Processing sample logical_deduction_721 (iteration 234) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.15s/it, est. speed input: 106.77 toks/s, output: 24.03 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.15s/it, est. speed input: 106.77 toks/s, output: 24.03 toks/s]
Completed sample logical_deduction_721 (iteration 234) for method cot
Processing sample logical_deduction_753 (iteration 235) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.62s/it, est. speed input: 215.08 toks/s, output: 23.73 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.62s/it, est. speed input: 215.08 toks/s, output: 23.73 toks/s]
Completed sample logical_deduction_753 (iteration 235) for method cot
Processing sample logical_deduction_844 (iteration 236) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.97s/it, est. speed input: 107.37 toks/s, output: 24.19 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.97s/it, est. speed input: 107.37 toks/s, output: 24.19 toks/s]
Completed sample logical_deduction_844 (iteration 236) for method cot
Processing sample logical_deduction_150 (iteration 237) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.93s/it, est. speed input: 110.63 toks/s, output: 24.06 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.93s/it, est. speed input: 110.63 toks/s, output: 24.06 toks/s]
Completed sample logical_deduction_150 (iteration 237) for method cot
Processing sample logical_deduction_511 (iteration 238) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.21s/it, est. speed input: 123.40 toks/s, output: 23.99 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.21s/it, est. speed input: 123.40 toks/s, output: 23.99 toks/s]
Completed sample logical_deduction_511 (iteration 238) for method cot
Processing sample logical_deduction_439 (iteration 239) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.42s/it, est. speed input: 116.38 toks/s, output: 23.74 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.43s/it, est. speed input: 116.38 toks/s, output: 23.74 toks/s]
Completed sample logical_deduction_439 (iteration 239) for method cot
Processing sample logical_deduction_1125 (iteration 240) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.86s/it, est. speed input: 285.44 toks/s, output: 23.44 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.86s/it, est. speed input: 285.44 toks/s, output: 23.44 toks/s]
Completed sample logical_deduction_1125 (iteration 240) for method cot
Processing sample logical_deduction_244 (iteration 241) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.27s/it, est. speed input: 264.51 toks/s, output: 23.36 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.27s/it, est. speed input: 264.51 toks/s, output: 23.36 toks/s]
Completed sample logical_deduction_244 (iteration 241) for method cot
Processing sample logical_deduction_1191 (iteration 242) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.20s/it, est. speed input: 269.35 toks/s, output: 23.46 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.20s/it, est. speed input: 269.35 toks/s, output: 23.46 toks/s]
Completed sample logical_deduction_1191 (iteration 242) for method cot
Processing sample logical_deduction_984 (iteration 243) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.13s/it, est. speed input: 268.13 toks/s, output: 23.40 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.13s/it, est. speed input: 268.13 toks/s, output: 23.40 toks/s]
Completed sample logical_deduction_984 (iteration 243) for method cot
Processing sample logical_deduction_1120 (iteration 244) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.32s/it, est. speed input: 262.82 toks/s, output: 23.48 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.32s/it, est. speed input: 262.82 toks/s, output: 23.48 toks/s]
Completed sample logical_deduction_1120 (iteration 244) for method cot
Processing sample logical_deduction_995 (iteration 245) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.07s/it, est. speed input: 230.11 toks/s, output: 23.57 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.07s/it, est. speed input: 230.11 toks/s, output: 23.57 toks/s]
Completed sample logical_deduction_995 (iteration 245) for method cot
Processing sample logical_deduction_1174 (iteration 246) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.22s/it, est. speed input: 325.51 toks/s, output: 23.20 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.22s/it, est. speed input: 325.51 toks/s, output: 23.20 toks/s]
Completed sample logical_deduction_1174 (iteration 246) for method cot
Processing sample logical_deduction_1134 (iteration 247) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.08s/it, est. speed input: 270.61 toks/s, output: 23.42 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.08s/it, est. speed input: 270.61 toks/s, output: 23.42 toks/s]
Completed sample logical_deduction_1134 (iteration 247) for method cot
Processing sample logical_deduction_1128 (iteration 248) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.67s/it, est. speed input: 246.15 toks/s, output: 23.47 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.67s/it, est. speed input: 246.15 toks/s, output: 23.47 toks/s]
Completed sample logical_deduction_1128 (iteration 248) for method cot
Processing sample logical_deduction_273 (iteration 249) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.80s/it, est. speed input: 286.22 toks/s, output: 23.33 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.80s/it, est. speed input: 286.22 toks/s, output: 23.33 toks/s]
Completed sample logical_deduction_273 (iteration 249) for method cot
Processing sample logical_deduction_1144 (iteration 250) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.22s/it, est. speed input: 326.09 toks/s, output: 23.24 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.22s/it, est. speed input: 326.09 toks/s, output: 23.24 toks/s]
Completed sample logical_deduction_1144 (iteration 250) for method cot
Processing sample logical_deduction_1153 (iteration 251) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.37s/it, est. speed input: 256.10 toks/s, output: 23.47 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.37s/it, est. speed input: 256.10 toks/s, output: 23.47 toks/s]
Completed sample logical_deduction_1153 (iteration 251) for method cot
Processing sample logical_deduction_1133 (iteration 252) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.21s/it, est. speed input: 269.49 toks/s, output: 23.24 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.21s/it, est. speed input: 269.49 toks/s, output: 23.24 toks/s]
Completed sample logical_deduction_1133 (iteration 252) for method cot
Processing sample logical_deduction_1024 (iteration 253) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.58s/it, est. speed input: 303.52 toks/s, output: 23.35 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.58s/it, est. speed input: 303.52 toks/s, output: 23.35 toks/s]
Completed sample logical_deduction_1024 (iteration 253) for method cot
Processing sample logical_deduction_1118 (iteration 254) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.18s/it, est. speed input: 329.32 toks/s, output: 23.23 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.18s/it, est. speed input: 329.32 toks/s, output: 23.23 toks/s]
Completed sample logical_deduction_1118 (iteration 254) for method cot
Processing sample logical_deduction_1057 (iteration 255) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.96s/it, est. speed input: 235.62 toks/s, output: 23.66 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.96s/it, est. speed input: 235.62 toks/s, output: 23.66 toks/s]
Completed sample logical_deduction_1057 (iteration 255) for method cot
Processing sample logical_deduction_1072 (iteration 256) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.77s/it, est. speed input: 243.02 toks/s, output: 23.56 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.77s/it, est. speed input: 243.02 toks/s, output: 23.56 toks/s]
Completed sample logical_deduction_1072 (iteration 256) for method cot
Processing sample logical_deduction_1140 (iteration 257) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.60s/it, est. speed input: 301.95 toks/s, output: 23.24 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.60s/it, est. speed input: 301.95 toks/s, output: 23.24 toks/s]
Completed sample logical_deduction_1140 (iteration 257) for method cot
Processing sample logical_deduction_1077 (iteration 258) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.49s/it, est. speed input: 256.42 toks/s, output: 23.49 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.49s/it, est. speed input: 256.42 toks/s, output: 23.49 toks/s]
Completed sample logical_deduction_1077 (iteration 258) for method cot
Processing sample logical_deduction_1106 (iteration 259) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.68s/it, est. speed input: 246.53 toks/s, output: 23.40 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.68s/it, est. speed input: 246.53 toks/s, output: 23.40 toks/s]
Completed sample logical_deduction_1106 (iteration 259) for method cot
Processing sample logical_deduction_294 (iteration 260) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.07s/it, est. speed input: 275.01 toks/s, output: 23.66 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.07s/it, est. speed input: 275.01 toks/s, output: 23.66 toks/s]
Completed sample logical_deduction_294 (iteration 260) for method cot
Processing sample logical_deduction_985 (iteration 261) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.63s/it, est. speed input: 297.37 toks/s, output: 23.52 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.63s/it, est. speed input: 297.37 toks/s, output: 23.52 toks/s]
Completed sample logical_deduction_985 (iteration 261) for method cot
Processing sample logical_deduction_287 (iteration 262) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.26s/it, est. speed input: 266.14 toks/s, output: 23.18 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.26s/it, est. speed input: 266.14 toks/s, output: 23.18 toks/s]
Completed sample logical_deduction_287 (iteration 262) for method cot
Processing sample logical_deduction_1100 (iteration 263) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.41s/it, est. speed input: 258.23 toks/s, output: 23.27 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.41s/it, est. speed input: 258.23 toks/s, output: 23.27 toks/s]
Completed sample logical_deduction_1100 (iteration 263) for method cot
Processing sample logical_deduction_1162 (iteration 264) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.46s/it, est. speed input: 257.93 toks/s, output: 23.08 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.46s/it, est. speed input: 257.93 toks/s, output: 23.08 toks/s]
Completed sample logical_deduction_1162 (iteration 264) for method cot
Processing sample logical_deduction_971 (iteration 265) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.09s/it, est. speed input: 273.91 toks/s, output: 22.99 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.09s/it, est. speed input: 273.91 toks/s, output: 22.99 toks/s]
Completed sample logical_deduction_971 (iteration 265) for method cot
Processing sample logical_deduction_267 (iteration 266) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.39s/it, est. speed input: 258.49 toks/s, output: 23.18 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.39s/it, est. speed input: 258.49 toks/s, output: 23.18 toks/s]
Completed sample logical_deduction_267 (iteration 266) for method cot
Processing sample logical_deduction_1111 (iteration 267) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.07s/it, est. speed input: 275.11 toks/s, output: 23.47 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.07s/it, est. speed input: 275.11 toks/s, output: 23.47 toks/s]
Completed sample logical_deduction_1111 (iteration 267) for method cot
Processing sample logical_deduction_1143 (iteration 268) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.35s/it, est. speed input: 261.07 toks/s, output: 23.17 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.35s/it, est. speed input: 261.07 toks/s, output: 23.17 toks/s]
Completed sample logical_deduction_1143 (iteration 268) for method cot
Processing sample logical_deduction_296 (iteration 269) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [01:49<00:00, 109.28s/it, est. speed input: 12.58 toks/s, output: 24.25 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [01:49<00:00, 109.29s/it, est. speed input: 12.58 toks/s, output: 24.25 toks/s]
Completed sample logical_deduction_296 (iteration 269) for method cot
Processing sample logical_deduction_1081 (iteration 270) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.44s/it, est. speed input: 259.18 toks/s, output: 23.51 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.44s/it, est. speed input: 259.18 toks/s, output: 23.51 toks/s]
Completed sample logical_deduction_1081 (iteration 270) for method cot
Processing sample logical_deduction_1014 (iteration 271) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.36s/it, est. speed input: 262.00 toks/s, output: 23.31 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.36s/it, est. speed input: 262.00 toks/s, output: 23.31 toks/s]
Completed sample logical_deduction_1014 (iteration 271) for method cot
Processing sample logical_deduction_247 (iteration 272) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.82s/it, est. speed input: 289.41 toks/s, output: 23.25 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.82s/it, est. speed input: 289.41 toks/s, output: 23.25 toks/s]
Completed sample logical_deduction_247 (iteration 272) for method cot
Processing sample logical_deduction_1156 (iteration 273) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.98s/it, est. speed input: 280.95 toks/s, output: 23.30 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.98s/it, est. speed input: 280.95 toks/s, output: 23.30 toks/s]
Completed sample logical_deduction_1156 (iteration 273) for method cot
Processing sample logical_deduction_1061 (iteration 274) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.77s/it, est. speed input: 242.96 toks/s, output: 23.59 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.77s/it, est. speed input: 242.96 toks/s, output: 23.59 toks/s]
Completed sample logical_deduction_1061 (iteration 274) for method cot
Processing sample logical_deduction_1114 (iteration 275) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.91s/it, est. speed input: 285.00 toks/s, output: 23.43 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.91s/it, est. speed input: 285.00 toks/s, output: 23.43 toks/s]
Completed sample logical_deduction_1114 (iteration 275) for method cot
Processing sample logical_deduction_1193 (iteration 276) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.28s/it, est. speed input: 265.87 toks/s, output: 23.46 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.29s/it, est. speed input: 265.87 toks/s, output: 23.46 toks/s]
Completed sample logical_deduction_1193 (iteration 276) for method cot
Processing sample logical_deduction_1088 (iteration 277) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.39s/it, est. speed input: 260.21 toks/s, output: 23.57 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.39s/it, est. speed input: 260.21 toks/s, output: 23.57 toks/s]
Completed sample logical_deduction_1088 (iteration 277) for method cot
Processing sample logical_deduction_1177 (iteration 278) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.15s/it, est. speed input: 272.38 toks/s, output: 23.28 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.16s/it, est. speed input: 272.38 toks/s, output: 23.28 toks/s]
Completed sample logical_deduction_1177 (iteration 278) for method cot
Processing sample logical_deduction_1113 (iteration 279) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.99s/it, est. speed input: 280.80 toks/s, output: 23.45 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.99s/it, est. speed input: 280.80 toks/s, output: 23.45 toks/s]
Completed sample logical_deduction_1113 (iteration 279) for method cot
Processing sample logical_deduction_1136 (iteration 280) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.39s/it, est. speed input: 260.30 toks/s, output: 23.38 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.39s/it, est. speed input: 260.30 toks/s, output: 23.38 toks/s]
Completed sample logical_deduction_1136 (iteration 280) for method cot
Processing sample logical_deduction_1186 (iteration 281) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.25s/it, est. speed input: 323.04 toks/s, output: 23.51 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.25s/it, est. speed input: 323.04 toks/s, output: 23.51 toks/s]
Completed sample logical_deduction_1186 (iteration 281) for method cot
Processing sample logical_deduction_997 (iteration 282) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.57s/it, est. speed input: 252.81 toks/s, output: 23.50 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.57s/it, est. speed input: 252.81 toks/s, output: 23.50 toks/s]
Completed sample logical_deduction_997 (iteration 282) for method cot
Processing sample logical_deduction_1040 (iteration 283) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.42s/it, est. speed input: 257.76 toks/s, output: 23.06 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.42s/it, est. speed input: 257.76 toks/s, output: 23.06 toks/s]
Completed sample logical_deduction_1040 (iteration 283) for method cot
Processing sample logical_deduction_279 (iteration 284) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.22s/it, est. speed input: 270.18 toks/s, output: 22.98 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.22s/it, est. speed input: 270.18 toks/s, output: 22.98 toks/s]
Completed sample logical_deduction_279 (iteration 284) for method cot
Processing sample logical_deduction_1107 (iteration 285) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.15s/it, est. speed input: 272.66 toks/s, output: 23.09 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.15s/it, est. speed input: 272.66 toks/s, output: 23.09 toks/s]
Completed sample logical_deduction_1107 (iteration 285) for method cot
Processing sample logical_deduction_1198 (iteration 286) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.79s/it, est. speed input: 291.30 toks/s, output: 22.97 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.79s/it, est. speed input: 291.30 toks/s, output: 22.97 toks/s]
Completed sample logical_deduction_1198 (iteration 286) for method cot
Processing sample logical_deduction_964 (iteration 287) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.85s/it, est. speed input: 288.60 toks/s, output: 23.07 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.86s/it, est. speed input: 288.60 toks/s, output: 23.07 toks/s]
Completed sample logical_deduction_964 (iteration 287) for method cot
Processing sample logical_deduction_290 (iteration 288) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.62s/it, est. speed input: 301.81 toks/s, output: 22.97 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.62s/it, est. speed input: 301.81 toks/s, output: 22.97 toks/s]
Completed sample logical_deduction_290 (iteration 288) for method cot
Processing sample logical_deduction_1195 (iteration 289) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.28s/it, est. speed input: 265.11 toks/s, output: 23.12 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.28s/it, est. speed input: 265.11 toks/s, output: 23.12 toks/s]
Completed sample logical_deduction_1195 (iteration 289) for method cot
Processing sample logical_deduction_1090 (iteration 290) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.61s/it, est. speed input: 249.72 toks/s, output: 23.51 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.61s/it, est. speed input: 249.72 toks/s, output: 23.51 toks/s]
Completed sample logical_deduction_1090 (iteration 290) for method cot
Processing sample logical_deduction_1196 (iteration 291) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.77s/it, est. speed input: 242.80 toks/s, output: 23.40 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.77s/it, est. speed input: 242.80 toks/s, output: 23.40 toks/s]
Completed sample logical_deduction_1196 (iteration 291) for method cot
Processing sample logical_deduction_1078 (iteration 292) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.98s/it, est. speed input: 279.94 toks/s, output: 23.30 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.98s/it, est. speed input: 279.94 toks/s, output: 23.30 toks/s]
Completed sample logical_deduction_1078 (iteration 292) for method cot
Processing sample logical_deduction_1033 (iteration 293) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.06s/it, est. speed input: 232.69 toks/s, output: 23.76 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.06s/it, est. speed input: 232.69 toks/s, output: 23.76 toks/s]
Completed sample logical_deduction_1033 (iteration 293) for method cot
Processing sample logical_deduction_254 (iteration 294) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.44s/it, est. speed input: 309.05 toks/s, output: 23.18 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.44s/it, est. speed input: 309.05 toks/s, output: 23.18 toks/s]
Completed sample logical_deduction_254 (iteration 294) for method cot
Processing sample logical_deduction_1083 (iteration 295) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.10s/it, est. speed input: 273.39 toks/s, output: 23.34 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.10s/it, est. speed input: 273.39 toks/s, output: 23.34 toks/s]
Completed sample logical_deduction_1083 (iteration 295) for method cot
Processing sample logical_deduction_1155 (iteration 296) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.16s/it, est. speed input: 270.10 toks/s, output: 23.25 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.16s/it, est. speed input: 270.10 toks/s, output: 23.25 toks/s]
Completed sample logical_deduction_1155 (iteration 296) for method cot
Processing sample logical_deduction_1000 (iteration 297) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.44s/it, est. speed input: 257.37 toks/s, output: 23.51 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.44s/it, est. speed input: 257.37 toks/s, output: 23.51 toks/s]
Completed sample logical_deduction_1000 (iteration 297) for method cot
Processing sample logical_deduction_1049 (iteration 298) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.01s/it, est. speed input: 277.85 toks/s, output: 23.35 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.01s/it, est. speed input: 277.85 toks/s, output: 23.35 toks/s]
Completed sample logical_deduction_1049 (iteration 298) for method cot
Processing sample logical_deduction_1047 (iteration 299) for method cot
Using LoRA from lora_adapters_experiment_6/grpo_saved_lora for generation
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.43s/it, est. speed input: 256.76 toks/s, output: 23.58 toks/s]Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.43s/it, est. speed input: 256.76 toks/s, output: 23.58 toks/s]
Completed sample logical_deduction_1047 (iteration 299) for method cot
Completed method: cot
Results saved to results_text_files/results_experiment_6.txt
Dataset composition:
  3-option problems: 60 (20.0%)
  5-option problems: 100 (33.3%)
  7-option problems: 140 (46.7%)

=== OVERALL PERFORMANCE ===

--- cot_answer ---
Accuracy: 53.67%
Answer distribution: {'A': 75, 'B': 60, 'C': 53, 'E': 36, 'D': 35, 'G': 20, 'F': 20, 'No answer extracted from output': 1}

--- direct_answer ---
Accuracy: 0.00%
Answer distribution: {}

=== PERFORMANCE BY PROBLEM TYPE ===

## 3-option problems ##

--- cot_answer ---
Accuracy: 81.67%
Answer distribution: {'C': 23, 'A': 20, 'B': 16, 'No answer extracted from output': 1}

--- direct_answer ---
Accuracy: 0.00%
Answer distribution: {}

## 5-option problems ##

--- cot_answer ---
Accuracy: 50.00%
Answer distribution: {'A': 27, 'B': 25, 'E': 19, 'D': 15, 'C': 14}

--- direct_answer ---
Accuracy: 0.00%
Answer distribution: {}

## 7-option problems ##

--- cot_answer ---
Accuracy: 44.29%
Answer distribution: {'A': 28, 'G': 20, 'F': 20, 'D': 20, 'B': 19, 'E': 17, 'C': 16}

--- direct_answer ---
Accuracy: 0.00%
Answer distribution: {}

=== RETRY ANALYSIS ===
Retried cases: 0
Retry success rate: 0.00%
Average retries for success: 0.00

=== FIX ANALYSIS ===
Fixed cases: 0
Fix success rate: 0.00%

=== BACKUP ANALYSIS ===
Used-backup cases: 0
Backup success rate: 0.00%

=== VALID-ONLY (NO ERROR) PERFORMANCE ===

--- cot_answer (valid only) ---
Accuracy: 53.85%
Answer distribution: {'A': 75, 'B': 60, 'C': 53, 'E': 36, 'D': 35, 'G': 20, 'F': 20}

--- direct_answer (valid only) ---
Accuracy: 0.00%
Answer distribution: {}
wandb: - 0.007 MB of 0.007 MB uploadedwandb: \ 0.184 MB of 0.184 MB uploadedwandb: | 0.184 MB of 0.184 MB uploadedwandb: 
wandb: Run history:
wandb:                   train/completion_length ‚ñÑ‚ñÉ‚ñá‚ñÜ‚ñÜ‚ñÇ‚ñÉ‚ñÉ‚ñà‚ñÜ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ
wandb:                               train/epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                         train/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                           train/grad_norm ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñá‚ñÑ‚ñÜ‚ñÇ‚ñÉ‚ñÅ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÖ‚ñà‚ñÑ‚ñÖ‚ñÇ‚ñÖ
wandb:                                  train/kl ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÇ‚ñÉ
wandb:                       train/learning_rate ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                train/loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñà‚ñÇ‚ñÉ
wandb:                              train/reward ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÑ‚ñà‚ñÜ
wandb:                          train/reward_std ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñá
wandb: train/rewards/cot_correctness_reward_func ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÑ‚ñÑ‚ñá‚ñÖ
wandb:      train/rewards/cot_format_reward_func ‚ñÅ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñà‚ñà
wandb:      train/rewards/cot_letter_reward_func ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:                                total_flos 0.0
wandb:                   train/completion_length 299.75
wandb:                               train/epoch 6.66667
wandb:                         train/global_step 500
wandb:                           train/grad_norm 0.94375
wandb:                                  train/kl 0.00398
wandb:                       train/learning_rate 0.0
wandb:                                train/loss 0.0002
wandb:                              train/reward 2.25
wandb:                          train/reward_std 1.0
wandb: train/rewards/cot_correctness_reward_func 1.25
wandb:      train/rewards/cot_format_reward_func 0.5
wandb:      train/rewards/cot_letter_reward_func 0.5
wandb:                                train_loss 0.00033
wandb:                             train_runtime 32074.507
wandb:                  train_samples_per_second 0.249
wandb:                    train_steps_per_second 0.016
wandb: 
wandb: üöÄ View run outputs at: https://wandb.ai/m-uceda-rug/huggingface/runs/8f5295ug
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/m-uceda-rug/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250616_162617-8f5295ug/logs

###############################################################################
H√°br√≥k Cluster
Job 17928220 for user s5112583
Finished at: Tue Jun 17 02:11:07 CEST 2025

Job details:
============

Job ID                         : 17928220
Name                           : exp6_job
User                           : s5112583
Partition                      : gpumedium
Nodes                          : a100gpu4
Number of Nodes                : 1
Cores                          : 16
Number of Tasks                : 1
State                          : COMPLETED  
Submit                         : 2025-06-15T14:36:53
Start                          : 2025-06-16T16:20:53
End                            : 2025-06-17T02:11:02
Reserved walltime              : 1-00:00:00
Used walltime                  :   09:50:09
Used CPU time                  :   10:36:58 (Efficiency:  6.75%)
% User (Computation)           : 96.89%
% System (I/O)                 :  3.11%
Total memory reserved          : 70000M
Maximum memory used            : 3.73G
Requested GPUs                 : a100=1
Allocated GPUs                 : a100=1
Max GPU utilization            : 45%
Max GPU memory used            : 28.04G
Hints and tips      :
 1) You requested much more CPU memory than your program used.
    Please reduce the requested amount of memory.
 *) For more information on these issues see:
    https://wiki.hpc.rug.nl/habrok/additional_information/job_hints

Acknowledgements:
=================

Please see this page for information about acknowledging H√°br√≥k in your publications:

https://wiki.hpc.rug.nl/habrok/introduction/scientific_output

################################################################################
